{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter settings and library importation\n",
    "\n",
    "# Used to move files around and other file system related tasks\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Used to record audio streams\n",
    "import pyaudio\n",
    "import wave\n",
    "import datetime\n",
    "\n",
    "# Used to process audio data\n",
    "import contextlib\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Used to read Matlab files from python\n",
    "import matlab.engine\n",
    "\n",
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to produce a less messy formatting for the current time\n",
    "def replace_special_chars(z, special_chars, new_char):\n",
    "    removeSpecialChars = z.translate ({ord(c): new_char for c in special_chars})\n",
    "    return removeSpecialChars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_into_smaller_windows(fname, window_size):\n",
    "    target_frames = window_size * 1000\n",
    "    \n",
    "    with contextlib.closing(wave.open(fname,'r')) as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "        \n",
    "        audio = AudioSegment.from_wav(fname)\n",
    "        \n",
    "        print(duration)\n",
    "        \n",
    "        fold = int(duration/window_size)        \n",
    "        for i in range(0, fold):\n",
    "            begin = i * target_frames\n",
    "            end = (i + 1) * target_frames\n",
    "            if end > duration*1000:\n",
    "                break\n",
    "            else:\n",
    "                sub_audio = audio[begin:end]\n",
    "                #print(sub_audio.getnframes()/sub_audio.getframerate())\n",
    "                sub_audio.export(fname[:len(fname)-4]+'-'+str(i)+'.wav', format='wav')\n",
    "            \n",
    "    os.remove(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'C://Users//yg9ca//Desktop//PCR_pipeline//test_audios//test_wav.wav'\n",
    "slice_into_smaller_windows(fname, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 10\n",
    "\n",
    "# Used to receive a single session of audio input from the microphone\n",
    "def record_single_session(CHUNK, FORMAT, CHANNELS, RATE, RECORD_SECONDS):\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Recording in process...\")\n",
    "    \n",
    "    CURRENT_TIME = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    WAVE_OUTPUT_FILENAME = replace_special_chars(CURRENT_TIME, ': ', '-') + '.wav'\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished...\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    os.rename(WAVE_OUTPUT_FILENAME, './/Recordings//' + WAVE_OUTPUT_FILENAME)\n",
    "    print(\"Generated audio file \" + WAVE_OUTPUT_FILENAME)\n",
    "    \n",
    "    return './/Recordings//' + WAVE_OUTPUT_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDirName = '.'\n",
    "nMixtures = 1024\n",
    "\n",
    "# Get the result for speaker ID\n",
    "def speakerID(fname, rootDirName, nMixtures, percent_of_speech):\n",
    "    \n",
    "    eng = matlab.engine.start_matlab()\n",
    "    \n",
    "    if percent_of_speech < 0.5:\n",
    "        # Not enough speech in the segment of + fname + to perform speaker ID.\n",
    "        sid = 0\n",
    "    else:    \n",
    "        # Get speaker ID result\n",
    "        sid = 0\n",
    "        try:\n",
    "            sid = eng.PCR_main (fname)\n",
    "        except:\n",
    "            pass\n",
    "        print('speaker ID result for ' + fname + ' is ' + str(sid) )\n",
    "        \n",
    "    eng.quit()\n",
    "    \n",
    "    return sid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_of_speech(fname):\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    # Get rid of background noises\n",
    "    percent_of_speech = eng.absolute_silence(fname, fname)\n",
    "    \n",
    "    eng.quit()\n",
    "    return percent_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "while(True):\n",
    "    # fname = record_single_session(CHUNK, FORMAT, CHANNELS, RATE, RECORD_SECONDS)\n",
    "    print(speakerID(fname, rootDirName, nMixtures, 0.5))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eng.plot_VAD('.//Recordings//2019-06-12-13-23-13.wav', nargout=0)\n",
    "\n",
    "# this is the main() of the pipeline\n",
    "def speech_recognition():\n",
    "    while(True):\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:                # use the default microphone as the audio source\n",
    "            audio = r.listen(source)                   # listen for the first phrase and extract it into audio data\n",
    "\n",
    "        try:\n",
    "            transcription = r.recognize_google(audio)    # recognize speech using Google Speech Recognition\n",
    "            print(transcription)\n",
    "            CURRENT_TIME = str(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            WAVE_OUTPUT_FILENAME = replace_special_chars(CURRENT_TIME, ': ', '-') + '.wav'\n",
    "            fname = './/Recordings//' + WAVE_OUTPUT_FILENAME\n",
    "            \n",
    "            with open(fname, \"wb\") as f:\n",
    "                f.write(audio.get_wav_data())\n",
    "                print('Recognizable voice detected. Saved as ' + WAVE_OUTPUT_FILENAME)\n",
    "                \n",
    "                #id = speakerID(fname, rootDirName, nMixtures, percent_of_speech(fname))\n",
    "                #print(id)\n",
    "                #slice_into_smaller_windows(fname, 5)\n",
    "\n",
    "            break\n",
    "            \n",
    "        except:                            # speech is unintelligible\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main() of the pipeline\n",
    "def speech_recognition_evaluation(folder):\n",
    "    \n",
    "    silence = []\n",
    "    speech = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.wav'):\n",
    "            audio = folder + '//' + filename\n",
    "            \n",
    "            percent = percent_of_speech(audio)\n",
    "            \n",
    "            if percent < 0.25:\n",
    "                silence.append(audio)\n",
    "                os.rename(audio, 'C://Users//yg9ca//Desktop//PCR_pipeline//test_audios//silence//'+filename)\n",
    "            else:\n",
    "                speech.append(audio)\n",
    "                os.rename(audio, 'C://Users//yg9ca//Desktop//PCR_pipeline//test_audios//speech//'+filename)\n",
    "\n",
    "            print(filename + ' ' + str(percent))\n",
    "        \n",
    "    return silence, speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silence, speech = speech_recognition_evaluation('C://Users//yg9ca//Desktop//PCR_pipeline//test_audios')\n",
    "\n",
    "print(silence)\n",
    "print(speech)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def single_audio_processing(fname):\n",
    "    speech_percentage = percent_of_speech(fname)\n",
    "    sid = speakerID(fname, rootDirName, nMixtures, percent_of_speech(fname))\n",
    "\n",
    "    \n",
    "    print('speech percentage = ' + str(speech_percentage))\n",
    "    print('sid = ' + str(sid))\n",
    "    \n",
    "\n",
    "# single_audio_processing('C://Users//yg9ca//Desktop//PCR_pipeline//test//test_wav.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
