{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features are unspecified. Defaut is set to = 272.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import os, shutil, glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Add\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pyprind\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlapping=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 272 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "try:\n",
    "    NumofFeaturetoUse = int(sys.argv[1])\n",
    "    print('Number of features to use is set to ' + str(sys.argv[1]) )\n",
    "except:\n",
    "    print('Number of features are unspecified. Defaut is set to = 272.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress testing\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Progress testing\n",
      "  Started: 09/06/2019 17:20:42\n",
      "  Finished: 09/06/2019 17:20:44\n",
      "  Total time elapsed: 00:00:01\n",
      "  CPU %: 9.40\n",
      "  Memory %: 3.22\n"
     ]
    }
   ],
   "source": [
    "bar = pyprind.ProgBar(1000, monitor=True, title='Progress testing', bar_char='█')\n",
    "for i in range(1000):\n",
    "    time.sleep(0.001)\n",
    "    bar.update()\n",
    "print(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(input_np):\n",
    "    output_np = []\n",
    "    for x in np.nditer(input_np):\n",
    "        if x == 'H':\n",
    "            x = 0\n",
    "        elif x == 'A':\n",
    "            x = 1\n",
    "        elif x == 'N':\n",
    "            x = 2\n",
    "        else:\n",
    "            x = 3\n",
    "        output_np.append(x)\n",
    "    output_np = np.array(output_np)\n",
    "    output_np = np.reshape(output_np, (len(output_np), 1) )\n",
    "    \n",
    "    return output_np\n",
    "\n",
    "def float_compatible(input_np):\n",
    "    \n",
    "    input_np = np.nan_to_num(input_np)\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    \n",
    "    for index in range(0, len(x[0])):\n",
    "        \n",
    "        try:\n",
    "            x_position = x[0][index]\n",
    "            y_position = x[1][index]\n",
    "            input_np[x_position, y_position] = 0.0\n",
    "        except:\n",
    "            print(x)\n",
    "            print(x[0])\n",
    "\n",
    "    return input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_FeatureExtractfromSinglewindow(y,hop_length,sr):\n",
    "\n",
    "    genFeatures=np.array([])\n",
    "    try:\n",
    "        mfcc0 = librosa.feature.mfcc(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length, n_mfcc=13)\n",
    "        mfcc=np.transpose(mfcc0)\n",
    "\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        mfcc_delta=librosa.feature.delta(mfcc0)\n",
    "        mfcc_delta=np.transpose(mfcc_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        zcr0=librosa.feature.zero_crossing_rate(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "        zcr=np.transpose(zcr0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(zcr, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        zcr_delta=librosa.feature.delta(zcr0)\n",
    "        zcr_delta=np.transpose(zcr_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(zcr_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        Erms0=librosa.feature.rmse(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "        Erms=np.transpose(Erms0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(Erms, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        Erms_delta=librosa.feature.delta(Erms0)\n",
    "        Erms_delta=np.transpose(Erms_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(Erms_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        cent0 = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length)\n",
    "        cent=np.transpose(cent0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(cent, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        cent_delta=librosa.feature.delta(cent0)\n",
    "        cent_delta=np.transpose(cent_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(cent_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "        #Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame.\n",
    "\n",
    "        ############### pitch at certain frame\n",
    "        pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=75, fmax=8000, n_fft=hop_length*2, hop_length=hop_length)\n",
    "        p=[pitches[magnitudes[:,i].argmax(),i] for i in range(0,pitches.shape[1])]\n",
    "        pitch0=np.array(p)   #shape (305,)\n",
    "        pitch=np.transpose(pitch0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(pitch, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        pitch_delta=librosa.feature.delta(pitch0)\n",
    "        pitch_delta=np.transpose(pitch_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(pitch_delta, 0)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    #print(genFeatures.shape)    #272\n",
    "    return genFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract specified amount of features from an audio file\n",
    "'''\n",
    "def function_FeatureExtract1(audiofile, NumofFeatures):\n",
    "    extension = '.wav'\n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    All = np.array([])\n",
    "    NumofFeaturetoUse = NumofFeatures #needs to be reassigned, takes two parameters\n",
    "    ListOfFrame2Vec = np.empty((0, frame_number, NumofFeaturetoUse))\n",
    "    audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "    segment_start_flag = 0\n",
    "    start_seg = 0\n",
    "    while (start_seg + segment_length) < len(audio):\n",
    "        flag = 1\n",
    "        sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "\n",
    "        featureSet = function_FeatureExtractfromSinglewindow(sound1, hop_length, sample_rate)\n",
    "\n",
    "        if segment_start_flag == 0:\n",
    "            SegAllFeat = featureSet\n",
    "            segment_start_flag = 1\n",
    "        else:\n",
    "            SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "        start_seg = start_seg + overlapping\n",
    "\n",
    "    if segment_start_flag == 1:\n",
    "        #print(SegAllFeat.shape)\n",
    "        SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "\n",
    "    #print(SegAllFeat.shape)\n",
    "    if flag_start_all == 0:\n",
    "        All = SegAllFeat\n",
    "        flag_start_all = 1\n",
    "    else:\n",
    "        All = np.vstack((All, SegAllFeat))\n",
    "\n",
    "    return All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these funstion will generate feature set for feature selection from training\n",
    "def function_FeatureExtract(path, classY):\n",
    "    extension = '.wav'\n",
    "    \n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    file_counter = 1\n",
    "    \n",
    "    All = np.array([])\n",
    "    ClassLabel = np.array([])\n",
    "    \n",
    "    #bar = pyprind.ProgBar(len(os.listdir(path)), monitor=True, title='feature extraction', bar_char='█')\n",
    "    \n",
    "    number_of_elements = len(os.listdir(path))\n",
    "    i = 0\n",
    "    for file_name in os.listdir(path):\n",
    "        \n",
    "        if not file_name.endswith(extension) or file_name[0] == '.':\n",
    "            continue\n",
    "        \n",
    "        audiofile = path + file_name\n",
    "        audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "        segment_start_flag = 0\n",
    "        start_seg = 0\n",
    "        \n",
    "        while (start_seg + segment_length) < len(audio):\n",
    "\n",
    "            flag = 1\n",
    "            sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "            featureSet = function_FeatureExtractfromSinglewindow(sound1, hop_length, sample_rate)\n",
    "\n",
    "            featureSet = float_compatible(featureSet)\n",
    "\n",
    "            if segment_start_flag == 0:\n",
    "                SegAllFeat = featureSet\n",
    "                SegAllFeat = float_compatible(SegAllFeat)\n",
    "                segment_start_flag = 1\n",
    "            else:\n",
    "                SegAllFeat = float_compatible(SegAllFeat)\n",
    "                SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "\n",
    "            if flag_Y_start == 0:\n",
    "                ClassLabel = [classY]\n",
    "                flag_Y_start = 1\n",
    "            else:\n",
    "                ClassLabel = np.vstack((ClassLabel, [classY]))\n",
    "\n",
    "            ################################ end of class value identify\n",
    "            start_seg = start_seg + overlapping\n",
    "\n",
    "        SegAllFeat = float_compatible(SegAllFeat)\n",
    "        #print(SegAllFeat.shape)\n",
    "        if segment_start_flag == 1:\n",
    "            try:\n",
    "                SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "            except:\n",
    "                x = np.where(SegAllFeat >= np.finfo(np.float32).max)\n",
    "                print(x)\n",
    "                break\n",
    "\n",
    "        #print(SegAllFeat.shape)\n",
    "        if flag_start_all == 0:\n",
    "            All = SegAllFeat\n",
    "            flag_start_all = 1\n",
    "        else:\n",
    "            All = np.vstack((All, SegAllFeat))\n",
    "\n",
    "        i += 1\n",
    "        update_progress(i / number_of_elements)\n",
    "\n",
    "    return All, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_new_feature_vector(feature_raw, feature_vector, label, label_vector):\n",
    "    \n",
    "    # feature_raw = the path in which the raw files (images, audios) are saved.\n",
    "    # feature_vector = the npy file consisting of all the feature vectors in the class\n",
    "    # label = the label of the class, should be numerical,  a single number\n",
    "    # label_vector = just an npy array of the labels\n",
    "    \n",
    "    if os.path.exists(feature_vector):\n",
    "        print('Deleting old feature vector npy ...')\n",
    "        os.remove(feature_vector)\n",
    "        \n",
    "    if os.path.exists(label_vector):\n",
    "        print('Deleting old label vector npy ...')\n",
    "        os.remove(label_vector)\n",
    "    \n",
    "    open(feature_vector, 'a').close()\n",
    "    open(label_vector, 'a').close()\n",
    "    \n",
    "    featureSet, Label = function_FeatureExtract(feature_raw, label)  # change here\n",
    "    \n",
    "    np.save(feature_vector, featureSet)\n",
    "    np.save(label_vector, Label)\n",
    "\n",
    "\n",
    "    vec = featureSet/np.float32(255)\n",
    "    # label = Label.astype(np.int32)  # not required\n",
    "    \n",
    "    return np.array(vec), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_old_feature_vector(feature_vector, label_vector):\n",
    "    \n",
    "    # feature_raw = the path in which the raw files (images, audios) are saved.\n",
    "    # feature_vector = the npy file consisting of all the feature vectors in the class\n",
    "    # label = the label of the class, should be numerical,  a single number\n",
    "    # label_vector = just an npy array of the labels\n",
    "    vec = np.array([])\n",
    "    ret_label = np.array([])\n",
    "    \n",
    "    if not os.path.exists(feature_vector):\n",
    "        print('Unable to find old feature vector npy ...')\n",
    "        \n",
    "    elif not os.path.exists(label_vector):\n",
    "        print('Unable to find old label vector npy ... ')\n",
    "\n",
    "    else:\n",
    "        vec = np.load(feature_vector)\n",
    "        ret_label = np.load(label_vector)\n",
    "\n",
    "    return np.array(vec), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '//Volumes//Morpheus//'\n",
    "\n",
    "h_directory = prefix + 'Datasets//TRAINING//Happy//'\n",
    "a_directory = prefix + 'Datasets//TRAINING//Angry//'\n",
    "n_directory = prefix + 'Datasets//TRAINING//Neutral//'\n",
    "s_directory = prefix + 'Datasets//TRAINING//Sad//'\n",
    "o_directory = prefix + 'Datasets//TRAINING//Other//'\n",
    "\n",
    "h_test = prefix + 'Datasets//TRAINING//Happy_test//'\n",
    "a_test = prefix + 'Datasets//TRAINING//Angry_test//'\n",
    "n_test = prefix + 'Datasets//TRAINING//Neutral_test//'\n",
    "s_test = prefix + 'Datasets//TRAINING//Sad_test//'\n",
    "o_test = prefix + 'Datasets//TRAINING//Other_test//'\n",
    "\n",
    "background_noise = 'D://Background_noise//TUT2016//'\n",
    "background_noise_test = 'D://Background_noise//noise_test//'\n",
    "\n",
    "emotion_train_folders = [h_directory, a_directory, n_directory, s_directory, o_directory]\n",
    "emotion_test_folders = [h_test, a_test, n_test, s_test, o_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '..//..//'\n",
    "\n",
    "h_feature_vector = prefix + 'Features//h_feature_vector_indices.npy'\n",
    "h_label_vector = prefix + 'Features//h_label_vector_indices.npy'\n",
    "\n",
    "a_feature_vector = prefix + 'Features//a_feature_vector_indices.npy'\n",
    "a_label_vector = prefix + 'Features//a_label_vector_indices.npy'\n",
    "\n",
    "n_feature_vector = prefix + 'Features//n_feature_vector_indices.npy'\n",
    "n_label_vector = prefix + 'Features//n_label_vector_indices.npy'\n",
    "\n",
    "s_feature_vector = prefix + 'Features//s_feature_vector_indices.npy'\n",
    "s_label_vector = prefix + 'Features//s_label_vector_indices.npy'\n",
    "\n",
    "s_feature_vector = prefix + 'Features//o_feature_vector_indices.npy'\n",
    "s_label_vector = prefix + 'Features//o_label_vector_indices.npy'\n",
    "\n",
    "h_feature_vector_test = prefix + 'Features//h_feature_vector_test_indices.npy'\n",
    "h_label_vector_test = prefix + 'Features//h_label_vector_test_indices.npy'\n",
    "\n",
    "a_feature_vector_test = prefix + 'Features//a_feature_vector_test_indices.npy'\n",
    "a_label_vector_test = prefix + 'Features//a_label_vector_test_indices.npy'\n",
    "\n",
    "n_feature_vector_test = prefix + 'Features//n_feature_vector_test_indices.npy'\n",
    "n_label_vector_test = prefix + 'Features//n_label_vector_test_indices.npy'\n",
    "\n",
    "s_feature_vector_test = prefix + 'Features//s_feature_vector_test_indices.npy'\n",
    "s_label_vector_test = prefix + 'Features//s_label_vector_test_indices.npy'\n",
    "\n",
    "s_feature_vector_test = prefix + 'Features//o_feature_vector_test_indices.npy'\n",
    "s_label_vector_test = prefix + 'Features//o_label_vector_test_indices.npy'\n",
    "\n",
    "indices_npy_five = prefix + 'Features//feat_ranking_five_classes.npy'\n",
    "indices_npy_four = prefix + 'Features//feat_ranking_four_classes.npy'\n",
    "indices_npy_binary_top = prefix + 'Features//feat_ranking_binary_top.npy'\n",
    "indices_npy_binary_H_A = prefix + 'Features//feat_ranking_binary_H_A.npy'\n",
    "indices_npy_binary_N_S = prefix + 'Features//feat_ranking_binary_N_S.npy'\n",
    "indices_npy_tri_top_O = prefix + 'Features//feat_ranking_tri_top_O.npy'\n",
    "indices_npy_tri_H_A_O = prefix + 'Features//feat_ranking_tri_H_A_O.npy'\n",
    "indices_npy_tri_N_S_O = prefix + 'Features//feat_ranking_tri_N_S_O.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "data_train_h, label_train_h = obtain_new_feature_vector(h_test, h_feature_vector_test, 0, h_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "data_train_a, label_train_a = obtain_new_feature_vector(a_test, a_feature_vector_test, 1, a_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "data_train_n, label_train_n = obtain_new_feature_vector(n_test, n_feature_vector_test, 2, n_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "data_train_s, label_train_s = obtain_new_feature_vector(s_test, s_feature_vector_test, 3, s_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "data_train_o, label_train_o = obtain_new_feature_vector(s_test, s_feature_vector_test, 4, s_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [##--------------------------------------------------------------------------------------------------] 2.0%\n"
     ]
    }
   ],
   "source": [
    "data_eval_h, label_eval_h = obtain_new_feature_vector(h_directory, h_feature_vector, 0, h_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_a, label_eval_a = obtain_new_feature_vector(a_directory, a_feature_vector, 1, a_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_n, label_eval_n = obtain_new_feature_vector(n_directory, n_feature_vector, 2, n_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_s, label_eval_s = obtain_new_feature_vector(s_directory, s_feature_vector, 3, s_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_o, label_eval_o = obtain_new_feature_vector(s_directory, s_feature_vector, 4, s_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specify_classes(npy_name):\n",
    "    \n",
    "    train_data_list = [data_train_h, data_train_a, data_train_n, data_train_s, data_train_o]\n",
    "    train_label_list = [label_train_h, label_train_a, label_train_n, label_train_s, label_train_o]\n",
    "    \n",
    "    eval_data_list = [data_eval_h, data_eval_a, data_eval_n, data_eval_s, data_eval_o]\n",
    "    eval_label_list = [label_eval_h, label_eval_a, label_eval_n, label_eval_s, label_eval_o]\n",
    "    \n",
    "    if 'five_classes' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[0], train_data_list[1], train_data_list[2], train_data_list[3], train_data_list[4]))\n",
    "        train_labels = np.append(train_label_list[0], train_label_list[1], train_label_list[2], train_label_list[3], train_label_list[4], axis=0)\n",
    "        \n",
    "        eval_data = np.vstack((eval_data_list[0], eval_data_list[1], eval_data_list[2], eval_data_list[3], eval_data_list[4]))\n",
    "        eval_labels = np.append(eval_label_list[0], eval_label_list[1], eval_label_list[2], eval_label_list[3], eval_label_list[4], axis=0)\n",
    "    \n",
    "    elif 'four_classes' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[0], train_data_list[1], train_data_list[2], train_data_list[3]))\n",
    "        train_labels = np.append(train_label_list[0], train_label_list[1], train_label_list[2], train_label_list[3], axis=0)\n",
    "        eval_data = np.vstack((eval_data_list[0], eval_data_list[1], eval_data_list[2], eval_data_list[3]))\n",
    "        eval_labels = np.append(eval_label_list[0], eval_label_list[1], eval_label_list[2], eval_label_list[3], axis=0)\n",
    "        \n",
    "    elif 'binary_top' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[0], train_data_list[1], train_data_list[2], train_data_list[3]))\n",
    "        train_labels = np.append(train_label_list[0], train_label_list[1], train_label_list[2], train_label_list[3], axis=0)\n",
    "        eval_data = np.vstack((eval_data_list[0], eval_data_list[1], eval_data_list[2], eval_data_list[3]))\n",
    "        eval_labels = np.append(eval_label_list[0], eval_label_list[1], eval_label_list[2], eval_label_list[3], axis=0)\n",
    "        \n",
    "        train_labels[train_labels == 0] = 0\n",
    "        train_labels[train_labels == 1] = 0\n",
    "        train_labels[train_labels == 2] = 1\n",
    "        train_labels[train_labels == 3] = 1\n",
    "        \n",
    "        eval_labels[eval_labels == 0] = 0\n",
    "        eval_labels[eval_labels == 1] = 0\n",
    "        eval_labels[eval_labels == 2] = 1\n",
    "        eval_labels[eval_labels == 3] = 1\n",
    "    \n",
    "    elif 'binary_H_A' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[0], train_data_list[1]))\n",
    "        train_labels = np.append(train_label_list[0], train_label_list[1], axis=0)\n",
    "        \n",
    "        eval_data = np.vstack((eval_data_list[0], eval_data_list[1]))\n",
    "        eval_labels = np.append(eval_label_list[0], eval_label_list[1], axis=0)\n",
    "        \n",
    "        train_labels[train_labels == 0] = 0\n",
    "        train_labels[train_labels == 1] = 1\n",
    "        \n",
    "        eval_labels[eval_labels == 0] = 0\n",
    "        eval_labels[eval_labels == 1] = 1\n",
    "        \n",
    "    elif 'binary_N_S' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[2], train_data_list[3]))\n",
    "        train_labels = np.append(train_label_list[2], train_label_list[3], axis=0)\n",
    "        \n",
    "        eval_data = np.vstack((eval_data_list[2], eval_data_list[3]))\n",
    "        eval_labels = np.append(eval_label_list[2], eval_label_list[3], axis=0)\n",
    "        \n",
    "        train_labels[train_labels == 2] = 0\n",
    "        train_labels[train_labels == 3] = 1\n",
    "        \n",
    "        eval_labels[eval_labels == 2] = 0\n",
    "        eval_labels[eval_labels == 3] = 1\n",
    "        \n",
    "    elif 'tri_top_O' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[0], train_data_list[1], train_data_list[2], train_data_list[3], train_data_list[4]))\n",
    "        train_labels = np.append(train_label_list[0], train_label_list[1], train_label_list[2], train_label_list[3], train_label_list[4], axis=0)  \n",
    "        eval_data = np.vstack((eval_data_list[0], eval_data_list[1], eval_data_list[2], eval_data_list[3], eval_data_list[4]))\n",
    "        eval_labels = np.append(eval_label_list[0], eval_label_list[1], eval_label_list[2], eval_label_list[3], eval_label_list[4], axis=0)\n",
    "        \n",
    "        train_labels[train_labels == 0] = 0\n",
    "        train_labels[train_labels == 1] = 0\n",
    "        train_labels[train_labels == 2] = 1\n",
    "        train_labels[train_labels == 3] = 1\n",
    "        train_labels[train_labels == 4] = 2\n",
    "        \n",
    "        eval_labels[eval_labels == 0] = 0\n",
    "        eval_labels[eval_labels == 1] = 0\n",
    "        eval_labels[eval_labels == 2] = 1\n",
    "        eval_labels[eval_labels == 3] = 1\n",
    "        eval_labels[eval_labels == 4] = 2\n",
    "        \n",
    "    elif 'tri_H_A_O' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[0], train_data_list[1], train_data_list[4]))\n",
    "        train_labels = np.append(train_label_list[0], train_label_list[1], train_label_list[4], axis=0)  \n",
    "        eval_data = np.vstack((eval_data_list[0], eval_data_list[1], eval_data_list[4]))\n",
    "        eval_labels = np.append(eval_label_list[0], eval_label_list[1], eval_label_list[4], axis=0)\n",
    "        \n",
    "        train_labels[train_labels == 0] = 0\n",
    "        train_labels[train_labels == 1] = 1\n",
    "        train_labels[train_labels == 4] = 2\n",
    "        \n",
    "        eval_labels[eval_labels == 0] = 0\n",
    "        eval_labels[eval_labels == 1] = 1\n",
    "        eval_labels[eval_labels == 4] = 2\n",
    "    \n",
    "    elif 'tri_N_S_O' in npy_name:\n",
    "        train_data = np.vstack((train_data_list[2], train_data_list[2], train_data_list[4]))\n",
    "        train_labels = np.append(train_label_list[3], train_label_list[3], train_label_list[4], axis=0)  \n",
    "        eval_data = np.vstack((eval_data_list[2], eval_data_list[2], eval_data_list[4]))\n",
    "        eval_labels = np.append(eval_label_list[3], eval_label_list[3], eval_label_list[4], axis=0)\n",
    "        \n",
    "        train_labels[train_labels == 2] = 0\n",
    "        train_labels[train_labels == 3] = 1\n",
    "        train_labels[train_labels == 4] = 2\n",
    "        \n",
    "        eval_labels[eval_labels == 2] = 0\n",
    "        eval_labels[eval_labels == 3] = 1\n",
    "        eval_labels[eval_labels == 4] = 2\n",
    "        \n",
    "    return [npy_name, train_data, train_labels, eval_data, eval_labels ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '..//..//'\n",
    "\n",
    "indices_npy_five = prefix + 'Features//feat_ranking_five_classes.npy'\n",
    "indices_npy_four = prefix + 'Features//feat_ranking_four_classes.npy'\n",
    "indices_npy_binary_top = prefix + 'Features//feat_ranking_binary_top.npy'\n",
    "indices_npy_binary_H_A = prefix + 'Features//feat_ranking_binary_H_A.npy'\n",
    "indices_npy_binary_N_S = prefix + 'Features//feat_ranking_binary_N_S.npy'\n",
    "indices_npy_tri_top_O = prefix + 'Features//feat_ranking_tri_top_O.npy'\n",
    "indices_npy_tri_H_A_O = prefix + 'Features//feat_ranking_tri_H_A_O.npy'\n",
    "indices_npy_tri_N_S_O = prefix + 'Features//feat_ranking_tri_N_S_O.npy'\n",
    "\n",
    "indices_list = [indices_npy_five, indices_npy_four, indices_npy_binary_top, indices_npy_binary_H_A, indices_npy_binary_N_S, indices_npy_tri_top_O, indices_npy_tri_H_A_O, indices_npy_tri_N_S_O]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_five)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_four)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_binary_top)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_binary_H_A)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_binary_N_S)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_tri_top_O)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_tri_H_A_O)\n",
    "# npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices_npy_tri_N_S_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ranking():\n",
    "    \n",
    "    featureSet = train_data.astype(np.float32)\n",
    "    Label = train_labels.astype(np.float32)\n",
    "\n",
    "    ############################################################ feature selection\n",
    "    \n",
    "    X, X_test, Y, Y_test= train_test_split(featureSet, Label, test_size=0.25)\n",
    "    seed = 7\n",
    "    num_trees = 272\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=num_trees)\n",
    "\n",
    "    forest.fit(X,Y)\n",
    "\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        \n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "    return indices\n",
    "\n",
    "    ############## whole code is random forest based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "# np.save(indices_npy, indices)\n",
    "# indices = feature_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indices in indices_list:\n",
    "    if os.path.exists(indices):\n",
    "        print('Deleting indices npy ...')\n",
    "        os.remove(indices)\n",
    "    open(indices, 'a').close()\n",
    "    \n",
    "bar = pyprind.ProgBar(len(os.listdir(path)), monitor=True, title='ranking features', bar_char='█')\n",
    "    \n",
    "for indices in indices_list:\n",
    "    npy_name, train_data, train_labels, eval_data, eval_labels = specify_classes(indices)\n",
    "    ranking = feature_ranking()\n",
    "    np.save(npy_name, ranking)\n",
    "    bar.update()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "featureSet_val=np.vstack((featureSet_validation0, featureSet_validation1))\n",
    "Label_val=np.append(Label_validation0, Label_validation1, axis=0)\n",
    "\n",
    "featureSet=np.vstack((featureSet_train0, featureSet_train1))\n",
    "Label=np.append(Label_train0, Label_train1, axis=0)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
