{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features are unspecified. Defaut is set to = 272.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import os, shutil, glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Add\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pyprind\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlapping=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 272 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "try:\n",
    "    NumofFeaturetoUse = int(sys.argv[1])\n",
    "    print('Number of features to use is set to ' + str(sys.argv[1]) )\n",
    "except:\n",
    "    print('Number of features are unspecified. Defaut is set to = 272.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress testing\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Progress testing\n",
      "  Started: 09/07/2019 21:49:51\n",
      "  Finished: 09/07/2019 21:49:52\n",
      "  Total time elapsed: 00:00:01\n",
      "  CPU %: 9.60\n",
      "  Memory %: 3.19\n"
     ]
    }
   ],
   "source": [
    "bar = pyprind.ProgBar(1000, monitor=True, title='Progress testing', bar_char='█')\n",
    "for i in range(1000):\n",
    "    time.sleep(0.001)\n",
    "    bar.update()\n",
    "print(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(input_np):\n",
    "    output_np = []\n",
    "    for x in np.nditer(input_np):\n",
    "        if x == 'H':\n",
    "            x = 0\n",
    "        elif x == 'A':\n",
    "            x = 1\n",
    "        elif x == 'N':\n",
    "            x = 2\n",
    "        else:\n",
    "            x = 3\n",
    "        output_np.append(x)\n",
    "    output_np = np.array(output_np)\n",
    "    output_np = np.reshape(output_np, (len(output_np), 1) )\n",
    "    \n",
    "    return output_np\n",
    "\n",
    "def float_compatible(input_np):\n",
    "    \n",
    "    input_np = np.nan_to_num(input_np)\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    \n",
    "    for index in range(0, len(x[0])):\n",
    "        \n",
    "        try:\n",
    "            x_position = x[0][index]\n",
    "            y_position = x[1][index]\n",
    "            input_np[x_position, y_position] = 0.0\n",
    "        except:\n",
    "            print(x)\n",
    "            print(x[0])\n",
    "\n",
    "    return input_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_FeatureExtractfromSinglewindow(y,hop_length,sr):\n",
    "\n",
    "    genFeatures=np.array([])\n",
    "    try:\n",
    "        mfcc0 = librosa.feature.mfcc(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length, n_mfcc=13)\n",
    "        mfcc=np.transpose(mfcc0)\n",
    "\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        mfcc_delta=librosa.feature.delta(mfcc0)\n",
    "        mfcc_delta=np.transpose(mfcc_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        zcr0=librosa.feature.zero_crossing_rate(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "        zcr=np.transpose(zcr0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(zcr, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        zcr_delta=librosa.feature.delta(zcr0)\n",
    "        zcr_delta=np.transpose(zcr_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(zcr_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        Erms0=librosa.feature.rmse(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "        Erms=np.transpose(Erms0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(Erms, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        Erms_delta=librosa.feature.delta(Erms0)\n",
    "        Erms_delta=np.transpose(Erms_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(Erms_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        cent0 = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length)\n",
    "        cent=np.transpose(cent0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(cent, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        cent_delta=librosa.feature.delta(cent0)\n",
    "        cent_delta=np.transpose(cent_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(cent_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "        #Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame.\n",
    "\n",
    "        ############### pitch at certain frame\n",
    "        pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=75, fmax=8000, n_fft=hop_length*2, hop_length=hop_length)\n",
    "        p=[pitches[magnitudes[:,i].argmax(),i] for i in range(0,pitches.shape[1])]\n",
    "        pitch0=np.array(p)   #shape (305,)\n",
    "        pitch=np.transpose(pitch0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(pitch, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        pitch_delta=librosa.feature.delta(pitch0)\n",
    "        pitch_delta=np.transpose(pitch_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(pitch_delta, 0)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    #print(genFeatures.shape)    #272\n",
    "    return genFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract specified amount of features from an audio file\n",
    "'''\n",
    "def function_FeatureExtract1(audiofile, NumofFeatures):\n",
    "    extension = '.wav'\n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    All = np.array([])\n",
    "    NumofFeaturetoUse = NumofFeatures #needs to be reassigned, takes two parameters\n",
    "    ListOfFrame2Vec = np.empty((0, frame_number, NumofFeaturetoUse))\n",
    "    audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "    segment_start_flag = 0\n",
    "    start_seg = 0\n",
    "    while (start_seg + segment_length) < len(audio):\n",
    "        flag = 1\n",
    "        sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "\n",
    "        featureSet = function_FeatureExtractfromSinglewindow(sound1, hop_length, sample_rate)\n",
    "\n",
    "        if segment_start_flag == 0:\n",
    "            SegAllFeat = featureSet\n",
    "            segment_start_flag = 1\n",
    "        else:\n",
    "            SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "        start_seg = start_seg + overlapping\n",
    "\n",
    "    if segment_start_flag == 1:\n",
    "        #print(SegAllFeat.shape)\n",
    "        SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "\n",
    "    #print(SegAllFeat.shape)\n",
    "    if flag_start_all == 0:\n",
    "        All = SegAllFeat\n",
    "        flag_start_all = 1\n",
    "    else:\n",
    "        All = np.vstack((All, SegAllFeat))\n",
    "\n",
    "    return All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these funstion will generate feature set for feature selection from training\n",
    "def function_FeatureExtract(path, classY):\n",
    "    extension = '.wav'\n",
    "    \n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    file_counter = 1\n",
    "    \n",
    "    All = np.array([])\n",
    "    ClassLabel = np.array([])\n",
    "    \n",
    "    #bar = pyprind.ProgBar(len(os.listdir(path)), monitor=True, title='feature extraction', bar_char='█')\n",
    "    \n",
    "    number_of_elements = len(os.listdir(path))\n",
    "    i = 0\n",
    "    for file_name in os.listdir(path):\n",
    "        \n",
    "        if not file_name.endswith(extension) or file_name[0] == '.':\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            audiofile = path + file_name\n",
    "            audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "            segment_start_flag = 0\n",
    "            start_seg = 0\n",
    "\n",
    "            while (start_seg + segment_length) < len(audio):\n",
    "\n",
    "                flag = 1\n",
    "                sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "                featureSet = function_FeatureExtractfromSinglewindow(sound1, hop_length, sample_rate)\n",
    "\n",
    "                featureSet = float_compatible(featureSet)\n",
    "\n",
    "                if segment_start_flag == 0:\n",
    "                    SegAllFeat = featureSet\n",
    "                    SegAllFeat = float_compatible(SegAllFeat)\n",
    "                    segment_start_flag = 1\n",
    "                else:\n",
    "                    SegAllFeat = float_compatible(SegAllFeat)\n",
    "                    SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "\n",
    "                if flag_Y_start == 0:\n",
    "                    ClassLabel = [classY]\n",
    "                    flag_Y_start = 1\n",
    "                else:\n",
    "                    ClassLabel = np.vstack((ClassLabel, [classY]))\n",
    "\n",
    "                ################################ end of class value identify\n",
    "                start_seg = start_seg + overlapping\n",
    "\n",
    "            SegAllFeat = float_compatible(SegAllFeat)\n",
    "            #print(SegAllFeat.shape)\n",
    "            if segment_start_flag == 1:\n",
    "                try:\n",
    "                    SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "                except:\n",
    "                    x = np.where(SegAllFeat >= np.finfo(np.float32).max)\n",
    "                    print(x)\n",
    "                    break\n",
    "\n",
    "            #print(SegAllFeat.shape)\n",
    "            if flag_start_all == 0:\n",
    "                All = SegAllFeat\n",
    "                flag_start_all = 1\n",
    "            else:\n",
    "                All = np.vstack((All, SegAllFeat))\n",
    "\n",
    "            i += 1\n",
    "            update_progress(i / number_of_elements)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return All, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_new_feature_vector(feature_raw, feature_vector, label, label_vector):\n",
    "    \n",
    "    # feature_raw = the path in which the raw files (images, audios) are saved.\n",
    "    # feature_vector = the npy file consisting of all the feature vectors in the class\n",
    "    # label = the label of the class, should be numerical,  a single number\n",
    "    # label_vector = just an npy array of the labels\n",
    "    \n",
    "    if os.path.exists(feature_vector):\n",
    "        print('Deleting old feature vector npy ...')\n",
    "        os.remove(feature_vector)\n",
    "        \n",
    "    if os.path.exists(label_vector):\n",
    "        print('Deleting old label vector npy ...')\n",
    "        os.remove(label_vector)\n",
    "    \n",
    "    open(feature_vector, 'a').close()\n",
    "    open(label_vector, 'a').close()\n",
    "    \n",
    "    featureSet, Label = function_FeatureExtract(feature_raw, label)  # change here\n",
    "    \n",
    "    np.save(feature_vector, featureSet)\n",
    "    np.save(label_vector, Label)\n",
    "\n",
    "\n",
    "    vec = featureSet/np.float32(255)\n",
    "    # label = Label.astype(np.int32)  # not required\n",
    "    \n",
    "    return np.array(vec), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_old_feature_vector(feature_vector, label_vector):\n",
    "    \n",
    "    # feature_raw = the path in which the raw files (images, audios) are saved.\n",
    "    # feature_vector = the npy file consisting of all the feature vectors in the class\n",
    "    # label = the label of the class, should be numerical,  a single number\n",
    "    # label_vector = just an npy array of the labels\n",
    "    vec = np.array([])\n",
    "    ret_label = np.array([])\n",
    "    \n",
    "    if not os.path.exists(feature_vector):\n",
    "        print('Unable to find old feature vector npy ...')\n",
    "        \n",
    "    elif not os.path.exists(label_vector):\n",
    "        print('Unable to find old label vector npy ... ')\n",
    "\n",
    "    else:\n",
    "        vec = np.load(feature_vector)\n",
    "        ret_label = np.load(label_vector)\n",
    "\n",
    "    return np.array(vec), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '//Volumes//Morpheus//'\n",
    "\n",
    "h_directory = prefix + 'Datasets//TRAINING//Happy//'\n",
    "a_directory = prefix + 'Datasets//TRAINING//Angry//'\n",
    "n_directory = prefix + 'Datasets//TRAINING//Neutral//'\n",
    "s_directory = prefix + 'Datasets//TRAINING//Sad//'\n",
    "o_directory = prefix + 'Datasets//TRAINING//Other//'\n",
    "\n",
    "h_test = prefix + 'Datasets//TRAINING//Happy_test//'\n",
    "a_test = prefix + 'Datasets//TRAINING//Angry_test//'\n",
    "n_test = prefix + 'Datasets//TRAINING//Neutral_test//'\n",
    "s_test = prefix + 'Datasets//TRAINING//Sad_test//'\n",
    "o_test = prefix + 'Datasets//TRAINING//Other_test//'\n",
    "\n",
    "background_noise = 'D://Background_noise//TUT2016//'\n",
    "background_noise_test = 'D://Background_noise//noise_test//'\n",
    "\n",
    "emotion_train_folders = [h_directory, a_directory, n_directory, s_directory, o_directory]\n",
    "emotion_test_folders = [h_test, a_test, n_test, s_test, o_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '..//..//'\n",
    "\n",
    "h_feature_vector = np.load(prefix + 'Features//h_feature_vector_indices.npy')\n",
    "h_label_vector = np.load(prefix + 'Features//h_label_vector_indices.npy')\n",
    "\n",
    "a_feature_vector = np.load(prefix + 'Features//a_feature_vector_indices.npy')\n",
    "a_label_vector = np.load(prefix + 'Features//a_label_vector_indices.npy')\n",
    "\n",
    "n_feature_vector = np.load(prefix + 'Features//n_feature_vector_indices.npy')\n",
    "n_label_vector = np.load(prefix + 'Features//n_label_vector_indices.npy')\n",
    "\n",
    "s_feature_vector = prefix + 'Features//s_feature_vector_indices.npy'\n",
    "s_label_vector = prefix + 'Features//s_label_vector_indices.npy'\n",
    "\n",
    "o_feature_vector = prefix + 'Features//o_feature_vector_indices.npy'\n",
    "o_label_vector = prefix + 'Features//o_label_vector_indices.npy'\n",
    "\n",
    "h_feature_vector_test = prefix + 'Features//h_feature_vector_test_indices.npy'\n",
    "h_label_vector_test = prefix + 'Features//h_label_vector_test_indices.npy'\n",
    "\n",
    "a_feature_vector_test = prefix + 'Features//a_feature_vector_test_indices.npy'\n",
    "a_label_vector_test = prefix + 'Features//a_label_vector_test_indices.npy'\n",
    "\n",
    "n_feature_vector_test = prefix + 'Features//n_feature_vector_test_indices.npy'\n",
    "n_label_vector_test = prefix + 'Features//n_label_vector_test_indices.npy'\n",
    "\n",
    "s_feature_vector_test = prefix + 'Features//s_feature_vector_test_indices.npy'\n",
    "s_label_vector_test = prefix + 'Features//s_label_vector_test_indices.npy'\n",
    "\n",
    "o_feature_vector_test = prefix + 'Features//o_feature_vector_test_indices.npy'\n",
    "o_label_vector_test = prefix + 'Features//o_label_vector_test_indices.npy'\n",
    "\n",
    "indices_npy_five = prefix + 'Features//feat_ranking_five_classes.npy'\n",
    "indices_npy_four = prefix + 'Features//feat_ranking_four_classes.npy'\n",
    "indices_npy_binary_top = prefix + 'Features//feat_ranking_binary_top.npy'\n",
    "indices_npy_binary_H_A = prefix + 'Features//feat_ranking_binary_H_A.npy'\n",
    "indices_npy_binary_N_S = prefix + 'Features//feat_ranking_binary_N_S.npy'\n",
    "indices_npy_tri_top_O = prefix + 'Features//feat_ranking_tri_top_O.npy'\n",
    "indices_npy_tri_H_A_O = prefix + 'Features//feat_ranking_tri_H_A_O.npy'\n",
    "indices_npy_tri_N_S_O = prefix + 'Features//feat_ranking_tri_N_S_O.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test_s, label_test_s = obtain_new_feature_vector(s_test, s_feature_vector_test, 3, s_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train_s, label_train_s = obtain_new_feature_vector(s_directory, s_feature_vector, 3, s_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test_o, label_test_o = obtain_new_feature_vector(o_test, o_feature_vector_test, 4, o_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "data_train_o, label_train_o = obtain_new_feature_vector(o_directory, o_feature_vector, 4, o_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_feature_vector_test = np.load(prefix + 'Features//h_feature_vector_test_indices.npy')\n",
    "h_label_vector_test = np.load(prefix + 'Features//h_label_vector_test_indices.npy')\n",
    "\n",
    "a_feature_vector_test = np.load(prefix + 'Features//a_feature_vector_test_indices.npy')\n",
    "a_label_vector_test = np.load(prefix + 'Features//a_label_vector_test_indices.npy')\n",
    "\n",
    "train_data = np.vstack((h_feature_vector, a_feature_vector))\n",
    "train_labels = np.vstack((h_label_vector, a_label_vector))\n",
    "indices_file = indices_npy_binary_H_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ranking(indices_file):\n",
    "    \n",
    "    if os.path.exists(indices_file):\n",
    "        print('Deleting indices npy ...')\n",
    "        os.remove(indices_file)\n",
    "    open(indices_file, 'a').close()\n",
    "    \n",
    "    featureSet = train_data.astype(np.float32)\n",
    "    Label = train_labels.astype(np.float32)\n",
    "\n",
    "    ############################################################ feature selection\n",
    "    \n",
    "    X, X_test, Y, Y_test= train_test_split(featureSet, Label, test_size=0.25)\n",
    "    seed = 7\n",
    "    num_trees = 272\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=num_trees)\n",
    "\n",
    "    forest.fit(X,Y)\n",
    "\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "        \n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "    np.save(indices_file, indices)\n",
    "\n",
    "    return indices\n",
    "\n",
    "    ############## whole code is random forest based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 13 (0.019585)\n",
      "2. feature 39 (0.015058)\n",
      "3. feature 26 (0.014274)\n",
      "4. feature 0 (0.010394)\n",
      "5. feature 258 (0.006100)\n",
      "6. feature 226 (0.005939)\n",
      "7. feature 45 (0.005899)\n",
      "8. feature 227 (0.005643)\n",
      "9. feature 14 (0.005590)\n",
      "10. feature 195 (0.005534)\n",
      "11. feature 225 (0.005491)\n",
      "12. feature 32 (0.005481)\n",
      "13. feature 78 (0.005451)\n",
      "14. feature 6 (0.005440)\n",
      "15. feature 263 (0.005394)\n",
      "16. feature 27 (0.005393)\n",
      "17. feature 40 (0.005387)\n",
      "18. feature 239 (0.005379)\n",
      "19. feature 91 (0.005300)\n",
      "20. feature 197 (0.005296)\n",
      "21. feature 215 (0.005274)\n",
      "22. feature 255 (0.005258)\n",
      "23. feature 93 (0.005250)\n",
      "24. feature 223 (0.005238)\n",
      "25. feature 198 (0.005218)\n",
      "26. feature 201 (0.005184)\n",
      "27. feature 100 (0.005171)\n",
      "28. feature 101 (0.005159)\n",
      "29. feature 199 (0.005145)\n",
      "30. feature 231 (0.005143)\n",
      "31. feature 203 (0.005134)\n",
      "32. feature 247 (0.005134)\n",
      "33. feature 202 (0.005112)\n",
      "34. feature 182 (0.005109)\n",
      "35. feature 196 (0.005092)\n",
      "36. feature 204 (0.005088)\n",
      "37. feature 95 (0.005085)\n",
      "38. feature 205 (0.005073)\n",
      "39. feature 92 (0.005064)\n",
      "40. feature 271 (0.005058)\n",
      "41. feature 98 (0.005049)\n",
      "42. feature 94 (0.005027)\n",
      "43. feature 200 (0.005024)\n",
      "44. feature 97 (0.005021)\n",
      "45. feature 102 (0.005011)\n",
      "46. feature 207 (0.004995)\n",
      "47. feature 96 (0.004990)\n",
      "48. feature 103 (0.004985)\n",
      "49. feature 206 (0.004978)\n",
      "50. feature 99 (0.004944)\n",
      "51. feature 228 (0.004840)\n",
      "52. feature 242 (0.004810)\n",
      "53. feature 71 (0.004782)\n",
      "54. feature 41 (0.004710)\n",
      "55. feature 3 (0.004703)\n",
      "56. feature 259 (0.004684)\n",
      "57. feature 28 (0.004679)\n",
      "58. feature 42 (0.004678)\n",
      "59. feature 44 (0.004654)\n",
      "60. feature 43 (0.004608)\n",
      "61. feature 224 (0.004584)\n",
      "62. feature 243 (0.004576)\n",
      "63. feature 29 (0.004542)\n",
      "64. feature 19 (0.004484)\n",
      "65. feature 240 (0.004476)\n",
      "66. feature 229 (0.004451)\n",
      "67. feature 210 (0.004411)\n",
      "68. feature 30 (0.004392)\n",
      "69. feature 65 (0.004367)\n",
      "70. feature 1 (0.004302)\n",
      "71. feature 15 (0.004299)\n",
      "72. feature 2 (0.004256)\n",
      "73. feature 31 (0.004242)\n",
      "74. feature 18 (0.004228)\n",
      "75. feature 48 (0.004112)\n",
      "76. feature 5 (0.004074)\n",
      "77. feature 67 (0.004060)\n",
      "78. feature 211 (0.004058)\n",
      "79. feature 46 (0.003982)\n",
      "80. feature 16 (0.003980)\n",
      "81. feature 17 (0.003978)\n",
      "82. feature 35 (0.003954)\n",
      "83. feature 4 (0.003946)\n",
      "84. feature 233 (0.003934)\n",
      "85. feature 70 (0.003863)\n",
      "86. feature 33 (0.003849)\n",
      "87. feature 52 (0.003824)\n",
      "88. feature 236 (0.003732)\n",
      "89. feature 21 (0.003715)\n",
      "90. feature 47 (0.003710)\n",
      "91. feature 34 (0.003617)\n",
      "92. feature 69 (0.003607)\n",
      "93. feature 20 (0.003606)\n",
      "94. feature 7 (0.003572)\n",
      "95. feature 58 (0.003524)\n",
      "96. feature 9 (0.003517)\n",
      "97. feature 241 (0.003508)\n",
      "98. feature 51 (0.003495)\n",
      "99. feature 49 (0.003490)\n",
      "100. feature 237 (0.003480)\n",
      "101. feature 36 (0.003457)\n",
      "102. feature 8 (0.003443)\n",
      "103. feature 256 (0.003437)\n",
      "104. feature 38 (0.003436)\n",
      "105. feature 232 (0.003403)\n",
      "106. feature 66 (0.003385)\n",
      "107. feature 68 (0.003342)\n",
      "108. feature 10 (0.003300)\n",
      "109. feature 261 (0.003281)\n",
      "110. feature 54 (0.003279)\n",
      "111. feature 209 (0.003275)\n",
      "112. feature 22 (0.003271)\n",
      "113. feature 50 (0.003267)\n",
      "114. feature 257 (0.003259)\n",
      "115. feature 24 (0.003254)\n",
      "116. feature 12 (0.003227)\n",
      "117. feature 213 (0.003219)\n",
      "118. feature 25 (0.003206)\n",
      "119. feature 55 (0.003202)\n",
      "120. feature 245 (0.003198)\n",
      "121. feature 37 (0.003140)\n",
      "122. feature 57 (0.003138)\n",
      "123. feature 23 (0.003106)\n",
      "124. feature 56 (0.003104)\n",
      "125. feature 117 (0.003100)\n",
      "126. feature 244 (0.003096)\n",
      "127. feature 72 (0.003085)\n",
      "128. feature 169 (0.003081)\n",
      "129. feature 156 (0.003069)\n",
      "130. feature 262 (0.003062)\n",
      "131. feature 104 (0.003049)\n",
      "132. feature 214 (0.003044)\n",
      "133. feature 208 (0.003043)\n",
      "134. feature 230 (0.003038)\n",
      "135. feature 260 (0.003026)\n",
      "136. feature 11 (0.003014)\n",
      "137. feature 212 (0.003007)\n",
      "138. feature 235 (0.003000)\n",
      "139. feature 80 (0.002951)\n",
      "140. feature 53 (0.002951)\n",
      "141. feature 74 (0.002941)\n",
      "142. feature 170 (0.002931)\n",
      "143. feature 76 (0.002899)\n",
      "144. feature 269 (0.002897)\n",
      "145. feature 246 (0.002879)\n",
      "146. feature 82 (0.002878)\n",
      "147. feature 73 (0.002877)\n",
      "148. feature 75 (0.002877)\n",
      "149. feature 171 (0.002874)\n",
      "150. feature 253 (0.002870)\n",
      "151. feature 63 (0.002869)\n",
      "152. feature 79 (0.002867)\n",
      "153. feature 84 (0.002867)\n",
      "154. feature 86 (0.002864)\n",
      "155. feature 184 (0.002858)\n",
      "156. feature 234 (0.002858)\n",
      "157. feature 109 (0.002854)\n",
      "158. feature 64 (0.002854)\n",
      "159. feature 62 (0.002849)\n",
      "160. feature 81 (0.002848)\n",
      "161. feature 264 (0.002846)\n",
      "162. feature 85 (0.002844)\n",
      "163. feature 157 (0.002844)\n",
      "164. feature 238 (0.002841)\n",
      "165. feature 77 (0.002840)\n",
      "166. feature 83 (0.002839)\n",
      "167. feature 186 (0.002839)\n",
      "168. feature 87 (0.002838)\n",
      "169. feature 190 (0.002837)\n",
      "170. feature 59 (0.002836)\n",
      "171. feature 90 (0.002835)\n",
      "172. feature 106 (0.002835)\n",
      "173. feature 119 (0.002835)\n",
      "174. feature 110 (0.002832)\n",
      "175. feature 266 (0.002829)\n",
      "176. feature 187 (0.002828)\n",
      "177. feature 60 (0.002827)\n",
      "178. feature 189 (0.002824)\n",
      "179. feature 194 (0.002820)\n",
      "180. feature 89 (0.002820)\n",
      "181. feature 254 (0.002818)\n",
      "182. feature 270 (0.002817)\n",
      "183. feature 118 (0.002815)\n",
      "184. feature 185 (0.002813)\n",
      "185. feature 174 (0.002812)\n",
      "186. feature 88 (0.002811)\n",
      "187. feature 183 (0.002810)\n",
      "188. feature 265 (0.002807)\n",
      "189. feature 175 (0.002803)\n",
      "190. feature 188 (0.002803)\n",
      "191. feature 221 (0.002803)\n",
      "192. feature 158 (0.002800)\n",
      "193. feature 192 (0.002799)\n",
      "194. feature 191 (0.002795)\n",
      "195. feature 123 (0.002794)\n",
      "196. feature 107 (0.002791)\n",
      "197. feature 222 (0.002786)\n",
      "198. feature 121 (0.002786)\n",
      "199. feature 61 (0.002777)\n",
      "200. feature 268 (0.002777)\n",
      "201. feature 130 (0.002777)\n",
      "202. feature 180 (0.002771)\n",
      "203. feature 116 (0.002770)\n",
      "204. feature 125 (0.002767)\n",
      "205. feature 193 (0.002766)\n",
      "206. feature 105 (0.002759)\n",
      "207. feature 143 (0.002752)\n",
      "208. feature 124 (0.002749)\n",
      "209. feature 145 (0.002747)\n",
      "210. feature 111 (0.002743)\n",
      "211. feature 220 (0.002743)\n",
      "212. feature 142 (0.002741)\n",
      "213. feature 168 (0.002739)\n",
      "214. feature 173 (0.002737)\n",
      "215. feature 248 (0.002734)\n",
      "216. feature 126 (0.002733)\n",
      "217. feature 181 (0.002732)\n",
      "218. feature 122 (0.002732)\n",
      "219. feature 129 (0.002731)\n",
      "220. feature 127 (0.002731)\n",
      "221. feature 108 (0.002729)\n",
      "222. feature 135 (0.002727)\n",
      "223. feature 178 (0.002725)\n",
      "224. feature 249 (0.002725)\n",
      "225. feature 161 (0.002724)\n",
      "226. feature 167 (0.002722)\n",
      "227. feature 114 (0.002720)\n",
      "228. feature 155 (0.002720)\n",
      "229. feature 112 (0.002719)\n",
      "230. feature 267 (0.002716)\n",
      "231. feature 172 (0.002715)\n",
      "232. feature 128 (0.002712)\n",
      "233. feature 179 (0.002711)\n",
      "234. feature 252 (0.002711)\n",
      "235. feature 140 (0.002709)\n",
      "236. feature 113 (0.002709)\n",
      "237. feature 136 (0.002708)\n",
      "238. feature 141 (0.002705)\n",
      "239. feature 176 (0.002704)\n",
      "240. feature 133 (0.002701)\n",
      "241. feature 138 (0.002700)\n",
      "242. feature 134 (0.002700)\n",
      "243. feature 132 (0.002698)\n",
      "244. feature 120 (0.002697)\n",
      "245. feature 153 (0.002692)\n",
      "246. feature 152 (0.002691)\n",
      "247. feature 137 (0.002689)\n",
      "248. feature 162 (0.002686)\n",
      "249. feature 151 (0.002684)\n",
      "250. feature 148 (0.002680)\n",
      "251. feature 115 (0.002680)\n",
      "252. feature 216 (0.002680)\n",
      "253. feature 147 (0.002679)\n",
      "254. feature 217 (0.002678)\n",
      "255. feature 131 (0.002678)\n",
      "256. feature 139 (0.002677)\n",
      "257. feature 149 (0.002677)\n",
      "258. feature 154 (0.002671)\n",
      "259. feature 150 (0.002668)\n",
      "260. feature 160 (0.002662)\n",
      "261. feature 218 (0.002661)\n",
      "262. feature 159 (0.002657)\n",
      "263. feature 146 (0.002651)\n",
      "264. feature 177 (0.002649)\n",
      "265. feature 164 (0.002649)\n",
      "266. feature 250 (0.002646)\n",
      "267. feature 166 (0.002645)\n",
      "268. feature 144 (0.002644)\n",
      "269. feature 163 (0.002626)\n",
      "270. feature 219 (0.002619)\n",
      "271. feature 165 (0.002598)\n",
      "272. feature 251 (0.002574)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a53c47a0c8d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-c07f6877aa11>\u001b[0m in \u001b[0;36mfeature_ranking\u001b[0;34m(indices_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "x = feature_ranking(indices_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting indices npy ...\n",
      "Feature ranking:\n",
      "1. feature 13 (0.018837)\n",
      "2. feature 39 (0.015046)\n",
      "3. feature 26 (0.014767)\n",
      "4. feature 0 (0.010312)\n",
      "5. feature 226 (0.005952)\n",
      "6. feature 258 (0.005921)\n",
      "7. feature 195 (0.005647)\n",
      "8. feature 6 (0.005645)\n",
      "9. feature 45 (0.005632)\n",
      "10. feature 14 (0.005602)\n",
      "11. feature 227 (0.005498)\n",
      "12. feature 225 (0.005496)\n",
      "13. feature 263 (0.005488)\n",
      "14. feature 32 (0.005477)\n",
      "15. feature 78 (0.005433)\n",
      "16. feature 215 (0.005367)\n",
      "17. feature 198 (0.005346)\n",
      "18. feature 91 (0.005304)\n",
      "19. feature 239 (0.005283)\n",
      "20. feature 197 (0.005274)\n",
      "21. feature 255 (0.005252)\n",
      "22. feature 93 (0.005229)\n",
      "23. feature 203 (0.005206)\n",
      "24. feature 40 (0.005201)\n",
      "25. feature 199 (0.005184)\n",
      "26. feature 231 (0.005179)\n",
      "27. feature 100 (0.005174)\n",
      "28. feature 200 (0.005173)\n",
      "29. feature 223 (0.005160)\n",
      "30. feature 202 (0.005153)\n",
      "31. feature 247 (0.005139)\n",
      "32. feature 201 (0.005122)\n",
      "33. feature 182 (0.005103)\n",
      "34. feature 101 (0.005087)\n",
      "35. feature 204 (0.005082)\n",
      "36. feature 97 (0.005074)\n",
      "37. feature 27 (0.005070)\n",
      "38. feature 94 (0.005067)\n",
      "39. feature 92 (0.005057)\n",
      "40. feature 196 (0.005050)\n",
      "41. feature 271 (0.005047)\n",
      "42. feature 95 (0.005040)\n",
      "43. feature 98 (0.005032)\n",
      "44. feature 207 (0.005029)\n",
      "45. feature 96 (0.005011)\n",
      "46. feature 102 (0.005010)\n",
      "47. feature 206 (0.005004)\n",
      "48. feature 205 (0.004994)\n",
      "49. feature 103 (0.004980)\n",
      "50. feature 99 (0.004924)\n",
      "51. feature 28 (0.004822)\n",
      "52. feature 228 (0.004812)\n",
      "53. feature 242 (0.004801)\n",
      "54. feature 41 (0.004776)\n",
      "55. feature 71 (0.004765)\n",
      "56. feature 259 (0.004726)\n",
      "57. feature 3 (0.004721)\n",
      "58. feature 19 (0.004704)\n",
      "59. feature 44 (0.004678)\n",
      "60. feature 43 (0.004677)\n",
      "61. feature 42 (0.004645)\n",
      "62. feature 224 (0.004589)\n",
      "63. feature 29 (0.004583)\n",
      "64. feature 229 (0.004560)\n",
      "65. feature 243 (0.004506)\n",
      "66. feature 30 (0.004481)\n",
      "67. feature 210 (0.004406)\n",
      "68. feature 240 (0.004395)\n",
      "69. feature 65 (0.004389)\n",
      "70. feature 2 (0.004271)\n",
      "71. feature 15 (0.004268)\n",
      "72. feature 31 (0.004265)\n",
      "73. feature 18 (0.004219)\n",
      "74. feature 1 (0.004123)\n",
      "75. feature 5 (0.004112)\n",
      "76. feature 67 (0.004112)\n",
      "77. feature 48 (0.004108)\n",
      "78. feature 211 (0.004101)\n",
      "79. feature 16 (0.004027)\n",
      "80. feature 46 (0.004024)\n",
      "81. feature 4 (0.003988)\n",
      "82. feature 233 (0.003941)\n",
      "83. feature 17 (0.003920)\n",
      "84. feature 33 (0.003863)\n",
      "85. feature 70 (0.003847)\n",
      "86. feature 35 (0.003816)\n",
      "87. feature 47 (0.003770)\n",
      "88. feature 236 (0.003753)\n",
      "89. feature 69 (0.003723)\n",
      "90. feature 21 (0.003706)\n",
      "91. feature 52 (0.003685)\n",
      "92. feature 34 (0.003586)\n",
      "93. feature 7 (0.003584)\n",
      "94. feature 49 (0.003561)\n",
      "95. feature 58 (0.003561)\n",
      "96. feature 51 (0.003555)\n",
      "97. feature 66 (0.003528)\n",
      "98. feature 20 (0.003520)\n",
      "99. feature 241 (0.003510)\n",
      "100. feature 9 (0.003501)\n",
      "101. feature 38 (0.003462)\n",
      "102. feature 237 (0.003426)\n",
      "103. feature 256 (0.003408)\n",
      "104. feature 36 (0.003398)\n",
      "105. feature 8 (0.003377)\n",
      "106. feature 261 (0.003366)\n",
      "107. feature 232 (0.003361)\n",
      "108. feature 10 (0.003320)\n",
      "109. feature 22 (0.003304)\n",
      "110. feature 50 (0.003298)\n",
      "111. feature 257 (0.003291)\n",
      "112. feature 68 (0.003291)\n",
      "113. feature 209 (0.003284)\n",
      "114. feature 24 (0.003250)\n",
      "115. feature 54 (0.003228)\n",
      "116. feature 245 (0.003210)\n",
      "117. feature 213 (0.003208)\n",
      "118. feature 37 (0.003206)\n",
      "119. feature 12 (0.003203)\n",
      "120. feature 25 (0.003193)\n",
      "121. feature 57 (0.003157)\n",
      "122. feature 169 (0.003134)\n",
      "123. feature 55 (0.003130)\n",
      "124. feature 23 (0.003117)\n",
      "125. feature 72 (0.003093)\n",
      "126. feature 260 (0.003078)\n",
      "127. feature 117 (0.003078)\n",
      "128. feature 244 (0.003065)\n",
      "129. feature 11 (0.003047)\n",
      "130. feature 262 (0.003046)\n",
      "131. feature 230 (0.003042)\n",
      "132. feature 214 (0.003040)\n",
      "133. feature 156 (0.003040)\n",
      "134. feature 170 (0.003036)\n",
      "135. feature 76 (0.003035)\n",
      "136. feature 104 (0.003026)\n",
      "137. feature 56 (0.003001)\n",
      "138. feature 53 (0.002988)\n",
      "139. feature 235 (0.002985)\n",
      "140. feature 212 (0.002980)\n",
      "141. feature 208 (0.002980)\n",
      "142. feature 80 (0.002941)\n",
      "143. feature 75 (0.002904)\n",
      "144. feature 246 (0.002900)\n",
      "145. feature 77 (0.002900)\n",
      "146. feature 269 (0.002890)\n",
      "147. feature 84 (0.002884)\n",
      "148. feature 85 (0.002880)\n",
      "149. feature 63 (0.002876)\n",
      "150. feature 86 (0.002875)\n",
      "151. feature 184 (0.002873)\n",
      "152. feature 171 (0.002872)\n",
      "153. feature 186 (0.002871)\n",
      "154. feature 73 (0.002863)\n",
      "155. feature 83 (0.002860)\n",
      "156. feature 82 (0.002857)\n",
      "157. feature 79 (0.002855)\n",
      "158. feature 74 (0.002851)\n",
      "159. feature 265 (0.002850)\n",
      "160. feature 81 (0.002848)\n",
      "161. feature 234 (0.002848)\n",
      "162. feature 110 (0.002847)\n",
      "163. feature 119 (0.002847)\n",
      "164. feature 190 (0.002844)\n",
      "165. feature 238 (0.002843)\n",
      "166. feature 157 (0.002841)\n",
      "167. feature 174 (0.002841)\n",
      "168. feature 253 (0.002837)\n",
      "169. feature 64 (0.002833)\n",
      "170. feature 107 (0.002831)\n",
      "171. feature 109 (0.002828)\n",
      "172. feature 90 (0.002827)\n",
      "173. feature 221 (0.002826)\n",
      "174. feature 59 (0.002826)\n",
      "175. feature 254 (0.002825)\n",
      "176. feature 87 (0.002824)\n",
      "177. feature 88 (0.002824)\n",
      "178. feature 266 (0.002823)\n",
      "179. feature 188 (0.002823)\n",
      "180. feature 60 (0.002822)\n",
      "181. feature 118 (0.002821)\n",
      "182. feature 187 (0.002819)\n",
      "183. feature 264 (0.002817)\n",
      "184. feature 123 (0.002816)\n",
      "185. feature 185 (0.002815)\n",
      "186. feature 194 (0.002813)\n",
      "187. feature 183 (0.002809)\n",
      "188. feature 189 (0.002808)\n",
      "189. feature 193 (0.002806)\n",
      "190. feature 270 (0.002802)\n",
      "191. feature 192 (0.002800)\n",
      "192. feature 106 (0.002800)\n",
      "193. feature 191 (0.002799)\n",
      "194. feature 222 (0.002799)\n",
      "195. feature 116 (0.002798)\n",
      "196. feature 89 (0.002794)\n",
      "197. feature 121 (0.002789)\n",
      "198. feature 175 (0.002789)\n",
      "199. feature 158 (0.002787)\n",
      "200. feature 62 (0.002784)\n",
      "201. feature 252 (0.002782)\n",
      "202. feature 105 (0.002782)\n",
      "203. feature 268 (0.002779)\n",
      "204. feature 61 (0.002778)\n",
      "205. feature 124 (0.002777)\n",
      "206. feature 143 (0.002771)\n",
      "207. feature 111 (0.002768)\n",
      "208. feature 179 (0.002761)\n",
      "209. feature 125 (0.002754)\n",
      "210. feature 267 (0.002753)\n",
      "211. feature 130 (0.002752)\n",
      "212. feature 172 (0.002750)\n",
      "213. feature 173 (0.002749)\n",
      "214. feature 161 (0.002747)\n",
      "215. feature 142 (0.002746)\n",
      "216. feature 249 (0.002744)\n",
      "217. feature 122 (0.002741)\n",
      "218. feature 180 (0.002731)\n",
      "219. feature 127 (0.002730)\n",
      "220. feature 135 (0.002729)\n",
      "221. feature 178 (0.002723)\n",
      "222. feature 132 (0.002723)\n",
      "223. feature 108 (0.002722)\n",
      "224. feature 155 (0.002720)\n",
      "225. feature 115 (0.002718)\n",
      "226. feature 112 (0.002718)\n",
      "227. feature 126 (0.002715)\n",
      "228. feature 114 (0.002715)\n",
      "229. feature 181 (0.002715)\n",
      "230. feature 145 (0.002714)\n",
      "231. feature 220 (0.002713)\n",
      "232. feature 129 (0.002709)\n",
      "233. feature 217 (0.002708)\n",
      "234. feature 248 (0.002708)\n",
      "235. feature 133 (0.002704)\n",
      "236. feature 139 (0.002702)\n",
      "237. feature 113 (0.002701)\n",
      "238. feature 153 (0.002697)\n",
      "239. feature 148 (0.002695)\n",
      "240. feature 128 (0.002693)\n",
      "241. feature 162 (0.002693)\n",
      "242. feature 120 (0.002692)\n",
      "243. feature 141 (0.002692)\n",
      "244. feature 131 (0.002685)\n",
      "245. feature 159 (0.002684)\n",
      "246. feature 149 (0.002684)\n",
      "247. feature 134 (0.002683)\n",
      "248. feature 177 (0.002681)\n",
      "249. feature 152 (0.002681)\n",
      "250. feature 168 (0.002680)\n",
      "251. feature 154 (0.002679)\n",
      "252. feature 140 (0.002678)\n",
      "253. feature 250 (0.002677)\n",
      "254. feature 160 (0.002676)\n",
      "255. feature 176 (0.002675)\n",
      "256. feature 164 (0.002674)\n",
      "257. feature 166 (0.002673)\n",
      "258. feature 147 (0.002672)\n",
      "259. feature 216 (0.002671)\n",
      "260. feature 138 (0.002671)\n",
      "261. feature 163 (0.002670)\n",
      "262. feature 136 (0.002668)\n",
      "263. feature 167 (0.002667)\n",
      "264. feature 146 (0.002664)\n",
      "265. feature 165 (0.002664)\n",
      "266. feature 151 (0.002660)\n",
      "267. feature 137 (0.002656)\n",
      "268. feature 150 (0.002651)\n",
      "269. feature 218 (0.002648)\n",
      "270. feature 144 (0.002622)\n",
      "271. feature 219 (0.002612)\n",
      "272. feature 251 (0.002571)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ec88fe08af0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_ranking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-c07f6877aa11>\u001b[0m in \u001b[0;36mfeature_ranking\u001b[0;34m(indices_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "x = feature_ranking(indices_file)\n",
    "np.save(indices_file, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature_vector_test = np.load(prefix + 'Features//n_feature_vector_test_indices.npy')\n",
    "s_label_vector_test = np.load(prefix + 'Features//s_label_vector_test_indices.npy')\n",
    "\n",
    "n_feature_vector_test = np.load(prefix + 'Features//n_feature_vector_test_indices.npy')\n",
    "s_label_vector_test = np.load(prefix + 'Features//s_label_vector_test_indices.npy')\n",
    "\n",
    "train_data = np.vstack((n_feature_vector, s_feature_vector))\n",
    "train_labels = np.vstack((n_label_vector, s_label_vector))\n",
    "indices_file = indices_npy_binary_N_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feature_ranking(indices_file)\n",
    "np.save(indices_file, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "featureSet_val=np.vstack((featureSet_validation0, featureSet_validation1))\n",
    "Label_val=np.append(Label_validation0, Label_validation1, axis=0)\n",
    "\n",
    "featureSet=np.vstack((featureSet_train0, featureSet_train1))\n",
    "Label=np.append(Label_train0, Label_train1, axis=0)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
