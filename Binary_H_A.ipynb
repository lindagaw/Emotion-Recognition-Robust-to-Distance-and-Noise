{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (16632, 48, 100)\n",
      "training label: (16632, 2)\n",
      "evaluation data: (3684, 48, 100)\n",
      "evaluation label: (3684, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:192: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(48, 100), kernel_constraint=<keras.con..., filters=512, kernel_size=10)`\n",
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_constraint=<keras.con..., filters=2560, kernel_size=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 39, 512)           512512    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 39, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 19, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 19, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10, 2560)          13109760  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 10, 2560)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 5, 2560)           0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 5, 2560)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 25602     \n",
      "=================================================================\n",
      "Total params: 13,647,874\n",
      "Trainable params: 13,647,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:245: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12474 samples, validate on 4158 samples\n",
      "Epoch 1/10000\n",
      "12474/12474 [==============================] - 347s 28ms/step - loss: 0.6857 - acc: 0.5625 - val_loss: 0.6753 - val_acc: 0.6109\n",
      "Epoch 2/10000\n",
      "12474/12474 [==============================] - 341s 27ms/step - loss: 0.6714 - acc: 0.6009 - val_loss: 0.6616 - val_acc: 0.6323\n",
      "Epoch 3/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.6609 - acc: 0.6144 - val_loss: 0.6518 - val_acc: 0.6436\n",
      "Epoch 4/10000\n",
      "12474/12474 [==============================] - 330s 26ms/step - loss: 0.6516 - acc: 0.6305 - val_loss: 0.6411 - val_acc: 0.6558\n",
      "Epoch 5/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.6432 - acc: 0.6413 - val_loss: 0.6330 - val_acc: 0.6643\n",
      "Epoch 6/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.6356 - acc: 0.6526 - val_loss: 0.6257 - val_acc: 0.6700\n",
      "Epoch 7/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.6293 - acc: 0.6573 - val_loss: 0.6194 - val_acc: 0.6741\n",
      "Epoch 8/10000\n",
      "12474/12474 [==============================] - 338s 27ms/step - loss: 0.6232 - acc: 0.6653 - val_loss: 0.6177 - val_acc: 0.6708\n",
      "Epoch 9/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.6174 - acc: 0.6700 - val_loss: 0.6107 - val_acc: 0.6809\n",
      "Epoch 10/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.6122 - acc: 0.6780 - val_loss: 0.6051 - val_acc: 0.6883\n",
      "Epoch 11/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.6070 - acc: 0.6823 - val_loss: 0.6012 - val_acc: 0.6895\n",
      "Epoch 12/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.6022 - acc: 0.6885 - val_loss: 0.5981 - val_acc: 0.6922\n",
      "Epoch 13/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.5975 - acc: 0.6918 - val_loss: 0.5945 - val_acc: 0.6943\n",
      "Epoch 14/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.5936 - acc: 0.6943 - val_loss: 0.5903 - val_acc: 0.6999\n",
      "Epoch 15/10000\n",
      "12474/12474 [==============================] - 330s 26ms/step - loss: 0.5889 - acc: 0.7015 - val_loss: 0.5873 - val_acc: 0.7030\n",
      "Epoch 16/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.5864 - acc: 0.7000 - val_loss: 0.5844 - val_acc: 0.7030\n",
      "Epoch 17/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.5818 - acc: 0.7034 - val_loss: 0.5820 - val_acc: 0.7073\n",
      "Epoch 18/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.5777 - acc: 0.7088 - val_loss: 0.5813 - val_acc: 0.7071\n",
      "Epoch 19/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.5733 - acc: 0.7124 - val_loss: 0.5766 - val_acc: 0.7097\n",
      "Epoch 20/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.5710 - acc: 0.7144 - val_loss: 0.5746 - val_acc: 0.7138\n",
      "Epoch 21/10000\n",
      "12474/12474 [==============================] - 331s 27ms/step - loss: 0.5677 - acc: 0.7178 - val_loss: 0.5718 - val_acc: 0.7167\n",
      "Epoch 22/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.5635 - acc: 0.7214 - val_loss: 0.5699 - val_acc: 0.7184\n",
      "Epoch 23/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.5613 - acc: 0.7209 - val_loss: 0.5677 - val_acc: 0.7174\n",
      "Epoch 24/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.5579 - acc: 0.7278 - val_loss: 0.5673 - val_acc: 0.7181\n",
      "Epoch 25/10000\n",
      "12474/12474 [==============================] - 339s 27ms/step - loss: 0.5534 - acc: 0.7281 - val_loss: 0.5624 - val_acc: 0.7217\n",
      "Epoch 26/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.5516 - acc: 0.7304 - val_loss: 0.5607 - val_acc: 0.7229\n",
      "Epoch 27/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.5470 - acc: 0.7358 - val_loss: 0.5592 - val_acc: 0.7237\n",
      "Epoch 28/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.5445 - acc: 0.7367 - val_loss: 0.5561 - val_acc: 0.7285\n",
      "Epoch 29/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.5424 - acc: 0.7379 - val_loss: 0.5540 - val_acc: 0.7290\n",
      "Epoch 30/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.5382 - acc: 0.7408 - val_loss: 0.5541 - val_acc: 0.7278\n",
      "Epoch 31/10000\n",
      "12474/12474 [==============================] - 339s 27ms/step - loss: 0.5364 - acc: 0.7431 - val_loss: 0.5510 - val_acc: 0.7314\n",
      "Epoch 32/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.5339 - acc: 0.7451 - val_loss: 0.5487 - val_acc: 0.7376\n",
      "Epoch 33/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.5308 - acc: 0.7456 - val_loss: 0.5476 - val_acc: 0.7326\n",
      "Epoch 34/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.5277 - acc: 0.7505 - val_loss: 0.5453 - val_acc: 0.7362\n",
      "Epoch 35/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.5253 - acc: 0.7504 - val_loss: 0.5432 - val_acc: 0.7367\n",
      "Epoch 36/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.5212 - acc: 0.7535 - val_loss: 0.5416 - val_acc: 0.7395\n",
      "Epoch 37/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.5197 - acc: 0.7536 - val_loss: 0.5409 - val_acc: 0.7367\n",
      "Epoch 38/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.5173 - acc: 0.7556 - val_loss: 0.5387 - val_acc: 0.7386\n",
      "Epoch 39/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.5140 - acc: 0.7605 - val_loss: 0.5373 - val_acc: 0.7393\n",
      "Epoch 40/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.5125 - acc: 0.7605 - val_loss: 0.5352 - val_acc: 0.7422\n",
      "Epoch 41/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.5091 - acc: 0.7628 - val_loss: 0.5330 - val_acc: 0.7424\n",
      "Epoch 42/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.5071 - acc: 0.7642 - val_loss: 0.5317 - val_acc: 0.7434\n",
      "Epoch 43/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.5049 - acc: 0.7650 - val_loss: 0.5304 - val_acc: 0.7465\n",
      "Epoch 44/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.5022 - acc: 0.7676 - val_loss: 0.5283 - val_acc: 0.7443\n",
      "Epoch 45/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.4998 - acc: 0.7693 - val_loss: 0.5285 - val_acc: 0.7470\n",
      "Epoch 46/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.4973 - acc: 0.7709 - val_loss: 0.5261 - val_acc: 0.7470\n",
      "Epoch 47/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.4947 - acc: 0.7740 - val_loss: 0.5284 - val_acc: 0.7436\n",
      "Epoch 48/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.4932 - acc: 0.7729 - val_loss: 0.5333 - val_acc: 0.7415\n",
      "Epoch 49/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.4901 - acc: 0.7767 - val_loss: 0.5214 - val_acc: 0.7506\n",
      "Epoch 50/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.4871 - acc: 0.7785 - val_loss: 0.5221 - val_acc: 0.7516\n",
      "Epoch 51/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.4859 - acc: 0.7795 - val_loss: 0.5197 - val_acc: 0.7470\n",
      "Epoch 52/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.4832 - acc: 0.7777 - val_loss: 0.5167 - val_acc: 0.7552\n",
      "Epoch 53/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.4824 - acc: 0.7820 - val_loss: 0.5152 - val_acc: 0.7542\n",
      "Epoch 54/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.4782 - acc: 0.7863 - val_loss: 0.5150 - val_acc: 0.7523\n",
      "Epoch 55/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.4755 - acc: 0.7880 - val_loss: 0.5131 - val_acc: 0.7557\n",
      "Epoch 56/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.4736 - acc: 0.7902 - val_loss: 0.5119 - val_acc: 0.7549\n",
      "Epoch 57/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.4713 - acc: 0.7915 - val_loss: 0.5101 - val_acc: 0.7583\n",
      "Epoch 58/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.4689 - acc: 0.7904 - val_loss: 0.5089 - val_acc: 0.7583\n",
      "Epoch 59/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.4677 - acc: 0.7922 - val_loss: 0.5107 - val_acc: 0.7576\n",
      "Epoch 60/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.4654 - acc: 0.7952 - val_loss: 0.5062 - val_acc: 0.7609\n",
      "Epoch 61/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.4630 - acc: 0.7974 - val_loss: 0.5063 - val_acc: 0.7617\n",
      "Epoch 62/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.4605 - acc: 0.8002 - val_loss: 0.5052 - val_acc: 0.7614\n",
      "Epoch 63/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.4567 - acc: 0.8012 - val_loss: 0.5055 - val_acc: 0.7607\n",
      "Epoch 64/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.4558 - acc: 0.8021 - val_loss: 0.5054 - val_acc: 0.7561\n",
      "Epoch 65/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.4536 - acc: 0.8021 - val_loss: 0.5000 - val_acc: 0.7646\n",
      "Epoch 66/10000\n",
      "12474/12474 [==============================] - 312s 25ms/step - loss: 0.4509 - acc: 0.8025 - val_loss: 0.5002 - val_acc: 0.7631\n",
      "Epoch 67/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.4495 - acc: 0.8039 - val_loss: 0.4984 - val_acc: 0.7658\n",
      "Epoch 68/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.4476 - acc: 0.8072 - val_loss: 0.5003 - val_acc: 0.7597\n",
      "Epoch 69/10000\n",
      "12474/12474 [==============================] - 314s 25ms/step - loss: 0.4469 - acc: 0.8053 - val_loss: 0.4955 - val_acc: 0.7643\n",
      "Epoch 70/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.4435 - acc: 0.8070 - val_loss: 0.4937 - val_acc: 0.7682\n",
      "Epoch 71/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.4404 - acc: 0.8130 - val_loss: 0.4938 - val_acc: 0.7614\n",
      "Epoch 72/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.4408 - acc: 0.8114 - val_loss: 0.4916 - val_acc: 0.7696\n",
      "Epoch 73/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.4371 - acc: 0.8111 - val_loss: 0.4956 - val_acc: 0.7643\n",
      "Epoch 74/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.4348 - acc: 0.8145 - val_loss: 0.4893 - val_acc: 0.7665\n",
      "Epoch 75/10000\n",
      "12474/12474 [==============================] - 313s 25ms/step - loss: 0.4320 - acc: 0.8186 - val_loss: 0.4882 - val_acc: 0.7694\n",
      "Epoch 76/10000\n",
      "12474/12474 [==============================] - 314s 25ms/step - loss: 0.4322 - acc: 0.8138 - val_loss: 0.4878 - val_acc: 0.7689\n",
      "Epoch 77/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.4286 - acc: 0.8206 - val_loss: 0.4859 - val_acc: 0.7674\n",
      "Epoch 78/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.4280 - acc: 0.8211 - val_loss: 0.4851 - val_acc: 0.7684\n",
      "Epoch 79/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.4255 - acc: 0.8214 - val_loss: 0.4843 - val_acc: 0.7701\n",
      "Epoch 80/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.4246 - acc: 0.8203 - val_loss: 0.4829 - val_acc: 0.7715\n",
      "Epoch 81/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.4211 - acc: 0.8244 - val_loss: 0.4814 - val_acc: 0.7715\n",
      "Epoch 82/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.4206 - acc: 0.8241 - val_loss: 0.4804 - val_acc: 0.7749\n",
      "Epoch 83/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.4162 - acc: 0.8289 - val_loss: 0.4796 - val_acc: 0.7742\n",
      "Epoch 84/10000\n",
      "12474/12474 [==============================] - 358s 29ms/step - loss: 0.4147 - acc: 0.8288 - val_loss: 0.4787 - val_acc: 0.7727\n",
      "Epoch 85/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.4135 - acc: 0.8268 - val_loss: 0.4933 - val_acc: 0.7665\n",
      "Epoch 86/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.4124 - acc: 0.8270 - val_loss: 0.4778 - val_acc: 0.7751\n",
      "Epoch 87/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.4110 - acc: 0.8303 - val_loss: 0.4815 - val_acc: 0.7749\n",
      "Epoch 88/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.4099 - acc: 0.8275 - val_loss: 0.4780 - val_acc: 0.7785\n",
      "Epoch 89/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.4089 - acc: 0.8315 - val_loss: 0.4739 - val_acc: 0.7768\n",
      "Epoch 90/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.4039 - acc: 0.8312 - val_loss: 0.4739 - val_acc: 0.7773\n",
      "Epoch 91/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.4039 - acc: 0.8349 - val_loss: 0.4729 - val_acc: 0.7761\n",
      "Epoch 92/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.4005 - acc: 0.8375 - val_loss: 0.4714 - val_acc: 0.7778\n",
      "Epoch 93/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.3997 - acc: 0.8375 - val_loss: 0.4714 - val_acc: 0.7780\n",
      "Epoch 94/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.3979 - acc: 0.8358 - val_loss: 0.4694 - val_acc: 0.7787\n",
      "Epoch 95/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.3946 - acc: 0.8411 - val_loss: 0.4699 - val_acc: 0.7809\n",
      "Epoch 96/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.3922 - acc: 0.8402 - val_loss: 0.4696 - val_acc: 0.7783\n",
      "Epoch 97/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.3909 - acc: 0.8436 - val_loss: 0.4663 - val_acc: 0.7826\n",
      "Epoch 98/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.3895 - acc: 0.8446 - val_loss: 0.4663 - val_acc: 0.7831\n",
      "Epoch 99/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.3876 - acc: 0.8451 - val_loss: 0.4662 - val_acc: 0.7807\n",
      "Epoch 100/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.3861 - acc: 0.8448 - val_loss: 0.4654 - val_acc: 0.7809\n",
      "Epoch 101/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.3855 - acc: 0.8450 - val_loss: 0.4630 - val_acc: 0.7850\n",
      "Epoch 102/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.3828 - acc: 0.8446 - val_loss: 0.4623 - val_acc: 0.7838\n",
      "Epoch 103/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.3811 - acc: 0.8466 - val_loss: 0.4613 - val_acc: 0.7855\n",
      "Epoch 104/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.3814 - acc: 0.8451 - val_loss: 0.4620 - val_acc: 0.7819\n",
      "Epoch 105/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.3769 - acc: 0.8494 - val_loss: 0.4586 - val_acc: 0.7862\n",
      "Epoch 106/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.3793 - acc: 0.8469 - val_loss: 0.4584 - val_acc: 0.7857\n",
      "Epoch 107/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.3732 - acc: 0.8537 - val_loss: 0.4580 - val_acc: 0.7852\n",
      "Epoch 108/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.3727 - acc: 0.8529 - val_loss: 0.4626 - val_acc: 0.7828\n",
      "Epoch 109/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.3700 - acc: 0.8548 - val_loss: 0.4567 - val_acc: 0.7860\n",
      "Epoch 110/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.3682 - acc: 0.8589 - val_loss: 0.4561 - val_acc: 0.7867\n",
      "Epoch 111/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.3663 - acc: 0.8583 - val_loss: 0.4537 - val_acc: 0.7869\n",
      "Epoch 112/10000\n",
      "12474/12474 [==============================] - 353s 28ms/step - loss: 0.3640 - acc: 0.8615 - val_loss: 0.4551 - val_acc: 0.7857\n",
      "Epoch 113/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.3637 - acc: 0.8587 - val_loss: 0.4518 - val_acc: 0.7896\n",
      "Epoch 114/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.3599 - acc: 0.8602 - val_loss: 0.4514 - val_acc: 0.7905\n",
      "Epoch 115/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.3582 - acc: 0.8629 - val_loss: 0.4499 - val_acc: 0.7888\n",
      "Epoch 116/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.3571 - acc: 0.8611 - val_loss: 0.4503 - val_acc: 0.7888\n",
      "Epoch 117/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.3565 - acc: 0.8628 - val_loss: 0.4498 - val_acc: 0.7886\n",
      "Epoch 118/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.3554 - acc: 0.8618 - val_loss: 0.4505 - val_acc: 0.7896\n",
      "Epoch 119/10000\n",
      "12474/12474 [==============================] - 330s 26ms/step - loss: 0.3506 - acc: 0.8679 - val_loss: 0.4473 - val_acc: 0.7905\n",
      "Epoch 120/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.3500 - acc: 0.8676 - val_loss: 0.4459 - val_acc: 0.7900\n",
      "Epoch 121/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.3483 - acc: 0.8697 - val_loss: 0.4483 - val_acc: 0.7908\n",
      "Epoch 122/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.3471 - acc: 0.8685 - val_loss: 0.4448 - val_acc: 0.7920\n",
      "Epoch 123/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.3455 - acc: 0.8700 - val_loss: 0.4437 - val_acc: 0.7924\n",
      "Epoch 124/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.3436 - acc: 0.8689 - val_loss: 0.4440 - val_acc: 0.7924\n",
      "Epoch 125/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.3418 - acc: 0.8712 - val_loss: 0.4450 - val_acc: 0.7941\n",
      "Epoch 126/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.3423 - acc: 0.8739 - val_loss: 0.4444 - val_acc: 0.7924\n",
      "Epoch 127/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.3391 - acc: 0.8750 - val_loss: 0.4437 - val_acc: 0.7924\n",
      "Epoch 128/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.3370 - acc: 0.8736 - val_loss: 0.4420 - val_acc: 0.7929\n",
      "Epoch 129/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.3359 - acc: 0.8729 - val_loss: 0.4400 - val_acc: 0.7953\n",
      "Epoch 130/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.3325 - acc: 0.8769 - val_loss: 0.4384 - val_acc: 0.7946\n",
      "Epoch 131/10000\n",
      "12474/12474 [==============================] - 349s 28ms/step - loss: 0.3343 - acc: 0.8769 - val_loss: 0.4394 - val_acc: 0.7937\n",
      "Epoch 132/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.3322 - acc: 0.8758 - val_loss: 0.4375 - val_acc: 0.7944\n",
      "Epoch 133/10000\n",
      "12474/12474 [==============================] - 358s 29ms/step - loss: 0.3309 - acc: 0.8780 - val_loss: 0.4356 - val_acc: 0.7937\n",
      "Epoch 134/10000\n",
      "12474/12474 [==============================] - 348s 28ms/step - loss: 0.3260 - acc: 0.8812 - val_loss: 0.4369 - val_acc: 0.7975\n",
      "Epoch 135/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.3243 - acc: 0.8816 - val_loss: 0.4346 - val_acc: 0.7980\n",
      "Epoch 136/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.3249 - acc: 0.8795 - val_loss: 0.4339 - val_acc: 0.7970\n",
      "Epoch 137/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.3274 - acc: 0.8775 - val_loss: 0.4352 - val_acc: 0.7973\n",
      "Epoch 138/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.3207 - acc: 0.8847 - val_loss: 0.4324 - val_acc: 0.7975\n",
      "Epoch 139/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.3198 - acc: 0.8829 - val_loss: 0.4314 - val_acc: 0.7973\n",
      "Epoch 140/10000\n",
      "12474/12474 [==============================] - 353s 28ms/step - loss: 0.3164 - acc: 0.8843 - val_loss: 0.4336 - val_acc: 0.7975\n",
      "Epoch 141/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.3159 - acc: 0.8868 - val_loss: 0.4358 - val_acc: 0.7961\n",
      "Epoch 142/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.3152 - acc: 0.8869 - val_loss: 0.4305 - val_acc: 0.7982\n",
      "Epoch 143/10000\n",
      "12474/12474 [==============================] - 341s 27ms/step - loss: 0.3155 - acc: 0.8847 - val_loss: 0.4294 - val_acc: 0.8001\n",
      "Epoch 144/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.3091 - acc: 0.8878 - val_loss: 0.4296 - val_acc: 0.7980\n",
      "Epoch 145/10000\n",
      "12474/12474 [==============================] - 346s 28ms/step - loss: 0.3111 - acc: 0.8885 - val_loss: 0.4282 - val_acc: 0.8023\n",
      "Epoch 146/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.3085 - acc: 0.8886 - val_loss: 0.4270 - val_acc: 0.7999\n",
      "Epoch 147/10000\n",
      "12474/12474 [==============================] - 331s 27ms/step - loss: 0.3045 - acc: 0.8917 - val_loss: 0.4259 - val_acc: 0.7987\n",
      "Epoch 148/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.3064 - acc: 0.8898 - val_loss: 0.4249 - val_acc: 0.8016\n",
      "Epoch 149/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.3050 - acc: 0.8891 - val_loss: 0.4245 - val_acc: 0.8035\n",
      "Epoch 150/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.3018 - acc: 0.8934 - val_loss: 0.4254 - val_acc: 0.7994\n",
      "Epoch 151/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.3028 - acc: 0.8935 - val_loss: 0.4227 - val_acc: 0.8011\n",
      "Epoch 152/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.2992 - acc: 0.8938 - val_loss: 0.4240 - val_acc: 0.8033\n",
      "Epoch 153/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.2971 - acc: 0.8951 - val_loss: 0.4217 - val_acc: 0.8042\n",
      "Epoch 154/10000\n",
      "12474/12474 [==============================] - 331s 27ms/step - loss: 0.2941 - acc: 0.8962 - val_loss: 0.4222 - val_acc: 0.7997\n",
      "Epoch 155/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2949 - acc: 0.8980 - val_loss: 0.4202 - val_acc: 0.8040\n",
      "Epoch 156/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.2911 - acc: 0.8995 - val_loss: 0.4194 - val_acc: 0.8030\n",
      "Epoch 157/10000\n",
      "12474/12474 [==============================] - 330s 26ms/step - loss: 0.2915 - acc: 0.8988 - val_loss: 0.4281 - val_acc: 0.8042\n",
      "Epoch 158/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2911 - acc: 0.8954 - val_loss: 0.4181 - val_acc: 0.8059\n",
      "Epoch 159/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2885 - acc: 0.9004 - val_loss: 0.4306 - val_acc: 0.8028\n",
      "Epoch 160/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2865 - acc: 0.9000 - val_loss: 0.4172 - val_acc: 0.8023\n",
      "Epoch 161/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.2852 - acc: 0.9018 - val_loss: 0.4168 - val_acc: 0.8025\n",
      "Epoch 162/10000\n",
      "12474/12474 [==============================] - 331s 27ms/step - loss: 0.2852 - acc: 0.9022 - val_loss: 0.4150 - val_acc: 0.8052\n",
      "Epoch 163/10000\n",
      "12474/12474 [==============================] - 351s 28ms/step - loss: 0.2825 - acc: 0.9040 - val_loss: 0.4157 - val_acc: 0.8062\n",
      "Epoch 164/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.2814 - acc: 0.9042 - val_loss: 0.4148 - val_acc: 0.8047\n",
      "Epoch 165/10000\n",
      "12474/12474 [==============================] - 331s 27ms/step - loss: 0.2793 - acc: 0.9078 - val_loss: 0.4152 - val_acc: 0.8057\n",
      "Epoch 166/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.2775 - acc: 0.9052 - val_loss: 0.4146 - val_acc: 0.8098\n",
      "Epoch 167/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2786 - acc: 0.9043 - val_loss: 0.4120 - val_acc: 0.8062\n",
      "Epoch 168/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2752 - acc: 0.9084 - val_loss: 0.4130 - val_acc: 0.8100\n",
      "Epoch 169/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.2749 - acc: 0.9072 - val_loss: 0.4140 - val_acc: 0.8105\n",
      "Epoch 170/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2735 - acc: 0.9067 - val_loss: 0.4105 - val_acc: 0.8098\n",
      "Epoch 171/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2706 - acc: 0.9092 - val_loss: 0.4104 - val_acc: 0.8093\n",
      "Epoch 172/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2676 - acc: 0.9133 - val_loss: 0.4114 - val_acc: 0.8110\n",
      "Epoch 173/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.2677 - acc: 0.9097 - val_loss: 0.4101 - val_acc: 0.8071\n",
      "Epoch 174/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.2664 - acc: 0.9118 - val_loss: 0.4091 - val_acc: 0.8081\n",
      "Epoch 175/10000\n",
      "12474/12474 [==============================] - 345s 28ms/step - loss: 0.2650 - acc: 0.9155 - val_loss: 0.4085 - val_acc: 0.8090\n",
      "Epoch 176/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.2634 - acc: 0.9129 - val_loss: 0.4131 - val_acc: 0.8093\n",
      "Epoch 177/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.2637 - acc: 0.9145 - val_loss: 0.4068 - val_acc: 0.8114\n",
      "Epoch 178/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2611 - acc: 0.9139 - val_loss: 0.4094 - val_acc: 0.8127\n",
      "Epoch 179/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2596 - acc: 0.9155 - val_loss: 0.4057 - val_acc: 0.8112\n",
      "Epoch 180/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2578 - acc: 0.9147 - val_loss: 0.4042 - val_acc: 0.8093\n",
      "Epoch 181/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2548 - acc: 0.9183 - val_loss: 0.4036 - val_acc: 0.8131\n",
      "Epoch 182/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2560 - acc: 0.9171 - val_loss: 0.4148 - val_acc: 0.8081\n",
      "Epoch 183/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2534 - acc: 0.9178 - val_loss: 0.4019 - val_acc: 0.8139\n",
      "Epoch 184/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2508 - acc: 0.9205 - val_loss: 0.4022 - val_acc: 0.8139\n",
      "Epoch 185/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.2499 - acc: 0.9203 - val_loss: 0.4012 - val_acc: 0.8143\n",
      "Epoch 186/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2489 - acc: 0.9218 - val_loss: 0.4018 - val_acc: 0.8148\n",
      "Epoch 187/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2482 - acc: 0.9197 - val_loss: 0.3999 - val_acc: 0.8177\n",
      "Epoch 188/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.2458 - acc: 0.9230 - val_loss: 0.4013 - val_acc: 0.8179\n",
      "Epoch 189/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.2442 - acc: 0.9234 - val_loss: 0.4019 - val_acc: 0.8175\n",
      "Epoch 190/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.2450 - acc: 0.9199 - val_loss: 0.4026 - val_acc: 0.8163\n",
      "Epoch 191/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.2452 - acc: 0.9197 - val_loss: 0.3976 - val_acc: 0.8131\n",
      "Epoch 192/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2427 - acc: 0.9222 - val_loss: 0.4010 - val_acc: 0.8189\n",
      "Epoch 193/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2412 - acc: 0.9258 - val_loss: 0.4003 - val_acc: 0.8187\n",
      "Epoch 194/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2380 - acc: 0.9254 - val_loss: 0.3971 - val_acc: 0.8175\n",
      "Epoch 195/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2384 - acc: 0.9251 - val_loss: 0.3964 - val_acc: 0.8196\n",
      "Epoch 196/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2366 - acc: 0.9254 - val_loss: 0.3946 - val_acc: 0.8194\n",
      "Epoch 197/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2349 - acc: 0.9292 - val_loss: 0.3942 - val_acc: 0.8194\n",
      "Epoch 198/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.2319 - acc: 0.9291 - val_loss: 0.3951 - val_acc: 0.8184\n",
      "Epoch 199/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.2320 - acc: 0.9294 - val_loss: 0.3950 - val_acc: 0.8155\n",
      "Epoch 200/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2302 - acc: 0.9298 - val_loss: 0.3932 - val_acc: 0.8179\n",
      "Epoch 201/10000\n",
      "12474/12474 [==============================] - 327s 26ms/step - loss: 0.2305 - acc: 0.9295 - val_loss: 0.3929 - val_acc: 0.8187\n",
      "Epoch 202/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2280 - acc: 0.9311 - val_loss: 0.3926 - val_acc: 0.8184\n",
      "Epoch 203/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.2266 - acc: 0.9321 - val_loss: 0.3928 - val_acc: 0.8220\n",
      "Epoch 204/10000\n",
      "12474/12474 [==============================] - 331s 27ms/step - loss: 0.2275 - acc: 0.9295 - val_loss: 0.3930 - val_acc: 0.8177\n",
      "Epoch 205/10000\n",
      "12474/12474 [==============================] - 338s 27ms/step - loss: 0.2269 - acc: 0.9296 - val_loss: 0.3906 - val_acc: 0.8235\n",
      "Epoch 206/10000\n",
      "12474/12474 [==============================] - 330s 26ms/step - loss: 0.2258 - acc: 0.9338 - val_loss: 0.3890 - val_acc: 0.8208\n",
      "Epoch 207/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.2209 - acc: 0.9362 - val_loss: 0.3922 - val_acc: 0.8254\n",
      "Epoch 208/10000\n",
      "12474/12474 [==============================] - 329s 26ms/step - loss: 0.2205 - acc: 0.9339 - val_loss: 0.3890 - val_acc: 0.8213\n",
      "Epoch 209/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2190 - acc: 0.9369 - val_loss: 0.3982 - val_acc: 0.8218\n",
      "Epoch 210/10000\n",
      "12474/12474 [==============================] - 330s 26ms/step - loss: 0.2189 - acc: 0.9347 - val_loss: 0.3876 - val_acc: 0.8249\n",
      "Epoch 211/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2182 - acc: 0.9354 - val_loss: 0.3868 - val_acc: 0.8223\n",
      "Epoch 212/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.2170 - acc: 0.9357 - val_loss: 0.3865 - val_acc: 0.8223\n",
      "Epoch 213/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.2151 - acc: 0.9351 - val_loss: 0.3866 - val_acc: 0.8223\n",
      "Epoch 214/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.2129 - acc: 0.9398 - val_loss: 0.3857 - val_acc: 0.8244\n",
      "Epoch 215/10000\n",
      "12474/12474 [==============================] - 328s 26ms/step - loss: 0.2124 - acc: 0.9388 - val_loss: 0.3930 - val_acc: 0.8249\n",
      "Epoch 216/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2122 - acc: 0.9392 - val_loss: 0.3852 - val_acc: 0.8225\n",
      "Epoch 217/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.2113 - acc: 0.9374 - val_loss: 0.3850 - val_acc: 0.8244\n",
      "Epoch 218/10000\n",
      "12474/12474 [==============================] - 348s 28ms/step - loss: 0.2097 - acc: 0.9372 - val_loss: 0.3885 - val_acc: 0.8264\n",
      "Epoch 219/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.2061 - acc: 0.9420 - val_loss: 0.3847 - val_acc: 0.8259\n",
      "Epoch 220/10000\n",
      "12474/12474 [==============================] - 340s 27ms/step - loss: 0.2040 - acc: 0.9440 - val_loss: 0.3824 - val_acc: 0.8256\n",
      "Epoch 221/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2048 - acc: 0.9425 - val_loss: 0.3844 - val_acc: 0.8261\n",
      "Epoch 222/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.2043 - acc: 0.9410 - val_loss: 0.3864 - val_acc: 0.8278\n",
      "Epoch 223/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.2051 - acc: 0.9407 - val_loss: 0.3810 - val_acc: 0.8254\n",
      "Epoch 224/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.1999 - acc: 0.9458 - val_loss: 0.3809 - val_acc: 0.8249\n",
      "Epoch 225/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.2015 - acc: 0.9426 - val_loss: 0.3827 - val_acc: 0.8278\n",
      "Epoch 226/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.1984 - acc: 0.9454 - val_loss: 0.3799 - val_acc: 0.8276\n",
      "Epoch 227/10000\n",
      "12474/12474 [==============================] - 369s 30ms/step - loss: 0.1986 - acc: 0.9470 - val_loss: 0.3806 - val_acc: 0.8278\n",
      "Epoch 228/10000\n",
      "12474/12474 [==============================] - 392s 31ms/step - loss: 0.1981 - acc: 0.9440 - val_loss: 0.3822 - val_acc: 0.8249\n",
      "Epoch 229/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 396s 32ms/step - loss: 0.1957 - acc: 0.9480 - val_loss: 0.3786 - val_acc: 0.8264\n",
      "Epoch 230/10000\n",
      "12474/12474 [==============================] - 371s 30ms/step - loss: 0.1957 - acc: 0.9457 - val_loss: 0.3773 - val_acc: 0.8290\n",
      "Epoch 231/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.1929 - acc: 0.9460 - val_loss: 0.3790 - val_acc: 0.8283\n",
      "Epoch 232/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.1953 - acc: 0.9459 - val_loss: 0.3782 - val_acc: 0.8314\n",
      "Epoch 233/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.1915 - acc: 0.9468 - val_loss: 0.3798 - val_acc: 0.8276\n",
      "Epoch 234/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.1889 - acc: 0.9488 - val_loss: 0.3763 - val_acc: 0.8309\n",
      "Epoch 235/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.1891 - acc: 0.9491 - val_loss: 0.3758 - val_acc: 0.8300\n",
      "Epoch 236/10000\n",
      "12474/12474 [==============================] - 340s 27ms/step - loss: 0.1886 - acc: 0.9497 - val_loss: 0.3769 - val_acc: 0.8288\n",
      "Epoch 237/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.1862 - acc: 0.9505 - val_loss: 0.3758 - val_acc: 0.8312\n",
      "Epoch 238/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.1879 - acc: 0.9485 - val_loss: 0.3757 - val_acc: 0.8307\n",
      "Epoch 239/10000\n",
      "12474/12474 [==============================] - 338s 27ms/step - loss: 0.1846 - acc: 0.9504 - val_loss: 0.3753 - val_acc: 0.8292\n",
      "Epoch 240/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.1817 - acc: 0.9531 - val_loss: 0.3748 - val_acc: 0.8319\n",
      "Epoch 241/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.1834 - acc: 0.9530 - val_loss: 0.3744 - val_acc: 0.8309\n",
      "Epoch 242/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.1809 - acc: 0.9511 - val_loss: 0.3731 - val_acc: 0.8321\n",
      "Epoch 243/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.1824 - acc: 0.9533 - val_loss: 0.3751 - val_acc: 0.8329\n",
      "Epoch 244/10000\n",
      "12474/12474 [==============================] - 337s 27ms/step - loss: 0.1796 - acc: 0.9529 - val_loss: 0.3744 - val_acc: 0.8331\n",
      "Epoch 245/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.1805 - acc: 0.9527 - val_loss: 0.3806 - val_acc: 0.8309\n",
      "Epoch 246/10000\n",
      "12474/12474 [==============================] - 338s 27ms/step - loss: 0.1779 - acc: 0.9548 - val_loss: 0.3724 - val_acc: 0.8338\n",
      "Epoch 247/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.1782 - acc: 0.9558 - val_loss: 0.3718 - val_acc: 0.8343\n",
      "Epoch 248/10000\n",
      "12474/12474 [==============================] - 338s 27ms/step - loss: 0.1746 - acc: 0.9538 - val_loss: 0.3788 - val_acc: 0.8324\n",
      "Epoch 249/10000\n",
      "12474/12474 [==============================] - 335s 27ms/step - loss: 0.1735 - acc: 0.9574 - val_loss: 0.3721 - val_acc: 0.8343\n",
      "Epoch 250/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.1730 - acc: 0.9578 - val_loss: 0.3707 - val_acc: 0.8348\n",
      "Epoch 251/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.1712 - acc: 0.9568 - val_loss: 0.3709 - val_acc: 0.8348\n",
      "Epoch 252/10000\n",
      "12474/12474 [==============================] - 339s 27ms/step - loss: 0.1720 - acc: 0.9576 - val_loss: 0.3703 - val_acc: 0.8348\n",
      "Epoch 253/10000\n",
      "12474/12474 [==============================] - 339s 27ms/step - loss: 0.1710 - acc: 0.9568 - val_loss: 0.3700 - val_acc: 0.8355\n",
      "Epoch 254/10000\n",
      "12474/12474 [==============================] - 333s 27ms/step - loss: 0.1725 - acc: 0.9549 - val_loss: 0.3685 - val_acc: 0.8360\n",
      "Epoch 255/10000\n",
      "12474/12474 [==============================] - 338s 27ms/step - loss: 0.1681 - acc: 0.9590 - val_loss: 0.3689 - val_acc: 0.8362\n",
      "Epoch 256/10000\n",
      "12474/12474 [==============================] - 341s 27ms/step - loss: 0.1708 - acc: 0.9567 - val_loss: 0.3737 - val_acc: 0.8357\n",
      "Epoch 257/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1672 - acc: 0.9591 - val_loss: 0.3672 - val_acc: 0.8348\n",
      "Epoch 258/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1652 - acc: 0.9598 - val_loss: 0.3685 - val_acc: 0.8365\n",
      "Epoch 259/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.1632 - acc: 0.9625 - val_loss: 0.3760 - val_acc: 0.8316\n",
      "Epoch 260/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.1645 - acc: 0.9594 - val_loss: 0.3718 - val_acc: 0.8362\n",
      "Epoch 261/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1641 - acc: 0.9594 - val_loss: 0.3656 - val_acc: 0.8384\n",
      "Epoch 262/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1639 - acc: 0.9607 - val_loss: 0.3658 - val_acc: 0.8372\n",
      "Epoch 263/10000\n",
      "12474/12474 [==============================] - 332s 27ms/step - loss: 0.1597 - acc: 0.9618 - val_loss: 0.3697 - val_acc: 0.8372\n",
      "Epoch 264/10000\n",
      "12474/12474 [==============================] - 334s 27ms/step - loss: 0.1601 - acc: 0.9614 - val_loss: 0.3654 - val_acc: 0.8374\n",
      "Epoch 265/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1576 - acc: 0.9627 - val_loss: 0.3663 - val_acc: 0.8389\n",
      "Epoch 266/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1590 - acc: 0.9623 - val_loss: 0.3761 - val_acc: 0.8331\n",
      "Epoch 267/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.1581 - acc: 0.9620 - val_loss: 0.3643 - val_acc: 0.8360\n",
      "Epoch 268/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.1562 - acc: 0.9634 - val_loss: 0.3640 - val_acc: 0.8386\n",
      "Epoch 269/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1568 - acc: 0.9626 - val_loss: 0.3640 - val_acc: 0.8405\n",
      "Epoch 270/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1561 - acc: 0.9614 - val_loss: 0.3629 - val_acc: 0.8393\n",
      "Epoch 271/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.1519 - acc: 0.9640 - val_loss: 0.3636 - val_acc: 0.8393\n",
      "Epoch 272/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1541 - acc: 0.9647 - val_loss: 0.3660 - val_acc: 0.8379\n",
      "Epoch 273/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1514 - acc: 0.9652 - val_loss: 0.3614 - val_acc: 0.8389\n",
      "Epoch 274/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1513 - acc: 0.9644 - val_loss: 0.3628 - val_acc: 0.8410\n",
      "Epoch 275/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1493 - acc: 0.9675 - val_loss: 0.3613 - val_acc: 0.8413\n",
      "Epoch 276/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.1502 - acc: 0.9640 - val_loss: 0.3622 - val_acc: 0.8398\n",
      "Epoch 277/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1468 - acc: 0.9683 - val_loss: 0.3620 - val_acc: 0.8425\n",
      "Epoch 278/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1486 - acc: 0.9659 - val_loss: 0.3608 - val_acc: 0.8398\n",
      "Epoch 279/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1470 - acc: 0.9679 - val_loss: 0.3606 - val_acc: 0.8403\n",
      "Epoch 280/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1471 - acc: 0.9667 - val_loss: 0.3597 - val_acc: 0.8413\n",
      "Epoch 281/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.1454 - acc: 0.9691 - val_loss: 0.3649 - val_acc: 0.8377\n",
      "Epoch 282/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1450 - acc: 0.9681 - val_loss: 0.3585 - val_acc: 0.8425\n",
      "Epoch 283/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1419 - acc: 0.9679 - val_loss: 0.3591 - val_acc: 0.8422\n",
      "Epoch 284/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1422 - acc: 0.9703 - val_loss: 0.3589 - val_acc: 0.8408\n",
      "Epoch 285/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.1439 - acc: 0.9667 - val_loss: 0.3589 - val_acc: 0.8427\n",
      "Epoch 286/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1405 - acc: 0.9688 - val_loss: 0.3587 - val_acc: 0.8398\n",
      "Epoch 287/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1407 - acc: 0.9697 - val_loss: 0.3591 - val_acc: 0.8425\n",
      "Epoch 288/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1397 - acc: 0.9695 - val_loss: 0.3577 - val_acc: 0.8418\n",
      "Epoch 289/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1391 - acc: 0.9697 - val_loss: 0.3569 - val_acc: 0.8442\n",
      "Epoch 290/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1354 - acc: 0.9719 - val_loss: 0.3577 - val_acc: 0.8444\n",
      "Epoch 291/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1346 - acc: 0.9710 - val_loss: 0.3567 - val_acc: 0.8430\n",
      "Epoch 292/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.1371 - acc: 0.9698 - val_loss: 0.3567 - val_acc: 0.8451\n",
      "Epoch 293/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1348 - acc: 0.9728 - val_loss: 0.3560 - val_acc: 0.8437\n",
      "Epoch 294/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1340 - acc: 0.9710 - val_loss: 0.3556 - val_acc: 0.8446\n",
      "Epoch 295/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.1320 - acc: 0.9727 - val_loss: 0.3549 - val_acc: 0.8439\n",
      "Epoch 296/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1320 - acc: 0.9727 - val_loss: 0.3552 - val_acc: 0.8432\n",
      "Epoch 297/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.1338 - acc: 0.9708 - val_loss: 0.3547 - val_acc: 0.8439\n",
      "Epoch 298/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1306 - acc: 0.9738 - val_loss: 0.3603 - val_acc: 0.8437\n",
      "Epoch 299/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1305 - acc: 0.9721 - val_loss: 0.3544 - val_acc: 0.8451\n",
      "Epoch 300/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1301 - acc: 0.9741 - val_loss: 0.3578 - val_acc: 0.8434\n",
      "Epoch 301/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1293 - acc: 0.9754 - val_loss: 0.3557 - val_acc: 0.8449\n",
      "Epoch 302/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1299 - acc: 0.9743 - val_loss: 0.3556 - val_acc: 0.8439\n",
      "Epoch 303/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1280 - acc: 0.9757 - val_loss: 0.3537 - val_acc: 0.8456\n",
      "Epoch 304/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.1253 - acc: 0.9751 - val_loss: 0.3542 - val_acc: 0.8432\n",
      "Epoch 305/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1264 - acc: 0.9745 - val_loss: 0.3554 - val_acc: 0.8449\n",
      "Epoch 306/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.1272 - acc: 0.9732 - val_loss: 0.3527 - val_acc: 0.8461\n",
      "Epoch 307/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1236 - acc: 0.9776 - val_loss: 0.3557 - val_acc: 0.8454\n",
      "Epoch 308/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1209 - acc: 0.9780 - val_loss: 0.3535 - val_acc: 0.8446\n",
      "Epoch 309/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1230 - acc: 0.9775 - val_loss: 0.3589 - val_acc: 0.8444\n",
      "Epoch 310/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.1204 - acc: 0.9780 - val_loss: 0.3525 - val_acc: 0.8466\n",
      "Epoch 311/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.1212 - acc: 0.9760 - val_loss: 0.3598 - val_acc: 0.8425\n",
      "Epoch 312/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1211 - acc: 0.9773 - val_loss: 0.3518 - val_acc: 0.8463\n",
      "Epoch 313/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1199 - acc: 0.9777 - val_loss: 0.3512 - val_acc: 0.8466\n",
      "Epoch 314/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1179 - acc: 0.9783 - val_loss: 0.3524 - val_acc: 0.8451\n",
      "Epoch 315/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.1180 - acc: 0.9784 - val_loss: 0.3505 - val_acc: 0.8482\n",
      "Epoch 316/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.1192 - acc: 0.9789 - val_loss: 0.3520 - val_acc: 0.8473\n",
      "Epoch 317/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1180 - acc: 0.9768 - val_loss: 0.3529 - val_acc: 0.8458\n",
      "Epoch 318/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1158 - acc: 0.9784 - val_loss: 0.3505 - val_acc: 0.8461\n",
      "Epoch 319/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1155 - acc: 0.9792 - val_loss: 0.3507 - val_acc: 0.8487\n",
      "Epoch 320/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1164 - acc: 0.9781 - val_loss: 0.3497 - val_acc: 0.8480\n",
      "Epoch 321/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.1176 - acc: 0.9759 - val_loss: 0.3577 - val_acc: 0.8468\n",
      "Epoch 322/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1126 - acc: 0.9816 - val_loss: 0.3508 - val_acc: 0.8454\n",
      "Epoch 323/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1144 - acc: 0.9795 - val_loss: 0.3504 - val_acc: 0.8492\n",
      "Epoch 324/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1135 - acc: 0.9794 - val_loss: 0.3528 - val_acc: 0.8468\n",
      "Epoch 325/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1109 - acc: 0.9809 - val_loss: 0.3482 - val_acc: 0.8466\n",
      "Epoch 326/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.1126 - acc: 0.9776 - val_loss: 0.3497 - val_acc: 0.8482\n",
      "Epoch 327/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1108 - acc: 0.9806 - val_loss: 0.3514 - val_acc: 0.8473\n",
      "Epoch 328/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1100 - acc: 0.9803 - val_loss: 0.3497 - val_acc: 0.8492\n",
      "Epoch 329/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1081 - acc: 0.9815 - val_loss: 0.3480 - val_acc: 0.8492\n",
      "Epoch 330/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1103 - acc: 0.9806 - val_loss: 0.3620 - val_acc: 0.8458\n",
      "Epoch 331/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1086 - acc: 0.9830 - val_loss: 0.3471 - val_acc: 0.8485\n",
      "Epoch 332/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.1090 - acc: 0.9817 - val_loss: 0.3511 - val_acc: 0.8427\n",
      "Epoch 333/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1071 - acc: 0.9812 - val_loss: 0.3486 - val_acc: 0.8519\n",
      "Epoch 334/10000\n",
      "12474/12474 [==============================] - 318s 26ms/step - loss: 0.1072 - acc: 0.9814 - val_loss: 0.3488 - val_acc: 0.8473\n",
      "Epoch 335/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1070 - acc: 0.9810 - val_loss: 0.3457 - val_acc: 0.8499\n",
      "Epoch 336/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.1039 - acc: 0.9830 - val_loss: 0.3475 - val_acc: 0.8499\n",
      "Epoch 337/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1054 - acc: 0.9830 - val_loss: 0.3455 - val_acc: 0.8514\n",
      "Epoch 338/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.1030 - acc: 0.9829 - val_loss: 0.3461 - val_acc: 0.8511\n",
      "Epoch 339/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1036 - acc: 0.9843 - val_loss: 0.3455 - val_acc: 0.8511\n",
      "Epoch 340/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.1029 - acc: 0.9826 - val_loss: 0.3461 - val_acc: 0.8511\n",
      "Epoch 341/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.1035 - acc: 0.9817 - val_loss: 0.3478 - val_acc: 0.8504\n",
      "Epoch 342/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.1026 - acc: 0.9830 - val_loss: 0.3456 - val_acc: 0.8511\n",
      "Epoch 343/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.1024 - acc: 0.9843 - val_loss: 0.3473 - val_acc: 0.8502\n",
      "Epoch 344/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.1020 - acc: 0.9829 - val_loss: 0.3440 - val_acc: 0.8528\n",
      "Epoch 345/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.1000 - acc: 0.9853 - val_loss: 0.3444 - val_acc: 0.8511\n",
      "Epoch 346/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.0992 - acc: 0.9848 - val_loss: 0.3442 - val_acc: 0.8514\n",
      "Epoch 347/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.1022 - acc: 0.9804 - val_loss: 0.3437 - val_acc: 0.8523\n",
      "Epoch 348/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.0986 - acc: 0.9844 - val_loss: 0.3447 - val_acc: 0.8523\n",
      "Epoch 349/10000\n",
      "12474/12474 [==============================] - 316s 25ms/step - loss: 0.0969 - acc: 0.9837 - val_loss: 0.3558 - val_acc: 0.8413\n",
      "Epoch 350/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.0996 - acc: 0.9839 - val_loss: 0.3432 - val_acc: 0.8535\n",
      "Epoch 351/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.0954 - acc: 0.9844 - val_loss: 0.3434 - val_acc: 0.8521\n",
      "Epoch 352/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.0943 - acc: 0.9867 - val_loss: 0.3446 - val_acc: 0.8511\n",
      "Epoch 353/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.0957 - acc: 0.9847 - val_loss: 0.3443 - val_acc: 0.8533\n",
      "Epoch 354/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0977 - acc: 0.9836 - val_loss: 0.3435 - val_acc: 0.8511\n",
      "Epoch 355/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0942 - acc: 0.9853 - val_loss: 0.3470 - val_acc: 0.8514\n",
      "Epoch 356/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.0938 - acc: 0.9867 - val_loss: 0.3425 - val_acc: 0.8528\n",
      "Epoch 357/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0935 - acc: 0.9854 - val_loss: 0.3429 - val_acc: 0.8535\n",
      "Epoch 358/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.0940 - acc: 0.9853 - val_loss: 0.3425 - val_acc: 0.8543\n",
      "Epoch 359/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.0932 - acc: 0.9869 - val_loss: 0.3466 - val_acc: 0.8540\n",
      "Epoch 360/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.0933 - acc: 0.9861 - val_loss: 0.3418 - val_acc: 0.8533\n",
      "Epoch 361/10000\n",
      "12474/12474 [==============================] - 317s 25ms/step - loss: 0.0934 - acc: 0.9852 - val_loss: 0.3459 - val_acc: 0.8494\n",
      "Epoch 362/10000\n",
      "12474/12474 [==============================] - 315s 25ms/step - loss: 0.0897 - acc: 0.9877 - val_loss: 0.3417 - val_acc: 0.8535\n",
      "Epoch 363/10000\n",
      "12474/12474 [==============================] - 318s 25ms/step - loss: 0.0907 - acc: 0.9863 - val_loss: 0.3427 - val_acc: 0.8521\n",
      "Epoch 364/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0897 - acc: 0.9867 - val_loss: 0.3422 - val_acc: 0.8545\n",
      "Epoch 365/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.0895 - acc: 0.9873 - val_loss: 0.3484 - val_acc: 0.8538\n",
      "Epoch 366/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0905 - acc: 0.9865 - val_loss: 0.3416 - val_acc: 0.8528\n",
      "Epoch 367/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.0883 - acc: 0.9867 - val_loss: 0.3423 - val_acc: 0.8545\n",
      "Epoch 368/10000\n",
      "12474/12474 [==============================] - 321s 26ms/step - loss: 0.0895 - acc: 0.9859 - val_loss: 0.3452 - val_acc: 0.8533\n",
      "Epoch 369/10000\n",
      "12474/12474 [==============================] - 326s 26ms/step - loss: 0.0894 - acc: 0.9870 - val_loss: 0.3418 - val_acc: 0.8533\n",
      "Epoch 370/10000\n",
      "12474/12474 [==============================] - 336s 27ms/step - loss: 0.0884 - acc: 0.9870 - val_loss: 0.3409 - val_acc: 0.8540\n",
      "Epoch 371/10000\n",
      "12474/12474 [==============================] - 344s 28ms/step - loss: 0.0865 - acc: 0.9869 - val_loss: 0.3416 - val_acc: 0.8540\n",
      "Epoch 372/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0863 - acc: 0.9883 - val_loss: 0.3430 - val_acc: 0.8535\n",
      "Epoch 373/10000\n",
      "12474/12474 [==============================] - 325s 26ms/step - loss: 0.0854 - acc: 0.9887 - val_loss: 0.3411 - val_acc: 0.8528\n",
      "Epoch 374/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.0850 - acc: 0.9893 - val_loss: 0.3422 - val_acc: 0.8547\n",
      "Epoch 375/10000\n",
      "12474/12474 [==============================] - 320s 26ms/step - loss: 0.0838 - acc: 0.9894 - val_loss: 0.3404 - val_acc: 0.8540\n",
      "Epoch 376/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.0851 - acc: 0.9873 - val_loss: 0.3410 - val_acc: 0.8559\n",
      "Epoch 377/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.0834 - acc: 0.9887 - val_loss: 0.3406 - val_acc: 0.8540\n",
      "Epoch 378/10000\n",
      "12474/12474 [==============================] - 323s 26ms/step - loss: 0.0839 - acc: 0.9873 - val_loss: 0.3422 - val_acc: 0.8533\n",
      "Epoch 379/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0824 - acc: 0.9897 - val_loss: 0.3392 - val_acc: 0.8569\n",
      "Epoch 380/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.0830 - acc: 0.9889 - val_loss: 0.3390 - val_acc: 0.8555\n",
      "Epoch 381/10000\n",
      "12474/12474 [==============================] - 324s 26ms/step - loss: 0.0806 - acc: 0.9913 - val_loss: 0.3444 - val_acc: 0.8521\n",
      "Epoch 382/10000\n",
      "12474/12474 [==============================] - 322s 26ms/step - loss: 0.0821 - acc: 0.9889 - val_loss: 0.3418 - val_acc: 0.8528\n",
      "Epoch 383/10000\n",
      "12474/12474 [==============================] - 319s 26ms/step - loss: 0.0816 - acc: 0.9892 - val_loss: 0.3426 - val_acc: 0.8569\n",
      "Epoch 384/10000\n",
      "  896/12474 [=>............................] - ETA: 5:18 - loss: 0.0791 - acc: 0.9888"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "# print(len(backend.tensorflow_backend._get_available_gpus()) > 0)\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "sample_rate = 44100\n",
    "frame_number = 48\n",
    "hop_length = 441  # frame size= 2 * hop\n",
    "segment_length = int(sample_rate * 0.2)  # 0.2\n",
    "segment_pad = int(sample_rate * 0.02)     # 0.02\n",
    "overlapping = int(sample_rate * 0.1)   # 0.1\n",
    "\n",
    "classes = 2\n",
    "NumofFeaturetoUse = 100\n",
    "n_neurons = 4096\n",
    "dense_layers = 1\n",
    "num_layers = 2\n",
    "fillength = 10\n",
    "nbindex = 512\n",
    "dropout = 0.1\n",
    "n_batch = 128\n",
    "n_epoch = 10000\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "prefix = '..//'\n",
    "h_feature_vector = np.load(prefix + 'Features//h_feature_vector_48.npy')\n",
    "h_label_vector = np.load(prefix + 'Features//h_label_vector_48.npy')\n",
    "a_feature_vector = np.load(prefix + 'Features//a_feature_vector_48.npy')\n",
    "a_label_vector = np.load(prefix + 'Features//a_label_vector_48.npy')\n",
    "n_feature_vector = np.load(prefix + 'Features//n_feature_vector_48.npy')\n",
    "n_label_vector = np.load(prefix + 'Features//n_label_vector_48.npy')\n",
    "s_feature_vector = np.load(prefix + 'Features//s_feature_vector_48.npy')\n",
    "s_label_vector = np.load(prefix + 'Features//s_label_vector_48.npy')\n",
    "\n",
    "h_feature_vector_test = np.load(prefix + 'Features//h_feature_vector_test_48.npy')\n",
    "h_label_vector_test = np.load(prefix + 'Features//h_label_vector_test_48.npy')\n",
    "a_feature_vector_test = np.load(prefix + 'Features//a_feature_vector_test_48.npy')\n",
    "a_label_vector_test = np.load(prefix + 'Features//a_label_vector_test_48.npy')\n",
    "n_feature_vector_test = np.load(prefix + 'Features//n_feature_vector_test_48.npy')\n",
    "n_label_vector_test = np.load(prefix + 'Features//n_label_vector_test_48.npy')\n",
    "s_feature_vector_test = np.load(prefix + 'Features//s_feature_vector_test_48.npy')\n",
    "s_label_vector_test = np.load(prefix + 'Features//s_label_vector_test_48.npy')\n",
    "\n",
    "h_label_vector[h_label_vector == 0] = 0\n",
    "a_label_vector[a_label_vector == 1] = 1\n",
    "h_label_vector_test[h_label_vector_test == 0] = 0\n",
    "a_label_vector_test[a_label_vector_test == 1] = 1\n",
    "\n",
    "h_label_vector = to_categorical(h_label_vector, num_classes = 2)\n",
    "a_label_vector = to_categorical(a_label_vector, num_classes = 2)\n",
    "h_label_vector_test = to_categorical(h_label_vector_test, num_classes = 2)\n",
    "a_label_vector_test = to_categorical(a_label_vector_test, num_classes = 2)\n",
    "\n",
    "# Load training npy files\n",
    "featureSet_training = np.vstack((h_feature_vector, a_feature_vector))\n",
    "label_training = np.vstack((h_label_vector, a_label_vector))\n",
    "\n",
    "# Load testing npy files\n",
    "featureSet_testing = np.vstack((h_feature_vector_test, a_feature_vector_test))\n",
    "label_testing = np.vstack((h_label_vector_test, a_label_vector_test))\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]      \n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "        \n",
    "    return input_np\n",
    "\n",
    "train_data = float_compatible((featureSet_training).astype(np.float32))\n",
    "eval_data = float_compatible((featureSet_testing).astype(np.float32))\n",
    "\n",
    "adam = optimizers.Adam(lr = 3e-6, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0, amsgrad = True)\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "rmsprop = optimizers.RMSprop(lr = 0.0001, rho = 0.9, epsilon = None, decay = 0.0)\n",
    "adagrad = optimizers.Adagrad(lr = 0.01, epsilon = None, decay = 0.0)\n",
    "adadelta = optimizers.Adadelta(lr = 1.0, rho = 0.95, epsilon = None, decay = 0.0)\n",
    "adamax = optimizers.Adamax(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0)\n",
    "nadam = optimizers.Nadam(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, schedule_decay = 0.004)\n",
    "\n",
    "featureSet = train_data\n",
    "Label = label_training\n",
    "featureSet = np.split(featureSet, np.array([NumofFeaturetoUse]), axis = 2)[0]\n",
    "\n",
    "print('training data: ' + str(featureSet.shape))\n",
    "print('training label: ' + str(Label.shape))\n",
    "\n",
    "featureSet_val = eval_data\n",
    "Label_val = label_testing\n",
    "featureSet_val = np.split(featureSet_val, np.array([NumofFeaturetoUse]), axis = 2)[0]\n",
    "\n",
    "print('evaluation data: ' + str(featureSet_val.shape))\n",
    "print('evaluation label: ' + str(Label_val.shape))\n",
    "\n",
    "def record(str_message, log_file):\n",
    "    str_message = str_message + '\\n'\n",
    "    file = open(log_file, 'a')\n",
    "    file.write(str_message)\n",
    "    file.close()\n",
    "\n",
    "def create_cnn(title, num_layers, n_neurons, n_batch, nbindex, dropout, classes, dense_layers):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution1D(nb_filter=nbindex, filter_length=fillength,\n",
    "                            input_shape=(featureSet.shape[1], featureSet.shape[2]), kernel_constraint=maxnorm(3)))\n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "    '''\n",
    "    model.add(Convolution1D(nb_filter=nbindex*2, filter_length=fillength,\n",
    "                            kernel_constraint=maxnorm(3)))\n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution1D(nb_filter=nbindex*3, filter_length=fillength,\n",
    "                            kernel_constraint=maxnorm(3)))\n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "    '''\n",
    "    model.add(Convolution1D(nb_filter=nbindex*5, filter_length=fillength,\n",
    "                            kernel_constraint=maxnorm(3)))  \n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_cnn():\n",
    "    \n",
    "    save_to_path = prefix + str(num_layers) + \"_Layer(s)//\"\n",
    "\n",
    "    checkpoint_filepath = prefix + str(num_layers) + \"_Layer(s)//Checkpoint_\" + title + \".hdf5\"\n",
    "    final_filepath = prefix + str(num_layers) + \"_Layer(s)//Final_\" + title + \".hdf5\"\n",
    "\n",
    "    if not os.path.exists(save_to_path):\n",
    "        os.mkdir(save_to_path)\n",
    "\n",
    "    X, X_test, Y, Y_test= train_test_split(featureSet, Label, test_size = 0.25, shuffle = True)\n",
    "\n",
    "    model = create_cnn(title, num_layers, n_neurons, n_batch, nbindex, dropout, classes, dense_layers)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(checkpoint_filepath, monitor = 'val_loss', verbose = 0, save_best_only = True, mode = 'auto')\n",
    "\n",
    "    early_stopping_monitor = EarlyStopping(patience = 50)\n",
    "\n",
    "    callbacks_list = [checkpoint, early_stopping_monitor]\n",
    "\n",
    "    model.fit(X, Y, nb_epoch = n_epoch, batch_size = n_batch,  callbacks = callbacks_list, validation_data = (X_test, Y_test), verbose = 1)\n",
    "\n",
    "    model.save_weights(final_filepath)\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_cnn(model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for item in list(Label_val):\n",
    "            if item[0] > item[1]:\n",
    "                y_true.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    for item in list(model.predict(featureSet_val)):\n",
    "            if item[0] > item[1]:\n",
    "                y_pred.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('f1 score: ' + str(f1_score(y_true, y_pred)))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print('true positive ' + str(tp))\n",
    "    print('false positive ' + str(fp))\n",
    "    print('false negative ' + str(fn))\n",
    "    print('true negative ' + str(tn))\n",
    "\n",
    "title = 'H_A_neurons_' + str(n_neurons) + '_filters_' + str(\n",
    "    nbindex) + '_dropout_' + str(dropout) + '_epoch_' + str(n_epoch)\n",
    "\n",
    "final_filepath = prefix + str(num_layers) + \"_Layer(s)//Final_\" + title + \".hdf5\"\n",
    "#model = load_model(final_filepath)\n",
    "model = train_cnn()\n",
    "predict_cnn(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
