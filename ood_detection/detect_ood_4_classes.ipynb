{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "import librosa\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mil_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.square(tf.keras.backend.max(y_pred) - tf.keras.backend.max(y_true))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34155, 48, 272)\n",
      "(34155, 4)\n",
      "(7551, 48, 272)\n",
      "(7551, 4)\n"
     ]
    }
   ],
   "source": [
    "# load training and testing ... \n",
    "\n",
    "condition = 'all'\n",
    "\n",
    "new_train = '..//train//' + condition + '//'\n",
    "new_test = '..//test//' + condition + '//'\n",
    "new_val = '..//val//' + condition + '//'\n",
    "\n",
    "def load_vectors(path):\n",
    "    files = sorted(os.listdir(path))\n",
    "    X = np.expand_dims(np.zeros((48, 272)), axis=0)\n",
    "    y = []\n",
    "    for npy in files:\n",
    "        if 'Calm' in npy or 'Other' in npy:\n",
    "            continue\n",
    "        \n",
    "        current = np.load(path+npy)\n",
    "        X = np.vstack((X, current))\n",
    "        label = [files.index(npy)]*len(current)       \n",
    "        y = y + label       \n",
    "    X = X[1:]\n",
    "    y = to_categorical(y)    \n",
    "    print(X.shape)\n",
    "    print(y.shape)    \n",
    "    return X, y\n",
    "    \n",
    "X_train, y_train = load_vectors(new_train)\n",
    "X_test, y_test = load_vectors(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('..//models//4_class_models_acc_0.8718_f1_0.8713_cnn.hdf5', custom_objects={'mil_squared_error': mil_squared_error})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model):\n",
    "    first_half_model = keras.Sequential()\n",
    "    second_half_model = keras.Sequential()\n",
    "    for i in range(0, len(model.layers)):\n",
    "        \n",
    "        if i < len(model.layers) - 1:\n",
    "            first_half_model.add(model.layers[i])\n",
    "        else:\n",
    "            second_half_model.add(model.layers[i])\n",
    "            \n",
    "    print('the original model has ' + str(len(model.layers)) + ' layers.')\n",
    "    print('the penultimate (a.k.a. first half) model has ' + str(len(first_half_model.layers)) + ' layers.')\n",
    "    print('the penultimate (a.k.a. second half) model has ' + str(len(second_half_model.layers)) + ' layers.')\n",
    "    return first_half_model, second_half_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the original model has 34 layers.\n",
      "the penultimate (a.k.a. first half) model has 33 layers.\n",
      "the penultimate (a.k.a. second half) model has 1 layers.\n"
     ]
    }
   ],
   "source": [
    "first_half_model, second_half_model = split_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, get emp_mean for each class\n",
    "\n",
    "emp_vals = [[], [], [], []]\n",
    "\n",
    "for X, y in zip(first_half_model.predict(X_train), y_train):\n",
    "    emp_vals[np.argmax(y)].append(X)\n",
    "    \n",
    "emp_vals = np.asarray(emp_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emp_mean(emp_val):\n",
    "    result = np.zeros(emp_val[0].shape).tolist()\n",
    "    \n",
    "    for penult_vector in emp_val:\n",
    "        #penult_vector has size (1024, 0)\n",
    "        for index in range(0, len(penult_vector)):\n",
    "            result[index] = penult_vector[index] + result[index]\n",
    "            \n",
    "    for index in range(0, len(result)):\n",
    "        result[index] = result[index]/len(result)       \n",
    "    result = np.expand_dims(np.asarray(result), axis=0)\n",
    "    print(result.shape)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n",
      "(1, 1024)\n",
      "(1, 1024)\n",
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "emp_means = [get_emp_mean(emp_vals[0]), get_emp_mean(emp_vals[1]), \\\n",
    "            get_emp_mean(emp_vals[2]), get_emp_mean(emp_vals[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "# get emprical covariance\n",
    "def get_emp_covar():\n",
    "    \n",
    "    flag = 0\n",
    "    \n",
    "    for X, y in zip(first_half_model.predict(X_train), y_train):\n",
    "        X = np.expand_dims(X, axis=0)\n",
    "        diff = X - emp_means[np.argmax(y)]\n",
    "        transpose = np.transpose(diff)\n",
    "        result = diff @ transpose\n",
    "        \n",
    "        if flag == 0:\n",
    "            emp_covar = result\n",
    "            flag = 1\n",
    "        else:\n",
    "            emp_covar = np.add(emp_covar, result)\n",
    "    \n",
    "    #division_vec = np.zeros(emp_covar.shape)\n",
    "    #division_vec = division_vec + len(y_train)\n",
    "            \n",
    "    emp_covar = emp_covar/len(y_train)\n",
    "    print(emp_covar.shape)\n",
    "    \n",
    "    return emp_covar\n",
    "\n",
    "emp_covar = get_emp_covar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_emp_covar = np.linalg.inv(emp_covar)\n",
    "\n",
    "def get_emp_mahalanobis(y_pred, c):\n",
    "    emp_mean = emp_means[c]\n",
    "    diff = y_pred - emp_mean\n",
    "    transpose = np.transpose(diff)\n",
    "    \n",
    "    emp_mahalanobis = np.linalg.norm(transpose @ inv_emp_covar @ diff)\n",
    "    \n",
    "    #print(emp_mahalanobis.shape)\n",
    "    \n",
    "    return emp_mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_mahalanobis_all_classes = [[], [], [], []]\n",
    "\n",
    "for index in range(0, len(emp_vals)):\n",
    "    for y_pred in emp_vals[index]:\n",
    "        emp_m = get_emp_mahalanobis(y_pred, index)\n",
    "        emp_mahalanobis_all_classes[index].append(emp_m)\n",
    "        \n",
    "np.shape(np.asarray(emp_mahalanobis_all_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_mahalanobis_all_classes_stds = []\n",
    "emp_mahalanobis_all_classes_means = []\n",
    "\n",
    "for index in range(0, len(emp_mahalanobis_all_classes)):\n",
    "    mean = np.mean(emp_mahalanobis_all_classes[index])\n",
    "    std = np.std(emp_mahalanobis_all_classes[index])\n",
    "    \n",
    "    emp_mahalanobis_all_classes_means.append(mean)\n",
    "    emp_mahalanobis_all_classes_stds.append(std)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mahalanobis_coeff(m_mean, m_std, m_dists, threshold):    \n",
    "    for i in np.linspace(0, 5, 500):\n",
    "        count = 0\n",
    "        for m_dist in m_dists:\n",
    "            \n",
    "            if m_mean - i*m_std < m_dist and m_mean + i*m_std > m_dist:\n",
    "                count += 1\n",
    "                \n",
    "        if count/len(m_dists) > threshold:            \n",
    "            #print(count/len(m_dists))\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7519918051445481\n",
      "0.753516333938294\n",
      "0.7512270731077241\n",
      "0.7516740438088753\n",
      "[1.0521042084168337, 1.1623246492985972, 1.1122244488977955, 1.0220440881763526]\n"
     ]
    }
   ],
   "source": [
    "emp_mahalanobis_all_classes_coeffs = []\n",
    "\n",
    "for m_mean, m_std, m_dists in zip(emp_mahalanobis_all_classes_means, \\\n",
    "                                 emp_mahalanobis_all_classes_stds, emp_mahalanobis_all_classes):\n",
    "    coeff = get_mahalanobis_coeff(m_mean, m_std, m_dists, threshold=0.75)\n",
    "    emp_mahalanobis_all_classes_coeffs.append(coeff)\n",
    "    \n",
    "print(emp_mahalanobis_all_classes_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_in_distribution(y_pred, c):\n",
    "    m_dist = get_emp_mahalanobis(y_pred, c)\n",
    "    std = emp_mahalanobis_all_classes_stds[c]\n",
    "    mean = emp_mahalanobis_all_classes_means[c]\n",
    "    coeff = emp_mahalanobis_all_classes_coeffs[c]\n",
    "    \n",
    "    if mean - coeff*m_std < m_dist and mean + coeff*m_std > m_dist:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda520b236a9c6d486bbc01b80a136b32a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
