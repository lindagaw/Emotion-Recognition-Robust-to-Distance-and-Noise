{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#model = keras.models.load_model('path/to/location')\n",
    "# load training and testing ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9995, 48, 272)\n",
      "(9995, 6)\n"
     ]
    }
   ],
   "source": [
    "# load training and testing ... \n",
    "\n",
    "condition = 'all'\n",
    "\n",
    "new_train = '..//train//' + condition + '//'\n",
    "new_test = '..//test//' + condition + '//'\n",
    "new_val = '..//val//' + condition + '//'\n",
    "\n",
    "def load_vectors(path):\n",
    "    files = sorted(os.listdir(path))\n",
    "    X = np.expand_dims(np.zeros((48, 272)), axis=0)\n",
    "    y = []\n",
    "    for npy in files:\n",
    "        '''\n",
    "        if 'Calm' in npy:\n",
    "            continue\n",
    "        '''\n",
    "        current = np.load(path+npy)\n",
    "        X = np.vstack((X, current))\n",
    "        label = [files.index(npy)]*len(current)       \n",
    "        y = y + label       \n",
    "    X = X[1:]\n",
    "    y = tf.keras.utils.to_categorical(y)    \n",
    "    print(X.shape)\n",
    "    print(y.shape)    \n",
    "    return X, y\n",
    "    \n",
    "#X_train, y_train = load_vectors(new_train)\n",
    "X_test, y_test = load_vectors(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mood model is intialized.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model, Sequential\n",
    "\n",
    "model_path = 'D://GitHub//Patient-Caregiver-Relationship//module//five_class_ood//'\n",
    "\n",
    "model = load_model(model_path + 'model.hdf5')\n",
    "\n",
    "model_no_softmax = Sequential()\n",
    "model_last_layer = Sequential()\n",
    "\n",
    "for index in range(1, len(model.layers)+1):\n",
    "    if index == len(model.layers):\n",
    "        model_last_layer.add(model.layers[index-1])\n",
    "    else:\n",
    "        model_no_softmax.add(model.layers[index-1])\n",
    "\n",
    "print('The mood model is intialized.')\n",
    "del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred_penultimate(fname, model_to_predict):\n",
    "    if '.wav' not in fname:\n",
    "        X = [fname]\n",
    "    else:\n",
    "        X = [extract_feats_single_wav_to_tensor(fname)]\n",
    "    y_pred = model_to_predict.predict(np.array(X))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def model_pred_penultimate_npy(npy, model_to_predict):\n",
    "    y_pred = model_to_predict.predict(np.asarray([npy]))\n",
    "    return y_pred\n",
    "\n",
    "def model_pred_softmax(vec, model_to_predict):\n",
    "    y_pred = model_to_predict.predict(vec)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The emprical class means are loaded.\n",
      "The covariance matrix is iloaded\n"
     ]
    }
   ],
   "source": [
    "emprical_means_h = np.load(model_path + 'penultimate_mahalanobis_training_samples_emprical_means_h.npy')\n",
    "emprical_means_a = np.load(model_path + 'penultimate_mahalanobis_training_samples_emprical_means_a.npy')\n",
    "emprical_means_n = np.load(model_path + 'penultimate_mahalanobis_training_samples_emprical_means_n.npy')\n",
    "emprical_means_s = np.load(model_path + 'penultimate_mahalanobis_training_samples_emprical_means_s.npy')\n",
    "emprical_means_o = np.load(model_path + 'penultimate_mahalanobis_training_samples_emprical_means_o.npy')\n",
    "\n",
    "emprical_std_means_h = np.std(emprical_means_h)\n",
    "emprical_std_means_a = np.std(emprical_means_a)\n",
    "emprical_std_means_n = np.std(emprical_means_n)\n",
    "emprical_std_means_s = np.std(emprical_means_s)\n",
    "emprical_std_means_o = np.std(emprical_means_o)\n",
    "\n",
    "emprical_mean_of_means_h = np.mean(emprical_means_h)\n",
    "emprical_mean_of_means_a = np.mean(emprical_means_a)\n",
    "emprical_mean_of_means_n = np.mean(emprical_means_n)\n",
    "emprical_mean_of_means_s = np.mean(emprical_means_s)\n",
    "emprical_mean_of_means_o = np.mean(emprical_means_o)\n",
    "\n",
    "means_for_all_classes = [emprical_mean_of_means_h, emprical_mean_of_means_a, emprical_mean_of_means_n, emprical_mean_of_means_s, emprical_mean_of_means_o]\n",
    "stds_for_all_classes = [emprical_std_means_h, emprical_std_means_a, emprical_std_means_n, emprical_std_means_s, emprical_std_means_o]\n",
    "\n",
    "mius = np.load(model_path + 'penultimate_emprical_means.npy')\n",
    "\n",
    "covariance_mat = np.load(model_path + 'penultimate_emprical_covariance.npy')\n",
    "inverse_covariance = np.linalg.pinv(covariance_mat)\n",
    "del covariance_mat\n",
    "print('The emprical class means are loaded.')\n",
    "print('The covariance matrix is iloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_index(a): \n",
    "    a = list(a)\n",
    "    minpos = a.index(min(a))    \n",
    "    return minpos\n",
    "\n",
    "def max_index(a): \n",
    "    a = list(a)\n",
    "    maxpos = a.index(max(a))    \n",
    "    return maxpos\n",
    "\n",
    "def calc_mahalanobis(penultimate, C, inverse_covariance, mius):\n",
    "    mahalanobis_scores = []\n",
    "    #inverse_covariance = np.linalg.pinv(covariance_mat)\n",
    "    for c in range(0, len(C)):\n",
    "        miu = mius[c]\n",
    "        predicted_minus_class_mean = penultimate - miu\n",
    "        predicted_minus_class_mean_transpose = np.transpose(predicted_minus_class_mean)\n",
    "        score = predicted_minus_class_mean_transpose * inverse_covariance * predicted_minus_class_mean_transpose\n",
    "        score_norm = np.linalg.norm(score)\n",
    "        mahalanobis_scores.append(score_norm)\n",
    "    return np.array(mahalanobis_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_if_ood_one_sample(fname): # <-- testing ood samples for one npy/wav\n",
    "    item = model_pred_penultimate(fname, model_no_softmax)\n",
    "    maha = calc_mahalanobis(item, [0, 1, 2, 3, 4], inverse_covariance, mius)\n",
    "\n",
    "    plausible = min_index(maha)\n",
    "\n",
    "    upper = ( means_for_all_classes[plausible] - 0.75 * stds_for_all_classes[plausible] ) < maha[plausible]\n",
    "    lower = maha[plausible] < ( means_for_all_classes[plausible] + 0.75 * stds_for_all_classes[plausible] )\n",
    "    \n",
    "    if upper and lower:\n",
    "        classification = model_pred_softmax(item, model_last_layer)\n",
    "        #print('classification: ' + str(np.argmax(classification[0])) )\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_if_ood_samples(X_test, y_test):\n",
    "    \n",
    "    new_X = []\n",
    "    new_Y = []\n",
    "    \n",
    "    for X, y in tqdm(zip(X_test, y_test)):\n",
    "        \n",
    "        if test_if_ood_one_sample(X):\n",
    "            new_X.append(X)\n",
    "            new_Y.append(y)\n",
    "            \n",
    "    new_X = np.asarray(new_X)\n",
    "    new_Y = np.asarray(new_Y)\n",
    "    return new_X, new_Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n",
      "9995it [2:08:02,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "new_X, new_Y = test_if_ood_samples(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('new_X_3rd.npy', new_X)\n",
    "np.save('new_y_3rd.npy', new_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda520b236a9c6d486bbc01b80a136b32a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
