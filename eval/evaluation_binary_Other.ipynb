{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the Top classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the evaluation script of the top classifier in the hierarchy of three classifiers. The top classifier outputs a vector of size 2.\n",
    "\n",
    "The two indices of the vector are the scores that the classifier has calculated based on one 5-second audio clip.\n",
    "\n",
    "The first indice (0th) is the score/probability that the audio clip is of the Happy/Angry class.\n",
    "\n",
    "The second indice (1st) is the score/probability that the audio clip is of the Neutral/Sad class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### library and package importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from graphs import draw\n",
    "import graphs\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "# print(len(backend.tensorflow_backend._get_available_gpus()) > 0)\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlappiong=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 272 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "sys.path.insert(1, '..//components//')\n",
    "import load_feat_directories\n",
    "\n",
    "# input new indices file here\n",
    "# indices_filename = 'D://indices_filename.npy'\n",
    "# indices=np.load(indices_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avail_modules(directory, prefix):\n",
    "    module_names = []\n",
    "    for item in os.listdir(directory):\n",
    "        if prefix in item:\n",
    "            module_names.append(directory + item)\n",
    "            i = module_names.index(directory + item)\n",
    "            print(str(i) + 'th module')\n",
    "            print(directory + item)\n",
    "    return module_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprise_vector(path, dist, reverb, noise):\n",
    "    vec_to_return = []\n",
    "    for fname in os.listdir(path):\n",
    "        components = fname.split('_')\n",
    "        '''\n",
    "        if dist == 0 and 'deamp' in components: continue\n",
    "        if reverb == 0 and 'WetDry' in components: continue\n",
    "        if noise == 0 and 'noise' in components: continue\n",
    "        '''\n",
    "        current_vec = np.load(path + fname)\n",
    "        vec_to_return.append(current_vec)\n",
    "        \n",
    "    vec_to_return = np.array(vec_to_return)\n",
    "    return vec_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprise_label(feature_vector, label):\n",
    "    label_vec_to_ret = []\n",
    "    length = len(list(feature_vector))\n",
    "    for index in range(0, length):\n",
    "        current_label = [label]\n",
    "        label_vec_to_ret.append(current_label)\n",
    "    label_vec_to_ret = np.array(label_vec_to_ret)\n",
    "\n",
    "    return label_vec_to_ret\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]\n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "\n",
    "    return input_np\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allnoised_npy[0, 1, 2, 3, 4] ==> H, A, N, S, O\n",
    "# homenoised_npy[0, 1, 2, 3, 4] ==> H, A, N, S, O\n",
    "all_noised_npy = load_feat_directories.allnoised_npy\n",
    "all_noised_npy_test = load_feat_directories.allnoised_npy_test\n",
    "home_noised_npy = load_feat_directories.homenoised_npy\n",
    "home_noised_npy_test = load_feat_directories.homenoised_npy_test\n",
    "\n",
    "for index in range(0, 5):\n",
    "    if not os.path.exists(home_noised_npy_test[index]):\n",
    "        print(home_noised_npy_test[index] + 'does not exist. Breaking the loop... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [0, 1, 2, 3, 4]\n",
    "home_or_all = 'home'\n",
    "dist = 0\n",
    "reverb = 0\n",
    "noise = 0\n",
    "\n",
    "for index in emotions:\n",
    "    if home_or_all == 'home':\n",
    "        path = home_noised_npy_test[index]\n",
    "    else:\n",
    "        path = all_noised_npy_test[index]\n",
    "        \n",
    "    if index == 0:\n",
    "        val_h_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_h_label = comprise_label(val_h_feat, index)\n",
    "    elif index == 1:\n",
    "        val_a_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_a_label = comprise_label(val_a_feat, index)\n",
    "    elif index == 2:\n",
    "        val_n_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_n_label = comprise_label(val_n_feat, index)\n",
    "    elif index == 3:\n",
    "        val_s_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_s_label = comprise_label(val_s_feat, index)\n",
    "    else:\n",
    "        val_o_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_o_label = comprise_label(val_o_feat, index)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1966, 48, 272)\n",
      "(1966, 1)\n",
      "(1942, 48, 272)\n",
      "(1942, 1)\n",
      "(1696, 48, 272)\n",
      "(1696, 1)\n",
      "(1947, 48, 272)\n",
      "(1947, 1)\n",
      "(1292, 48, 272)\n",
      "(1292, 1)\n"
     ]
    }
   ],
   "source": [
    "print(val_h_feat.shape)\n",
    "print(val_h_label.shape)\n",
    "\n",
    "print(val_a_feat.shape)\n",
    "print(val_a_label.shape)\n",
    "\n",
    "print(val_n_feat.shape)\n",
    "print(val_n_label.shape)\n",
    "\n",
    "print(val_s_feat.shape)\n",
    "print(val_s_label.shape)\n",
    "\n",
    "print(val_o_feat.shape)\n",
    "print(val_o_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other vs Target Emotions (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_eval_all(emotionFolders, val):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            \n",
    "            one_sample = np.load(emotionFolder + emotionfile)\n",
    "            one_sample = np.array([one_sample])\n",
    "            zero_score, one_score = model.predict(one_sample)[0]\n",
    "            zero_scores.append(zero_score)\n",
    "            one_scores.append(one_score)\n",
    "\n",
    "            if val == 0:\n",
    "                if zero_score > one_score: correct += 1\n",
    "                else: incorrect += 1\n",
    "            else:\n",
    "                if one_score > zero_score: correct += 1\n",
    "                else: incorrect += 1\n",
    "\n",
    "            total += 1\n",
    "                \n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'error_rate': incorrect/total, 'accuracy': correct/total, 'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_eval_original(emotionFolders, val):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "\n",
    "    for emotionfile in os.listdir(emotionFolder):\n",
    "        dist = 'deamp_' in emotionfile\n",
    "        reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "        noise = 'noise_' in emotionfile\n",
    "\n",
    "        r_n = not dist and reverb and noise \n",
    "        r = not dist and reverb and not noise\n",
    "        n = not dist and not reverb and noise\n",
    "        original = not dist and not reverb and not noise\n",
    "        d_r_n = dist and reverb and noise\n",
    "        d_r = dist and reverb and not noise\n",
    "        d_n = dist and not reverb and noise\n",
    "        d = dist and not reverb and not noise \n",
    "\n",
    "        if original:\n",
    "            one_sample = np.load(emotionFolder + emotionfile)\n",
    "            one_sample = np.array([one_sample])\n",
    "            zero_score, one_score = model.predict(one_sample)[0]\n",
    "            zero_scores.append(zero_score)\n",
    "            one_scores.append(one_score)\n",
    "\n",
    "            if val == 0:\n",
    "                if zero_score > one_score: correct += 1\n",
    "                else: incorrect += 1\n",
    "            else:\n",
    "                if one_score > zero_score: correct += 1\n",
    "                else: incorrect += 1\n",
    "\n",
    "            total += 1\n",
    "    \n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'error_rate': incorrect/total, 'accuracy': correct/total, 'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_eval_deamplified_noised(emotionFolders, val):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    deamplified_dbs = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise # does not exist\n",
    "            \n",
    "            if d_n:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                \n",
    "                components = emotionfile.split('_')\n",
    "                deamplified_amount_position = components.index('deamp') + 1\n",
    "                deamplified = float(components[deamplified_amount_position])\n",
    "                deamplified_dbs.append(deamplified)\n",
    "                \n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                \n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                if val == 0:\n",
    "                    if zero_score > one_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > zero_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                \n",
    "                total += 1\n",
    "                \n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'deamplified_dbs': deamplified_dbs, 'error_rate': incorrect/total, 'accuracy': correct/total, \\\n",
    "             'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_eval_reverbed(emotionFolders, val):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    wetdrys = []\n",
    "    diffusions = []\n",
    "    decayfactors = []\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise # does not exist\n",
    "            \n",
    "            if r:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                \n",
    "                components = emotionfile.split('_')\n",
    "                \n",
    "                wetdry_position = components.index('WetDry') + 1\n",
    "                wetdrys.append(float(components[wetdry_position]))\n",
    "                \n",
    "                decayfactor_position = components.index('DecayFactor') + 1\n",
    "                decayfactors.append(float(components[decayfactor_position]))\n",
    "                \n",
    "                diffusion_position = components.index('Diffusion') + 1\n",
    "                diffusions.append(float(components[diffusion_position].split('.')[0]))\n",
    "                \n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                if val == 0:\n",
    "                    if zero_score > one_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > zero_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                \n",
    "                total += 1\n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'wetdrys': wetdrys, 'diffusions': diffusions, 'decayfactors': decayfactors, \\\n",
    "             'error_rate': incorrect/total, 'accuracy': correct/total, 'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_eval_deamplified_noised_reverbed(emotionFolders, val):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    wetdrys = []\n",
    "    diffusions = []\n",
    "    decayfactors = []\n",
    "    deamplified_dbs = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise # does not exist\n",
    "            \n",
    "            if d_r_n:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                \n",
    "                components = emotionfile.split('_')\n",
    "                \n",
    "                deamplified_position = components.index('deamp') + 1\n",
    "                deamplified_dbs.append(float(components[deamplified_position]))\n",
    "                \n",
    "                wetdry_position = components.index('WetDry') + 1\n",
    "                wetdrys.append(float(components[wetdry_position]))\n",
    "                \n",
    "                decayfactor_position = components.index('DecayFactor') + 1\n",
    "                decayfactors.append(float(components[decayfactor_position]))\n",
    "                \n",
    "                diffusion_position = components.index('Diffusion') + 1\n",
    "                diffusions.append(float(components[diffusion_position].split('.')[0]))\n",
    "                \n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                if val == 0:\n",
    "                    if zero_score > one_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > zero_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                \n",
    "                total += 1\n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total))\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'wetdrys': wetdrys, 'diffusions': diffusions, 'decayfactors': decayfactors,\n",
    "             'deamplified_dbs': deamplified_dbs, 'error_rate': incorrect/total, 'accuracy': correct/total, \\\n",
    "             'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for item in list(Label_val):\n",
    "            if item[0] > item[1]:\n",
    "                y_true.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    for item in list(model.predict(featureSet_val)):\n",
    "            if item[0] > item[1]:\n",
    "                y_pred.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('f1 score: ' + str(f1_score(y_true, y_pred)))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print('true positive ' + str(tp))\n",
    "    print('false positive ' + str(fp))\n",
    "    print('false negative ' + str(fn))\n",
    "    print('true negative ' + str(tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_index_val = random.sample(range(len(val_h_feat)), 325)\n",
    "a_index_val = random.sample(range(len(val_a_feat)), 325)\n",
    "n_index_val = random.sample(range(len(val_n_feat)), 325)\n",
    "s_index_val = random.sample(range(len(val_s_feat)), 325)\n",
    "\n",
    "target_feats_val = []\n",
    "target_labels_val = []\n",
    "\n",
    "for index in h_index_val:\n",
    "    target_feats_val.append(val_h_feat[index])\n",
    "    target_labels_val.append(val_h_label[index])\n",
    "        \n",
    "for index in a_index_val:\n",
    "    target_feats_val.append(val_a_feat[index])\n",
    "    target_labels_val.append(val_a_label[index])\n",
    "\n",
    "for index in n_index_val:\n",
    "    target_feats_val.append(val_n_feat[index])\n",
    "    target_labels_val.append(val_n_label[index])\n",
    "        \n",
    "for index in s_index_val:\n",
    "    target_feats_val.append(val_s_feat[index])\n",
    "    target_labels_val.append(val_s_label[index])\n",
    "    \n",
    "target_feats_val = np.array(target_feats_val)\n",
    "target_labels_val = np.array(target_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing data: (2592, 48, 272)\n",
      "testing label: (2592, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load training npy files (shouldn't be necessary, but here it goes anyway)\n",
    "featureSet = float_compatible(np.vstack((target_feats_val, val_o_feat)))\n",
    "Label = np.vstack((target_labels_val, val_o_label))\n",
    "Label[Label == 0] = 0\n",
    "Label[Label == 1] = 0\n",
    "Label[Label == 2] = 0\n",
    "Label[Label == 3] = 0\n",
    "Label[Label == 4] = 1\n",
    "Label = to_categorical(Label)\n",
    "print('testing data: ' + str(featureSet.shape))\n",
    "print('testing label: ' + str(Label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th module\n",
      "..//..//modules//Checkpoint_home_Other_neurons_shared_architecture_2048_filters_1024_dropout_0.2_epoch_1000_dense_2.hdf5\n",
      "1th module\n",
      "..//..//modules//Checkpoint_home_Other_neurons_2048_filters_1024_dropout_0.2_epoch_1000_dense_2.hdf5\n"
     ]
    }
   ],
   "source": [
    "directory = '..//..//modules//'\n",
    "module_prefix = 'Other_'\n",
    "modules = avail_modules(directory, module_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = modules[0]\n",
    "model = keras.models.load_model(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 46, 1024)          836608    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 23, 1024)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 23, 1024)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 21, 2048)          6293504   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 10, 2048)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 2048)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 8, 2048)           12584960  \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 4, 2048)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 2048)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 2, 1024)           6292480   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 32,307,202\n",
      "Trainable params: 32,307,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the directories that contain the files of emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionFolders = [home_noised_npy_test[0], home_noised_npy_test[1], \\\n",
    "                  home_noised_npy_test[2], home_noised_npy_test[3], home_noised_npy_test[4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Happy validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: listdir: path should be string, bytes, os.PathLike or None, not numpy.ndarray\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "listdir: embedded null character in path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-9f3623f803b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdictionary_all_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother_eval_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_feats_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mone_scores_all_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary_all_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'one_scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzero_scores_all_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary_all_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zero_scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdeamplified_dbs_all_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary_all_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deamplified_dbs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-8e0ae5efacd9>\u001b[0m in \u001b[0;36mother_eval_all\u001b[0;34m(emotionFolders, val)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0memotionFolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotionFolders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0memotionfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotionFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mone_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotionFolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0memotionfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: listdir: embedded null character in path"
     ]
    }
   ],
   "source": [
    "dictionary_all_h = other_eval_all([target_feats_val], 0)\n",
    "\n",
    "one_scores_all_h = dictionary_all_h.get('one_scores')\n",
    "zero_scores_all_h = dictionary_all_h.get('zero_scores')\n",
    "deamplified_dbs_all_h = dictionary_all_h.get('deamplified_dbs')\n",
    "wetdrys_all_h = dictionary_all_h.get('wetdrys')\n",
    "diffusions_all_h = dictionary_all_h.get('diffusions')\n",
    "decayfactors_all_h = dictionary_all_h.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Angry validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 1906\n",
      "incorrect = 36\n",
      "error rate = 0.018537590113285273\n",
      "accuracy = 0.9814624098867147\n",
      "total files = 1942\n"
     ]
    }
   ],
   "source": [
    "dictionary_all_a = top_eval_all([target_feats_val], 1)\n",
    "\n",
    "one_scores_all_a = dictionary_all_a.get('one_scores')\n",
    "zero_scores_all_a = dictionary_all_a.get('zero_scores')\n",
    "deamplified_dbs_all_a = dictionary_all_a.get('deamplified_dbs')\n",
    "wetdrys_all_a = dictionary_all_a.get('wetdrys')\n",
    "diffusions_all_a = dictionary_all_a.get('diffusions')\n",
    "decayfactors_all_a = dictionary_all_a.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Neutral validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 1670\n",
      "incorrect = 26\n",
      "error rate = 0.015330188679245283\n",
      "accuracy = 0.9846698113207547\n",
      "total files = 1696\n"
     ]
    }
   ],
   "source": [
    "dictionary_all_n = top_eval_all([emotionFolders[2]])\n",
    "\n",
    "one_scores_all_n = dictionary_all_n.get('one_scores')\n",
    "zero_scores_all_n = dictionary_all_n.get('zero_scores')\n",
    "deamplified_dbs_all_n = dictionary_all_n.get('deamplified_dbs')\n",
    "wetdrys_all_n = dictionary_all_n.get('wetdrys')\n",
    "diffusions_all_n = dictionary_all_n.get('diffusions')\n",
    "decayfactors_all_n = dictionary_all_n.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Sad validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 1911\n",
      "incorrect = 36\n",
      "error rate = 0.01848998459167951\n",
      "accuracy = 0.9815100154083205\n",
      "total files = 1947\n"
     ]
    }
   ],
   "source": [
    "dictionary_all_s = top_eval_all([emotionFolders[3]])\n",
    "\n",
    "one_scores_all_s = dictionary_all_s.get('one_scores')\n",
    "zero_scores_all_s = dictionary_all_s.get('zero_scores')\n",
    "deamplified_dbs_all_s = dictionary_all_s.get('deamplified_dbs')\n",
    "wetdrys_all_s = dictionary_all_s.get('wetdrys')\n",
    "diffusions_all_s = dictionary_all_s.get('diffusions')\n",
    "decayfactors_all_s = dictionary_all_s.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw the plot (evaluation on all the wav files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 662.4x360 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x20f44b0afd0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAFKCAYAAAD7QJ6iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXzdZZ33/9cna5MuadKU7gtdKN1osaHs0CrDj0WnjLiBiqKIzLjc3spwM+pgx5/MuOB4g7vDACMIIjOyjILrWBDQlhYolEKhpUAXui9pm7Rpcq77j3Na05h0gTQpX1/Px6MPzvf6Xt/rXNe3Pcn7XNd1OJFSQpIkKauKursDkiRJh5NhR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZVpJd3fgcFqwYMFRJSUlNwKTMNip8+SARc3NzZdNmzZtXXd3RpK0f5kOOyUlJTcOHDhwfP/+/TcXFRX5PxRSp8jlcrF+/foJa9asuRH46+7ujyRp/7I+2zGpf//+9QYddaaioqLUv3//reRnDCVJR7ish50ig44Oh8K/q6y/fiQpEzK9jNXW6lnTp72e6wffO29BR+eWLFlSdtJJJ40fO3bsToCTTjpp2w033LD69TxfaxdeeOHIJUuWVJSVlaUJEyY03Hbbba90VPe6666rvfLKKzd01nO3Z8ZdF7+ueznnnbd3eC/3OP74448955xztvzLv/zLmtfzXJKkv2y+M+1EJ5544rZ58+YtmTdv3pK2QaelpYX9HbfV3vmbb755+eOPP/7c8uXLy+fPn9+jo2tvueWW/ofU8SPQ0qVLS4cOHbrrwQcf7NNZbR7onkuSssmwc5iNHj164t/8zd+MvOKKK4Z++tOfHvz2t7995BlnnDF2wYIFFddcc82AqVOnHnv88ccf+/vf/74SYMKECeMvueSS4RdeeOHR7bXX3NxMQ0ND8Z4vcJ01a9bR06dPHzdt2rRxL7zwQtkPf/jDvsuXL+8xffr0cf/2b/9WvXjx4rLTTjtt7PTp08d9+MMfHtaFQ39dfvSjH1W/973v3TRixIhdzzzzTPnq1atLZs6cOeaEE04YN2vWrKMB7rzzzqqpU6cee8IJJ4z73ve+V/Ozn/2s9+WXXz4U4Iknnuhx4YUXjoR97+m8efMqTjrppGOOP/74Yy+55JLhALlcjve///3Dp02bNu6EE04Yt2LFipJp06aN29OX888/f9TixYvLuuE2SJI6wV/UMtbhNnfu3N7Tp08fB3DBBRds+uxnP7t+7dq1ZT/4wQ+e69+/f8unP/3pwcOGDWv66U9/+tIrr7xScv/99/ddsGDBc0uWLCm77LLLRj766KPPb926teSqq65aO2nSpF1t27/00kuPXrduXemZZ55Zf8IJJ+wEuO22217u3bt37kc/+lHVDTfc0P+b3/zmqq9+9as7582btwTg3HPPHfX973//lYkTJ+76wAc+MOyhhx6qPOOMMxq69s4cujlz5vS5+uqrl/Xs2TN3++23V69Zs6b00ksv3XDJJZdsaWlpoaWlhWuuuWbIvHnznquqqsq1tLTwwAMP9G6vrdb3dPv27fHoo48+X1RUxNlnnz366aefLl+4cGFFSUlJWrBgwRLIzwBNmjSp4aGHHqqcNGnSzs2bNxdPmDChqWvvgCSpsxh2OtGJJ5647Re/+MWLrcuGDx++s3///nvXT6ZPn74D4IUXXiifOHFiQ3FxMRMmTGiqr68vBqiqqmpuL+hAfhnr6KOP3v22t71tdGNjY5SWlqaPf/zjQxYtWlTZ1NRUNG7cuMa21yxbtqzHpZdeOhJgx44dRWedddY24IgOO8uWLSt97rnnKs4666wxuVyOnTt3FvXs2TP3pS996VWA4uJiVqxYUTJ48OCmqqqq3J6yiNi7GX3PzBfse0+ff/758k996lPDGhsbi1auXFn2yiuvlD777LM9zjjjjO176hcXF/OhD31o4y233NJvypQpDRdccMGWLhu8JKnTuYx1mBUVFbV7PHbs2F2LFi2qbGlpYfHixWV9+vRpbq9+W7W1tS3nn3/+lm9961v9/vCHP1SuX7++dMGCBUuuvvrq1a1/we8xevTonbfddtvyefPmLXn66aeffc973nPE/+L+0Y9+VP2Vr3xlxe9///sXHnnkkRfGjBmzs7y8PPfb3/62F+RnXgYPHtz86quvltXX1xftKautrW1ZtWpVGcAf//jHyj3ttb6n119/ff+Pfexj6x577LElkydPbkgpxYQJExoffvjhXnvq5HI5zjzzzIbFixdX3HXXXTUf+MAHNnXZ4CVJne4vamZnf5+m6gytl7EmTZrUcNNNN63oqO7w4cObzz///C3Tpk07NiK44YYbOvx0VVtXXHHFxhkzZhzz0Y9+dMnatWtLTznllLHjxo3buef8aaedtu3Nb37zmMsuu2z917/+9ZWXXXbZiKampigqKuI//uM/Xho7duzrXpI5mE9TvVb33ntv9f333790z/HMmTO3rVq1qvTGG2+svf766wcMGzZs109/+tOXZs+eveq00047pqKiInfppZduuPzyyzft3LkzTjnllGNGjhy5s722Z82atfWqq64adtNNN9Xu2bB80UUXbb3//vurpk2bNq60tDTdc889ywYOHNgyc+bM+vnz5/ccMGCAO5sl6Q0s2psNyIqFCxe+NGXKlMP6EWxl1+c+97mB48aN23nJJZe0Oxu2cOHC2ilTpozs4m5Jkg6Ry1hSO6688spBDz74YO+LLrroiF/2kyTt31/UMpZ0sK677rpXu7sPkqTOkfWZnVwul4vu7oSyp/DvKtfd/ZAkHVjWw86i9evXVxl41JkK33peBSzq7r5Ikg4s08tYzc3Nl61Zs+bGNWvWTCL7wU5dJwcsam5uvqy7OyJJOrBMfxpLkiTJ2Q5JkpRphh1JkpRpmdqzU1tbm0aOHNnd3ZAkSd1gwYIFG1JK/duWZyrsjBw5kvnz53d3NyRJUjeIiJfbK3cZS5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZVqmvi5i99JnWT1reqe2efH7xnRqe5IkqWs5syNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjLNsCNJkjItE18EGhHnANeXFQXfeuFVPj520D7nd7Xk+F9PvMjTWxqoLivhu3WjGVZZvvf8qoZdzPjdIj4zbjBXjMlf+7t1W7nm6VdYPfdZBr1lNMMvmNCVQ5J0CDY9uZqlNz9OyqV2X6871+9gyXfnsrt+JyW9yhn/iZMp71cJwIPv/jE9h1cB0KO2J5P+zxkAbF60hhdvfZJcc47eR1cz7m9PJIp9fyi9Eb2mV25EbG9z/MGI+FbndOmQ+1IMfBs495hePbhn1Uae39a4T507XtlAVWkJj5x1HB8ZPYBrF6/Y5/zsZ1Yw86iqvcctKfG5p17mtpPGcsI3zmPdIy+zY+XWLhiNpEOVcjle+PcFTP7sjA5fr8tufYIBZ4yk7rrzGPGOibx4+8K954rKiqn72rnUfe3cvUEn5RJLvj2X8f/rFE74+nmU9+/JmgeXd+m4JHWeLLxNmQ4sTSm9WBTBrCE1/HLN5n0q/GrNZt45rBaA8wfV8PCGbaSUAPjFq5sZXlnOuN4Ve+s/sXkHI3uWM6JnD4pKijnqlOFsfGxllw1I0sGrX7qJioG9qBjQq8PXa8PKrVRPHghA34kD2Dh//6/n3dt3ESVFVA7uA0D1cQPZMHfFfq+RdOTq9LATEW+LiLkR8URE/CYiBhTKZ0fErRHxPxHxQkR8pFA+IyIeioi7I2JxRHwvIooi4sMR8Y1W7X4kIv61naccAuz9KTSoRxlrGnfvU2HNzt0MrigDoKQo6FNSzOamZhqaW/j20lf59LjBbeo37a0PUN6vkl2b9p0tknRkaNrUsHdJCtp/vfYaUc36QljZMG8lLY3N7N62C4Dc7hYWXP1LHv/cr9gwLx+CSnuXk1pybFu2MX/NH1ewa0NDVwxH0mHwWvfsVETEk62Oa4D7Co8fBk5KKaWIuAy4CvhM4dxxwElAT+CJiPh5oXw6MAF4GfgF8Hbgx8BTEXFVSmk3cCnw0Xb6En9W0KYkkdq5KrhuySo+MmogPUuK29Q/mGeRdERo7wXb5vU66v1TWXrTAtbOeZGq8UdRVlNBFOcrnfSdv6a8ppLGtdtZ+MX/oefwKioG9mb8p05l6X88QdrdQvWUQXvrS3rjea1hpzGlNHXPQUR8EKgrHA4F7oyIQUAZ0Hqh+96UUiPQGBG/Ix9ytgDzUkovFtq6AzgtpfSfEfE/wFsj4lmgNKX0dDt9mQa8MyKmDqko49WdTQzoUbpPhUE9yljdmJ+tac4l6ptbqC4t5onNO/j56s1cu3gF9btbKAooLy5iclVPVjc27b1+18YGyqsrkHTkKetXya6Nf5p1ae/1Wl5TycQrTwegZedu1s9dQUll2d5zABUDetF3wlFsf2kzFQN7U3VMLcd/8SwANi18lcbV9V0xHEmHweHYs/NN4FsppcnkZ2J6tDrX9j1YOkD5jcAHyc/q3NzB830e2Ai8s7q0mHtXbeLsAdX7VDh7YF/uWrEBgJ+/uolTa3sTEdx92njm/tUU5v7VFC4bNYBPjB3EpUcPYGrfnizfsYtXduwi19zCukdfoV/d0IO+AZK6Tp/RNTS+uo3Gdds7fL3urt9FyuV/rLxy92IGzhyVL9/eRG53y9469UvWUzk0/2GFpq07gfwy14p7n2XQ2WO6akiSOtnh+Oh5FbCq8PgDbc7Nioh/Ib+MNQO4GjgGmB4RR5Nfxno38AOAlNLciBgGvIn8EtifSSk1R8THgV8+v30nnzpmMOP6VPC151YxpW8lZw+s5j3D+/PJx1/k1N88Rd+yEr4zbdR+B1BSFHxp8nAu/uMSXl30IgNnjqLnsKr9XiOpe0RxEWM+VMfT184h5dLe1+vyO5+i9+gaauuGsmXxWpbfvhAiqBrfn7Efzk9EN6zaygs/eAyKAnKJYRdMoGch7Ky471k2Pb6alEsMPnsM1ZMGducwJb0OsedTSYd0UcT2lFKvVscfBOpSSh+PiFnAN8gHnj8CJ6SUZkTEbGAwMBoYDnw1pfRvETEDuAZYD0wGHgL+LqWUK7R9NTA1pfSeA/VrSt+e6YEzJx7yePbn4vf5bk6SpDeCB991x4KUUl3b8tc0s9M66BSObwFuKTy+F7i3g0ufTyld3k55Q0rp3R1ccxr58CRJknTIjtj/z05E9I2I58lvhv5td/dHkiS9MXXZ10WklGZ3UD4HmNNO+Rby+3kkSZJesyN2ZkeSJKkzGHYkSVKmGXYkSVKmGXYkSVKmGXYkSVKmGXYkSVKmGXYkSVKmGXYkSVKmGXYkSVKmGXYkSVKmddnXRXSF0jHjGXzvvE5tc06ntiZJkg6X4I52y53ZkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmVbS3R3oTLuXPsvqWdMPWO/i943pgt5IkqQjgTM7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp0ww7kiQp095QXwQaEecA1wPFwI0ppS+3Pp9LiSvmL+XpLQ1Ul5Xw3brRDKssZ1NTM5c/tpSFW3bwrmG1wJ++CHTdwy/xyt2LIaCsuoLxnziF0j7lXTouSQdn05OrWXrz46RcYtBbRjP8ggn7nN+5fgdLvjuX3fU7KelVzvhPnEx5v0oAlt32BJseXw0JqicPZPSlbyIiWH7HQtY+9BK7tzdx+q3v7I5hSTrMOmVmJyL+JiJSRBzbGe118BzFwLeBc4EJwEURsc9Puk1NzVSVlvDIWcfxkdEDuHbxCgB6FAVXHTuEf5w4bJ82U0uOpbc8zpQvvIW6686j54i+rPrF84drCJJeh5TL8cK/L2DyZ2dwwjfOY90jL7Nj5dZ96iy79QkGnDGSuuvOY8Q7JvLi7QsB2LpkPfVLNlB33bnUff1c6pdtZOvidQD0mzaE4//57C4fj6Su01nLWBcBDwPv6YzGIqK9GafpwNKU0osppSbgx8Cs1hXqm1t457BaAM4fVMPDG7aRUqKypJjp/XpTXrTvcFMCErTsaialREtDM2U1FZ0xBEmdrH7pJioG9qJiQC+KSoo56pThbHxs5T51GlZupXryQAD6ThzAxvmF8xHkmlrINefI7c6RWhKlVT0A6HNMLeXVvu6lLHvdy1gR0Qs4FZgJ3AfMjogZwGxgAzAJWAC8L6WUIuI84F8L5x4HRqWU3hoRs4HBwEhgQ0QMAz6RUnqy8FQ3A8+0euqVwImt+7I7lxhcUZYfWFHQp6SYzU3N1JSXttv3opIixn6kjvlX3k9xeQkVg3oz9rJpr+t+SDo8mjY17F2SAijvV0n9Cxv3qdNrRDXr565g6Hnj2DBvJS2NzezetouqY2rpO3EAf7j8Hkgw5Jyx9Bxa1dVDkNRNOmNm5wLgFyml54FNEfGmQvnxwKfILzmNAk6NiB7A94FzU0qnAf3btDUNmJVSuhi4EfggQEQcA5QCm9vUTxFxeUTMj4j5Lamd3kV02PFcc47Vv1rKtK+cw0nfv4Cew/vm9+9IOvK0+/re93DU+6eydfE6Flz1AFsXr6OspoIoDhrXbKNhVT0nf28WJ39/FpsXrWVLYRlLUvZ1Rti5iPySEoX/XlR4PC+ltDKllAOeJD9jcyzwYkppeaHOHW3aui+l1Fh4fBfw1ogoBT4E3A203nQzFFidUvpBSqkupVTXozhY3dgEQHMuUd/cQnVpcYcd3/5SPjtVDOxNRND/5OHUP7/hEIcvqSuU9atk18aGvce7Njb82fJTeU0lE688nWlfPZejLzoOgJLKMjbMW0mfsf0o7lFKcY9Sao4fTP0LvtalvxSvK+xERD/gzcCNEfES8PfAu8m/39rVqmoL+SWzjqdZ8nbseZBSagB+TX5fzruArwBjI+LoiCgjvz/ovtYX9ykp5q4V+R9gP391E6fW5kNMR8prKmhYuZWm+p0AbH5qDZVD+hygi5K6Q5/RNTS+uo3GddvJNbew7tFX6Fc3dJ86u+t3kXL5KaBX7l7MwJmjACivrWTLs+tILTlyzTm2Ll5H5RCXsaS/FK93z847gB+mlD66pyAiHgRO66D+c8CoiBiZUnqJfDDanxuB/wZ+n1JaHxEfB35J/qPnN6WUnomILwLzU0r31ZSVsLmpmVN/8xR9y0r4zrRRexs68dcL2d7cQlMu0XzFPRz3+Zn0HFrFiHdMYuEXfksUB+W1PTn2Yye91nsh6TCK4iLGfKiOp6+dQ8olBs4cRc9hVSy/8yl6j66htm4oWxavZfntCyGCqvH9GfvhOgD6nzSMLYvWMv/KBwConjqI2rohQP4j6esefplcUzN/uOIeBr15NCPfNbnbximp80VK7S2EH+TFEXOAL6eUftGq7JPA3wLLUkpvLZR9i3wguSUi3gZ8jfwG5XnAgJTSewsblLenlK5r8xzPAZ9q/RwdmdK3Z3rgzIkH7PfF7xtzwDqSJOmN5cF33bEgpVTXtvx1zeyklGa0U3YDcEObso+3OvxdSunYyK8vfRuYX6gzu21bETGY/FLbr15PPyVJ0l+u7vi6iI9ExJPkP0ZeRf7TWX8mIi4B5gKfK2xyliRJOmRd/nURKaVvAN84iHo/BH54+HskSZKyzC8ClSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmWbYkSRJmdblXxdxOJWOGc/ge+cdsN6cw98VSZLUxYI72i13ZkeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGWaYUeSJGVaSXd3oDPtXvosq2dN7/D8xe8b04W9kSRJRwJndiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqYZdiRJUqa9ob4INCLOAa4HioEbU0pfbn0+lxJXzF/K01saqC4r4bt1oxlWWc6mpmYuf2wpc3/5BANnHM3YD9ftvebJ2b+laXMjRWXFABz3+ZmUVfXowlFJOhibnlzN0psfJ+USg94ymuEXTNjn/M71O1jy3bnsrt9JSa9yxn/iZMr7VQKw7LYn2PT4akhQPXkgoy99ExGx99pFX3mIxnXbOeHr53XpmCR1jQOGnYhIwL+mlD5TOL4S6JVSmn2oTxYRfYGLU0rfeQ3XvgQk4C3ASuCxiLgvpbR4T51NTc1MLS3hkbOO495VG7l28Qq+VzeGHkXBVccO4arxvdixYuuftT3+kyfTe3S/Q+2SpC6Scjle+PcFHPf5mZT3q+Dxf/gV/eqG0HNo1d46y259ggFnjGTgjFFsXrSGF29fyPhPnMzWJeupX7KBuuvOBeCJf/wNWxevo+/EAQCsn7uC4h5vqPd9kg7RwSxj7QLeHhG1nfB8fYG/a+9ERBQf4NpyYHlK6cWUUhPwY2BW6wr1zS28c1i+m+cPquHhDdtIKVFZUsz0fr33zt5IemOpX7qJioG9qBjQi6KSYo46ZTgbH1u5T52GlVupnjwQgL4TB7BxfuF8BLmmFnLNOXK7c6SWRGlh9rZl525W/uw5hl84sUvHI6lrHUzYaQZ+APzvticion9E/FdEPFb4c2qhfHZhBmhPvUURMRL4MjA6Ip6MiK9FxIyI+F1E3A48Xah7T0QsiIhnIuLyVk9XDKxqdbwSGNK6P7tzicEVZQCUFAV9SorZ3NR8wAEu+c5c5v/9A7z8n4tIKR3ELZHUlZo2NexdkgIo71fJrk2N+9TpNaKa9XNXALBh3kpaGpvZvW0XVcfU0nfiAP5w+T384fJ7qJkycO+M0PIfP82wtx1LsW+EpEw72LnbbwNPRcRX25RfD3wjpfRwRAwHfgmM3087VwOTUkpTASJiBjC9ULa8UOdDKaVNEVFBfqnqv1JKGzto78DJpNW6fHvGf/JkymsqaW7czeKvP8zah15i4JlHH7BZSV2ovVd6m5f2qPdPZelNC1g750Wqxh9FWU0FURw0rtlGw6p6Tv5efiJ44f//O6oXr6OkspTGNdsY88E3sXPd9sM/Bknd5qDCTkqpPiJ+CHwSaP126ixgQquNfn0iovch9mFeq6AD8MmI+JvC42HAWGAj0MK+MzlDgdWF2Z/LAcqLgtWNTQyuKKM5l6hvbqG6dP/v2Mpr8u8WSypKOeq0EWxbutGwIx1hyvpVsmtjw97jXRsbKK+u2KdOeU0lE688HcgvT62fu4KSyjJe/c0y+oztR3GPUgBqjh9M/QsbKKkoZfvyzfzxY/eRWnLs3rqLJ2f/lqmz39J1A5PUJQ5lV97/BR4Hbm5VVgScnFLaZz45IprZd4lsfx9v2tHquhnkA9TJKaWGiJjT6tpdwKiIOJr8ctZ7yG92fob8MhtDKsrSXSs2UFfTi5+/uolTa3vv84mLtlJLjuYduyntU06uOcfGBaupnjxgP12V1B36jK6h8dVtNK7bTnlNBesefYXxnzxlnzq763dR0quMKApeuXsxA2eOAqC8tpJXf7uM4S05UoKti9cx5Lxx1NYNYfDZYwHYuW47T3/lIYOOlFEHHXYKS0s/AT4M3FQo/hXwceBrABExNaX0JPAS8NZC2ZuAPVMl24D9zfxUAZsLQedY4KQ2568mv1RWDNyUUnomIr4IzE8p3VdTVsLmpmZO/c1T9C0r4TvTRu298MRfL2RNEeSac2x4bCXHfX4mPWp78tS1vyO15Ei5RPXkgQw6a/TB3hJJXSSKixjzoTqevnYOKZcYOHMUPYdVsfzOp+g9uobauqFsWbyW5bcvhAiqxvff+7+Y6H/SMLYsWsv8Kx8AoHrqIGrrhuzv6SRlTBxoQ25EbE8p9So8HgAsB76aUppd+ITWt8nv0ykBHkopXVHYb3MvcBTwGHAacG5K6aXCZuTjgAeAnwNXppT2BKNy4B7yy1VLgP7A7JTSnMJHz+tSShs66uuUvj3TA2d2/KmKi9835kD3Q5IkvUE9+K47FqSU6tqWH3BmZ0/QKTxeC1S2Ot4AvLudaxqBszto7+I2RXNandsFnNvBdSMP1FdJkqS2/LoISZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaYYdSZKUaQf81vM3ktIx4xl877wOz8/puq5IkqQuFtzRbrkzO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdMMO5IkKdNKursDnWn30mdZPfon3CYAAA4fSURBVGv6Aetd/L4xXdAbSZJ0JHBmR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZZphR5IkZdob6otAI+Ic4HqgGLgxpfTl1udzKXHF/KU8vaWB6rISvls3mmGV5Wxqaubyx5aycMsO3jWsFvjTF4Gue/glXrl7MQSUVVcw/hOnUNqnvEvHJengbHpyNUtvfpyUSwx6y2iGXzBhn/M71+9gyXfnsrt+JyW9yhn/iZMp71cJwLLbnmDT46shQfXkgYy+9E1EBMvvWMjah15i9/YmTr/1nd0xLEmHWZfO7ETE5yLimYh4KiKejIgTD/K6kRGxCPg2cC4wAbgoIvb5SbepqZmq0hIeOes4PjJ6ANcuXgFAj6LgqmOH8I8Th+3TbmrJsfSWx5nyhbdQd9159BzRl1W/eL4zhiqpk6Vcjhf+fQGTPzuDE75xHuseeZkdK7fuU2fZrU8w4IyR1F13HiPeMZEXb18IwNYl66lfsoG6686l7uvnUr9sI1sXrwOg37QhHP/PZ3f5eCR1nS4LOxFxMvBW4E0ppeOAs4AVh9BEBbA0pfRiSqkJ+DEwq3WF+uYW3jmsFoDzB9Xw8IZtpJSoLClmer/elBftO9yUgAQtu5pJKdHS0ExZTcVrHqOkw6d+6SYqBvaiYkAvikqKOeqU4Wx8bOU+dRpWbqV68kAA+k4cwMb5hfMR5JpayDXnyO3OkVoSpVU9AOhzTC3l1b7upSzrymWsQcCGlNIugJTSBoCIuAZ4G/kw8yjw0ZRSiohpwE1AA/AwUMq+4WglsM/M0O5cYnBFGQAlRUGfkmI2NzVTU17aboeKSooY+5E65l95P8XlJVQM6s3Yy6Z13ogldZqmTQ17l6QAyvtVUv/Cxn3q9BpRzfq5Kxh63jg2zFtJS2Mzu7ftouqYWvpOHMAfLr8HEgw5Zyw9h1Z19RAkdZOuXMb6FTAsIp6PiO9ExJmF8m+llE5IKU0iH3jeWii/GfhkSunk/bSZDvisER2eyjXnWP2rpUz7yjmc9P0L6Dm8b37/jqQjT3uv9jYv71Hvn8rWxetYcNUDbF28jrKaCqI4aFyzjYZV9Zz8vVmc/P1ZbF60li2FZSxJ2ddlMzsppe2F2ZrTgZnAnRFxNbAtIq4CKoEa4JmIeAjom1J6sHD5rcDbgdabboYCqyPicuBygPKiYHVjE4MrymjOJeqbW6guLe6wT9tf2gxAxcDeAPQ/eTgr7jXsSEeisn6V7NrYsPd418aGP1t+Kq+pZOKVpwPQsnM36+euoKSyjFd/s4w+Y/tR3CM/y1tz/GDqX9hA3wlHdd0AJHWbLt2gnFJqSSnNSSl9Afg48F7gO8A7UkqTgX8DepB/v9b2fVwjMDYijo6IMuA9wH0ppR+klOpSSnX9ykq4a8UGAH7+6iZOre1N7Gdmp7ymgoaVW2mq3wnA5qfWUDmkT6eOWVLn6DO6hsZXt9G4bju55hbWPfoK/eqG7lNnd/0uUi7/o+OVuxczcOYoAMprK9ny7DpSS45cc46ti9dROcRlLOkvRZfN7ETEOCCXUnqhUDQVWAIcB2yIiF7AO4D/TCltiYitEXFaSulh8qEI8gHpl+Q/en5TSumZiPgiMD+ldF9NWQmbm5o59TdP0beshO9MG7X3+U/89UK2N7fQlEs0X3EPx31+Jj2HVjHiHZNY+IXfEsVBeW1Pjv3YSV1zQyQdkiguYsyH6nj62jmkXGLgzFH0HFbF8jufovfoGmrrhrJl8VqW374QIqga35+xH64DoP9Jw9iyaC3zr3wAgOqpg6itGwLkP5K+7uGXyTU184cr7mHQm0cz8l2Tu22ckjpfpHTgbS+d8kT5JaxvAn2BZmAp+eWnT5GfpXmJ/Abkl1NKs9tsUP4l+dmfSft7jil9e6YHzpx4wL5c/L4xB6wjSZLeWB581x0LUkp1bcu7cs/OAuCUdk59vvCnvfpTWhXNPjw9kyRJWebXRUiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEwz7EiSpEzrsi8C7QqlY8Yz+N55B6w35/B3RZIkdbHgjnbLndmRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZZtiRJEmZFiml7u5Dp4mI9cDL3d0PSZLULUaklPq3LcxU2JEkSWrLZSxJkpRphh1JkpRphh1JkpRphh1JkpRphh1JkpRphh1JkpRphh1JkpRphh1JkpRphh1JkpRphh3pDSwi5kTEZYep7c9GxI2Ho+2uEBEjIyJFREnh+JDu1eG8t4db5N0cEZsjYl5EnB4RS1qdfykizurOPkpdqaS7OyD9JYiIl4ABQEur4ltSSh/vnh7tKyJmALellIbuKUsp/XP39ahrRcRsYExK6X3d3ZdOchrwV8DQlNKOQtm4buyP1K0MO1LXeVtK6Tfd3Qn9RRgBvNQq6Eh/0VzGkrpRRJRHxJaImNSqrH9ENEbEURFRHRE/i4j1hSWJn0XE0A7amh0Rt7U6bruMc2lEPBsR2yLixYj4aKG8J/AAMDgithf+DG6nvb+OiGcK/Z0TEeNbnXspIq6MiKciYmtE3BkRPTroZ1FEfD4iXo6IdRHxw4ioatPnD0TEKxGxISI+t5/7d35EPBER9RGxojBDc0gi4hzgs8C7C2Nf2Or0iIh4pHDPfhURta2uOykiHi3cj4WF2bH22r80Iv671fHSiPhJq+MVETG18Pj6wnF9RCyIiNML5YML/yZqWl13fOH+lLZ5vg8DNwInF8bzTxExIyJWdtC/ooi4OiKWRcTGiPjJnueJiB4RcVuhfEtEPBYRAw723kpHCsOO1I1SSruAnwIXtSp+F/BgSmkd+dfozeTfqQ8HGoFvvcanWwe8FegDXAp8IyLeVHj3fy6wOqXUq/BndesLI+IY4A7gU0B/4H7gvyOirE2/zwGOBo4DPthBPz5Y+DMTGAX0amdMp5FfdnkLcE3rYNXGDuASoC9wPvC3EXFBx7fgz6WUfgH8M3BnYexTWp2+mPy9OgooA64EiIghwM+BLwE1hfL/ioj+7TzFg8DphVAxCCgFTi20s2f8TxXqPgZMLbR5O3BXRPQo/H38AbiwTd/+M6W0u814/h24AvhDYTxfOMAt+CRwAXAmMBjYDHy7cO4DQBUwDOhXaLfxAO1JRxzDjtR17im8O97z5yOF8tvZN+xcXCgjpbQxpfRfKaWGlNI24Fryv5QOWUrp5ymlZSnvQeBXwOkHefm7gZ+nlH5d+OV6HVABnNKqzg0ppdUppU3Af5P/pd2e9wL/mlJ6MaW0HfgH4D17ZqAK/iml1JhSWggsBKa011BKaU5K6emUUi6l9BT5QPaa7k8Hbk4pPZ9SagR+wp/G9D7g/pTS/YXn/jUwHzivnT6+CGwrXHsm8EtgVUQcWzj+fUopV6h7W+HvvDml9HWgnD/ttdn77yQiAnhPoez1+ijwuZTSykL4ng28o/D3sZt8yBmTUmpJKS1IKdV3wnNKXco9O1LXuaCDPTv/A1RExInAGvK/FO8GiIhK4BvkZ0yqC/V7R0RxSqmlnbY6FBHnAl8AjiH/RqcSePogLx8MvLznIKWUi4gVwJBWdda0etxQuOaAbRUel5DfwN1RW73aa6hwz74MTCI/81IO3LW/gRyijvoxAnhnRLyt1flS4HcdtPMgMAMYU3i8hXzQOblwDEBEfAa4jPw9SuRn4fYsnf0n8M2IGAyMLZz//WscV2sjgLsjIteqrIX838et5Gd1fhwRfYHbyAej3X/ejHTkcmZH6maFd/U/If+u/WLgZ4VZHIDPkH9nf2JKqQ9wRqE82mlqB/kAs8fAPQ8iohz4L/IzMgNSSn3JL0XtaScdoJuryf9S3NNekP8luOpA4ztQW+SX55qBta+hrduB+4BhKaUq4Hu0f28O5EDjb2sFcGtKqW+rPz1TSl/uoP6esHN64fGD5MPOmYXHFPbn/B/yy4HVhb+jrRTGk1LaQn427l3k/53ckVI61H53NJZz24ylR0ppVUppd0rpn1JKE8jP4r2V/LKh9IZi2JGODLeTXyp6L/suTfQmv0diS2HT6P72XzwJnBERwwsbfv+h1bk9sx7rgebCLM/Zrc6vBfrt2Sjcjp8A50fEWwobYj8D7AIePdgBtnIH8L8j4uiI6MWf9ss0v4a2egObUko7I2I6+RDwWqwFRkbEwf5MvA14W0T8fxFRXNjIOyM62DxOPtDMBCpSSivJz8icQ36J6IlWY2km/3dUEhHXkJ/Zae128mHjQjpnCQvyAfHaiBgBezfIzyo8nhkRkyOiGKgnv6x1SDOK0pHAsCN1nf+OP33aaXtE3L3nREppLvmZmcHkPxm1x/8lvzdmA/BH4BcdNV7YN3In+c2uC4CftTq3jfxG1J+Q34B6MfkZkT3nnyMfQl4s7CfaZwkqpbSE/D6Vbxb68jbyH6VvOtSbANxEfnnkIWA5sBP4xGtoB+DvgC9GxDbgGvLjey32LH1tjIjHD1Q5pbQCmEX+U1zryc+O/D0d/ExNKT0PbKew7FTY9/Ii8Eir5chfkv+7f5780t7OQrut3Ud+CWttYT9TZ7i+0O6vCvfxj8CJhXMDyS+f1QPPkg9tt7XXiHQki86ZBZUkSToyObMjSZIyzbAjSZIyzbAjSZIyzbAjSZIyzbAjSZIyzbAjSZIyzbAjSZIyzbAjSZIyzbAjSZIy7f8Bz8xVavyWSHYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 662.4x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_names = ['Error Rate', 'Accuracy']\n",
    "graph_title = 'Evaluation on all the wav files'\n",
    "results = {\n",
    "    'Happy': [dictionary_all_h.get('error_rate'), dictionary_all_h.get('accuracy')],\n",
    "    'Angry': [dictionary_all_a.get('error_rate'), dictionary_all_a.get('accuracy')],\n",
    "    'Neutral': [dictionary_all_n.get('error_rate'), dictionary_all_n.get('accuracy')],\n",
    "    'Sad': [dictionary_all_s.get('error_rate'), dictionary_all_s.get('accuracy')]\n",
    "}\n",
    "\n",
    "draw(results, category_names, graph_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
