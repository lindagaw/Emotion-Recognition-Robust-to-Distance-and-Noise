{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the H/A classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the evaluation script of the top classifier in the hierarchy of three classifiers. The top classifier outputs a vector of size 2.\n",
    "\n",
    "The two indices of the vector are the scores that the classifier has calculated based on one 5-second audio clip.\n",
    "\n",
    "The first indice (0th) is the score/probability that the audio clip is of the Happy/Angry class.\n",
    "\n",
    "The second indice (1st) is the score/probability that the audio clip is of the Neutral/Sad class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### library and package importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\yg9ca\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from graphs import draw\n",
    "import graphs\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "# print(len(backend.tensorflow_backend._get_available_gpus()) > 0)\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlappiong=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 272 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "sys.path.insert(1, '..//components//')\n",
    "import load_feat_directories\n",
    "\n",
    "# input new indices file here\n",
    "# indices_filename = 'D://indices_filename.npy'\n",
    "# indices=np.load(indices_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avail_modules(directory, prefix):\n",
    "    module_names = []\n",
    "    for item in os.listdir(directory):\n",
    "        if prefix in item:\n",
    "            module_names.append(directory + item)\n",
    "            i = module_names.index(directory + item)\n",
    "            print(str(i) + 'th module')\n",
    "            print(directory + item)\n",
    "    return module_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprise_vector(path, dist, reverb, noise):\n",
    "    vec_to_return = []\n",
    "    for fname in os.listdir(path):\n",
    "        components = fname.split('_')\n",
    "        '''\n",
    "        if dist == 0 and 'deamp' in components: continue\n",
    "        if reverb == 0 and 'WetDry' in components: continue\n",
    "        if noise == 0 and 'noise' in components: continue\n",
    "        '''\n",
    "        current_vec = np.load(path + fname)\n",
    "        vec_to_return.append(current_vec)\n",
    "        \n",
    "    vec_to_return = np.array(vec_to_return)\n",
    "    return vec_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprise_label(feature_vector, label):\n",
    "    label_vec_to_ret = []\n",
    "    length = len(list(feature_vector))\n",
    "    for index in range(0, length):\n",
    "        current_label = [label]\n",
    "        label_vec_to_ret.append(current_label)\n",
    "    label_vec_to_ret = np.array(label_vec_to_ret)\n",
    "\n",
    "    return label_vec_to_ret\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]\n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "\n",
    "    return input_np\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H/A (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ha_eval_all(emotionFolders):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            \n",
    "            one_sample = np.load(emotionFolder + emotionfile)\n",
    "            one_sample = np.array([one_sample])\n",
    "            zero_score, one_score = model.predict(one_sample)[0]\n",
    "            zero_scores.append(zero_score)\n",
    "            one_scores.append(one_score)\n",
    "\n",
    "            if val == 0:\n",
    "                if zero_score > one_score: correct += 1\n",
    "                else: incorrect += 1\n",
    "            else:\n",
    "                if one_score > zero_score: correct += 1\n",
    "                else: incorrect += 1\n",
    "\n",
    "            total += 1\n",
    "                \n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'error_rate': incorrect/total, 'accuracy': correct/total, 'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ha_eval_original(emotionFolders):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise \n",
    "            \n",
    "            if original:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                print(model.predict(one_sample)[0])\n",
    "\n",
    "                if val == 0:\n",
    "                    if zero_score > 0 and one_score < 0.9999: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > 0 and zero_score < 0.9999: correct += 1\n",
    "                    else: incorrect += 1\n",
    "\n",
    "                total += 1\n",
    "    \n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'error_rate': incorrect/total, 'accuracy': correct/total, 'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ha_eval_deamplified_noised(emotionFolders):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    deamplified_dbs = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise # does not exist\n",
    "            \n",
    "            if d_n:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                \n",
    "                components = emotionfile.split('_')\n",
    "                deamplified_amount_position = components.index('deamp') + 1\n",
    "                deamplified = float(components[deamplified_amount_position])\n",
    "                deamplified_dbs.append(deamplified)\n",
    "                \n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                \n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                if val == 0:\n",
    "                    if zero_score > one_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > zero_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                \n",
    "                total += 1\n",
    "                \n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'deamplified_dbs': deamplified_dbs, 'error_rate': incorrect/total, 'accuracy': correct/total, \\\n",
    "             'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ha_eval_reverbed(emotionFolders):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    wetdrys = []\n",
    "    diffusions = []\n",
    "    decayfactors = []\n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise # does not exist\n",
    "            \n",
    "            if r:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                components = emotionfile.split('_')\n",
    "                \n",
    "                wetdry_position = components.index('WetDry') + 1\n",
    "                wetdrys.append(float(components[wetdry_position]))\n",
    "                \n",
    "                decayfactor_position = components.index('DecayFactor') + 1\n",
    "                decayfactors.append(float(components[decayfactor_position]))\n",
    "                \n",
    "                diffusion_position = components.index('Diffusion') + 1\n",
    "                diffusions.append(float(components[diffusion_position].split('.')[0]))\n",
    "                \n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                if val == 0:\n",
    "                    if zero_score > one_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > zero_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                \n",
    "                total += 1\n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total) )\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'wetdrys': wetdrys, 'diffusions': diffusions, 'decayfactors': decayfactors, \\\n",
    "             'error_rate': incorrect/total, 'accuracy': correct/total, 'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ha_eval_deamplified_noised_reverbed(emotionFolders):\n",
    "    total = 0\n",
    "    \n",
    "    zero_scores = []\n",
    "    one_scores = []\n",
    "    \n",
    "    wetdrys = []\n",
    "    diffusions = []\n",
    "    decayfactors = []\n",
    "    deamplified_dbs = []\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile and 'Diffusion_' in emotionfile and 'DecayFactor_' in emotionfile\n",
    "            noise = 'noise_' in emotionfile\n",
    "        \n",
    "            r_n = not dist and reverb and noise \n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise # does not exist\n",
    "            \n",
    "            if d_r_n:\n",
    "                one_sample = np.load(emotionFolder + emotionfile)\n",
    "                one_sample = np.array([one_sample])\n",
    "                zero_score, one_score = model.predict(one_sample)[0]\n",
    "                \n",
    "                components = emotionfile.split('_')\n",
    "                \n",
    "                deamplified_position = components.index('deamp') + 1\n",
    "                deamplified_dbs.append(float(components[deamplified_position]))\n",
    "                \n",
    "                wetdry_position = components.index('WetDry') + 1\n",
    "                wetdrys.append(float(components[wetdry_position]))\n",
    "                \n",
    "                decayfactor_position = components.index('DecayFactor') + 1\n",
    "                decayfactors.append(float(components[decayfactor_position]))\n",
    "                \n",
    "                diffusion_position = components.index('Diffusion') + 1\n",
    "                diffusions.append(float(components[diffusion_position].split('.')[0]))\n",
    "                \n",
    "                zero_scores.append(zero_score)\n",
    "                one_scores.append(one_score)\n",
    "                \n",
    "                if val == 0:\n",
    "                    if zero_score > one_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                else:\n",
    "                    if one_score > zero_score: correct += 1\n",
    "                    else: incorrect += 1\n",
    "                \n",
    "                total += 1\n",
    "    print('correct = ' + str(correct))\n",
    "    print('incorrect = ' + str(incorrect))\n",
    "    print('error rate = ' + str(incorrect/total) )\n",
    "    print('accuracy = ' + str(correct/total))\n",
    "    print('total files = ' + str(total))\n",
    "                       \n",
    "    mydict = {'one_scores': one_scores, 'zero_scores': zero_scores, \\\n",
    "             'wetdrys': wetdrys, 'diffusions': diffusions, 'decayfactors': decayfactors,\n",
    "             'deamplified_dbs': deamplified_dbs, 'error_rate': incorrect/total, 'accuracy': correct/total, \\\n",
    "             'total_files': total}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for item in list(Label_val):\n",
    "            if item[0] > item[1]:\n",
    "                y_true.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    for item in list(model.predict(featureSet_val)):\n",
    "            if item[0] > item[1]:\n",
    "                y_pred.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('f1 score: ' + str(f1_score(y_true, y_pred)))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print('true positive ' + str(tp))\n",
    "    print('false positive ' + str(fp))\n",
    "    print('false negative ' + str(fn))\n",
    "    print('true negative ' + str(tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th module\n",
      "..//..//modules//Checkpoint_home_H_A_neurons_home_2048_filters_1024_dropout_0.2_epoch_1000_dense_6.hdf5\n",
      "1th module\n",
      "..//..//modules//Checkpoint_home_H_A_neurons_home_2048_filters_1024_dropout_0.2_epoch_1000_dense_8.hdf5\n"
     ]
    }
   ],
   "source": [
    "directory = '..//..//modules//'\n",
    "module_prefix = 'H_A_'\n",
    "modules = avail_modules(directory, module_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = modules[0]\n",
    "model = keras.models.load_model(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the directories that contain the files of emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "emodb_Happy_npy = 'D://Datasets//EMO-DB//wav//npy//Happy//'\n",
    "emodb_Angry_npy = 'D://Datasets//EMO-DB//wav//npy//Angry//'\n",
    "emodb_Neutral_npy = 'D://Datasets//EMO-DB//wav//npy//Neutral//'\n",
    "emodb_Sad_npy = 'D://Datasets//EMO-DB//wav//npy//Sad//'\n",
    "emodb_Other_npy = 'D://Datasets//EMO-DB//wav//npy//Other//'\n",
    "emotionFolders = [emodb_Happy_npy, emodb_Angry_npy, emodb_Neutral_npy, emodb_Sad_npy, emodb_Other_npy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only evaluate unmodified wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Happy validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0044963e-05 9.9996996e-01]\n",
      "[0.9786453  0.02135465]\n",
      "[0.09375498 0.906245  ]\n",
      "[0.90089196 0.099108  ]\n",
      "[0.00624444 0.9937556 ]\n",
      "[0.9666793  0.03332067]\n",
      "[9.9999499e-01 5.0163085e-06]\n",
      "[0.14140175 0.85859823]\n",
      "[9.9997520e-01 2.4803387e-05]\n",
      "[9.9969244e-01 3.0762752e-04]\n",
      "[9.9998879e-01 1.1232388e-05]\n",
      "[9.9998915e-01 1.0831289e-05]\n",
      "[1.0000000e+00 3.1888232e-09]\n",
      "[9.9994600e-01 5.4052824e-05]\n",
      "[2.5435106e-06 9.9999750e-01]\n",
      "[9.999933e-01 6.667883e-06]\n",
      "[9.9967635e-01 3.2364437e-04]\n",
      "[0.01032003 0.98968   ]\n",
      "[0.9959965  0.00400347]\n",
      "[0.1864541 0.8135459]\n",
      "[9.999902e-01 9.824958e-06]\n",
      "[1.000000e+00 5.049593e-09]\n",
      "[9.9947494e-01 5.2512519e-04]\n",
      "[9.9994981e-01 5.0158214e-05]\n",
      "[9.9999988e-01 1.4916765e-07]\n",
      "[9.9999690e-01 3.0617762e-06]\n",
      "[9.9999976e-01 2.4791768e-07]\n",
      "[0.00121683 0.9987832 ]\n",
      "[9.9999952e-01 4.3476803e-07]\n",
      "[0.04521242 0.95478755]\n",
      "[1.0000000e+00 3.7563364e-08]\n",
      "[0.99531186 0.00468817]\n",
      "[9.999045e-01 9.545304e-05]\n",
      "[9.1580051e-04 9.9908423e-01]\n",
      "[0.13085707 0.86914295]\n",
      "[0.8802085  0.11979146]\n",
      "[2.2286257e-09 1.0000000e+00]\n",
      "[4.8269354e-05 9.9995172e-01]\n",
      "[4.7266993e-05 9.9995267e-01]\n",
      "[0.2965652  0.70343477]\n",
      "[9.9999797e-01 2.0699836e-06]\n",
      "[0.47277966 0.5272203 ]\n",
      "[0.97928166 0.02071833]\n",
      "[0.10014807 0.899852  ]\n",
      "[9.9999940e-01 6.4395635e-07]\n",
      "[9.9999154e-01 8.4316007e-06]\n",
      "[9.9999523e-01 4.7916155e-06]\n",
      "[9.9927765e-01 7.2235020e-04]\n",
      "[0.88062966 0.11937029]\n",
      "[9.9998260e-01 1.7361619e-05]\n",
      "[9.999999e-01 6.308185e-08]\n",
      "[1.000000e+00 4.389975e-09]\n",
      "[6.7352387e-04 9.9932647e-01]\n",
      "[1.18350414e-04 9.99881625e-01]\n",
      "[0.9978452  0.00215478]\n",
      "[0.00900925 0.99099076]\n",
      "[9.9999833e-01 1.7242714e-06]\n",
      "[9.9997222e-01 2.7817629e-05]\n",
      "[0.9964405  0.00355954]\n",
      "[1.1541978e-06 9.9999881e-01]\n",
      "[0.00947223 0.99052775]\n",
      "[0.30356804 0.696432  ]\n",
      "[1.0000000e+00 2.9431625e-08]\n",
      "[0.00101501 0.998985  ]\n",
      "[0.25783578 0.7421642 ]\n",
      "[9.9999964e-01 3.5289136e-07]\n",
      "[0.98979723 0.01020269]\n",
      "[9.9992573e-01 7.4225150e-05]\n",
      "[0.22663645 0.77336353]\n",
      "[0.9886824  0.01131767]\n",
      "[0.26275557 0.7372444 ]\n",
      "correct = 65\n",
      "incorrect = 6\n",
      "error rate = 0.08450704225352113\n",
      "accuracy = 0.9154929577464789\n",
      "total files = 71\n"
     ]
    }
   ],
   "source": [
    "dictionary_original_h = ha_eval_original([emotionFolders[0]])\n",
    "one_scores_original_h = dictionary_original_h.get('one_scores')\n",
    "zero_scores_original_h = dictionary_original_h.get('zero_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Angry validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.382479e-09 1.000000e+00]\n",
      "[9.99898553e-01 1.01436875e-04]\n",
      "[9.9999809e-01 1.8815933e-06]\n",
      "[2.1121891e-04 9.9978882e-01]\n",
      "[0.9933343  0.00666567]\n",
      "[0.00133413 0.9986659 ]\n",
      "[0.9381821  0.06181794]\n",
      "[9.9999940e-01 5.9559864e-07]\n",
      "[0.9585232  0.04147672]\n",
      "[0.6433247  0.35667524]\n",
      "[0.9323029  0.06769709]\n",
      "[0.0018408 0.9981592]\n",
      "[9.9998820e-01 1.1847658e-05]\n",
      "[0.9599137  0.04008628]\n",
      "[9.9993503e-01 6.5023582e-05]\n",
      "[1.1718164e-05 9.9998832e-01]\n",
      "[0.98374337 0.01625662]\n",
      "[0.05982304 0.940177  ]\n",
      "[9.999951e-01 4.916063e-06]\n",
      "[0.00159176 0.99840826]\n",
      "[0.00207069 0.99792933]\n",
      "[0.99494296 0.00505702]\n",
      "[0.98543465 0.0145654 ]\n",
      "[8.5221004e-04 9.9914777e-01]\n",
      "[0.05675487 0.9432451 ]\n",
      "[1.8476585e-06 9.9999821e-01]\n",
      "[9.9932325e-01 6.7671615e-04]\n",
      "[9.9915576e-01 8.4428914e-04]\n",
      "[9.9990094e-01 9.9008925e-05]\n",
      "[0.04771964 0.95228034]\n",
      "[0.96215457 0.0378454 ]\n",
      "[6.170207e-08 9.999999e-01]\n",
      "[1.000000e+00 1.446292e-08]\n",
      "[9.9986565e-01 1.3427653e-04]\n",
      "[9.999981e-01 1.926486e-06]\n",
      "[9.9995506e-01 4.4972658e-05]\n",
      "[0.8705518  0.12944819]\n",
      "[0.6933403  0.30665973]\n",
      "[9.9999738e-01 2.6719974e-06]\n",
      "[1.2005565e-07 9.9999988e-01]\n",
      "[1.3703583e-09 1.0000000e+00]\n",
      "[9.99885798e-01 1.14212526e-04]\n",
      "[6.557238e-04 9.993443e-01]\n",
      "[9.9999368e-01 6.2952377e-06]\n",
      "[4.4564668e-11 1.0000000e+00]\n",
      "[9.9977797e-01 2.2203855e-04]\n",
      "[0.00560096 0.994399  ]\n",
      "[0.02210375 0.9778962 ]\n",
      "[0.9874537  0.01254624]\n",
      "[4.4662187e-11 1.0000000e+00]\n",
      "[1.4339294e-07 9.9999988e-01]\n",
      "[0.63720834 0.36279166]\n",
      "[0.61102176 0.38897827]\n",
      "[0.5681656  0.43183437]\n",
      "[9.999919e-01 8.125399e-06]\n",
      "[1.00858415e-05 9.99989867e-01]\n",
      "[0.24729468 0.75270534]\n",
      "[0.00359421 0.99640584]\n",
      "[0.08621372 0.91378623]\n",
      "[4.467971e-05 9.999553e-01]\n",
      "[1.3748794e-05 9.9998629e-01]\n",
      "[0.9380837  0.06191627]\n",
      "[0.01545685 0.98454314]\n",
      "[0.92305493 0.07694509]\n",
      "[9.999224e-01 7.763940e-05]\n",
      "[9.9993193e-01 6.8018220e-05]\n",
      "[0.5133899  0.48661014]\n",
      "[2.401426e-06 9.999976e-01]\n",
      "[0.00239594 0.9976041 ]\n",
      "[0.9984634  0.00153666]\n",
      "[1.9311033e-17 1.0000000e+00]\n",
      "[4.1698455e-12 1.0000000e+00]\n",
      "[0.00249215 0.9975078 ]\n",
      "[0.00513959 0.99486035]\n",
      "[0.4925457  0.50745434]\n",
      "[2.7563909e-05 9.9997246e-01]\n",
      "[6.122828e-05 9.999387e-01]\n",
      "[2.6990623e-08 1.0000000e+00]\n",
      "[9.9995959e-01 4.0425293e-05]\n",
      "[0.00659184 0.9934082 ]\n",
      "[9.9955577e-01 4.4422256e-04]\n",
      "[4.8165389e-06 9.9999523e-01]\n",
      "[9.9969459e-01 3.0549132e-04]\n",
      "[0.7114866  0.28851342]\n",
      "[9.9992454e-01 7.5472635e-05]\n",
      "[0.00759124 0.99240875]\n",
      "[9.9979097e-01 2.0903371e-04]\n",
      "[0.98316413 0.01683584]\n",
      "[0.9961747  0.00382523]\n",
      "[9.995932e-01 4.067714e-04]\n",
      "[0.00611411 0.99388593]\n",
      "[0.6426961  0.35730392]\n",
      "[0.03339661 0.96660346]\n",
      "[9.9964166e-01 3.5837037e-04]\n",
      "[0.12317885 0.8768212 ]\n",
      "[0.00111267 0.99888736]\n",
      "[9.9935764e-01 6.4231222e-04]\n",
      "[4.3069568e-07 9.9999952e-01]\n",
      "[9.9935204e-01 6.4796337e-04]\n",
      "[0.9977222  0.00227783]\n",
      "[0.78332406 0.21667589]\n",
      "[0.9918018  0.00819826]\n",
      "[0.6746877 0.3253123]\n",
      "[2.3082076e-04 9.9976915e-01]\n",
      "[1.0657277e-04 9.9989343e-01]\n",
      "[8.492856e-05 9.999151e-01]\n",
      "[9.999602e-01 3.986715e-05]\n",
      "[0.05633082 0.94366926]\n",
      "[1.1972578e-07 9.9999988e-01]\n",
      "[9.999813e-01 1.873600e-05]\n",
      "[0.03900638 0.9609936 ]\n",
      "[0.00281475 0.9971853 ]\n",
      "[0.9641271  0.03587282]\n",
      "[4.937291e-07 9.999995e-01]\n",
      "[9.9979275e-01 2.0720669e-04]\n",
      "[0.94681054 0.05318944]\n",
      "[9.9931204e-01 6.8797148e-04]\n",
      "[9.9947101e-01 5.2904687e-04]\n",
      "[0.038524 0.961476]\n",
      "[0.86382365 0.1361763 ]\n",
      "[9.9976200e-01 2.3802667e-04]\n",
      "[9.9994051e-01 5.9505546e-05]\n",
      "[0.26758403 0.732416  ]\n",
      "[0.27396846 0.7260315 ]\n",
      "[3.0703973e-07 9.9999964e-01]\n",
      "[9.9999845e-01 1.5125105e-06]\n",
      "[0.99567825 0.00432175]\n",
      "correct = 107\n",
      "incorrect = 20\n",
      "error rate = 0.15748031496062992\n",
      "accuracy = 0.84251968503937\n",
      "total files = 127\n"
     ]
    }
   ],
   "source": [
    "dictionary_original_a = ha_eval_original([emotionFolders[1]])\n",
    "one_scores_original_a = dictionary_original_a.get('one_scores')\n",
    "zero_scores_original_a = dictionary_original_a.get('zero_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw the plot (evaluation on only unmodified, original wav files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 662.4x360 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x201eba880b8>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 662.4x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_names = ['Error Rate', 'Accuracy']\n",
    "graph_title = 'Evaluation on only unmodified, original wav files'\n",
    "results = {\n",
    "    'Happy': [dictionary_original_h.get('error_rate'), dictionary_original_h.get('accuracy')],\n",
    "    'Angry': [dictionary_original_a.get('error_rate'), dictionary_original_a.get('accuracy')]\n",
    "}\n",
    "\n",
    "draw(results, category_names, graph_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only evaluate reverberated wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Happy validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_reverbed_h = ha_eval_reverbed([emotionFolders[0]])\n",
    "\n",
    "one_scores_reverbed_h = dictionary_reverbed_h.get('one_scores')\n",
    "zero_scores_reverbed_h = dictionary_reverbed_h.get('zero_scores')\n",
    "\n",
    "wetdrys_reverbed_h = dictionary_reverbed_h.get('wetdrys')\n",
    "diffusions_reverbed_h = dictionary_reverbed_h.get('diffusions')\n",
    "decayfactors_reverbed_h = dictionary_reverbed_h.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Angry validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_reverbed_a = ha_eval_reverbed([emotionFolders[1]])\n",
    "\n",
    "one_scores_reverbed_a = dictionary_reverbed_a.get('one_scores')\n",
    "zero_scores_reverbed_a = dictionary_reverbed_a.get('zero_scores')\n",
    "\n",
    "wetdrys_reverbed_a = dictionary_reverbed_a.get('wetdrys')\n",
    "diffusions_reverbed_a = dictionary_reverbed_a.get('diffusions')\n",
    "decayfactors_reverbed_a = dictionary_reverbed_a.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw the plot (evaluation on only the reverberated wav files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Error Rate', 'Accuracy']\n",
    "graph_title = 'Evaluation on only the reverberated wav files'\n",
    "results = {\n",
    "    'Happy': [dictionary_reverbed_h.get('error_rate'), dictionary_reverbed_h.get('accuracy')],\n",
    "    'Angry': [dictionary_reverbed_a.get('error_rate'), dictionary_reverbed_a.get('accuracy')],\n",
    "}\n",
    "\n",
    "draw(results, category_names, graph_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_WetDry = [wetdrys_reverbed_h, zero_scores_reverbed_h]\n",
    "a_WetDry = [wetdrys_reverbed_a, one_scores_reverbed_a]\n",
    "\n",
    "title = 'How wet/dry ratio affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Wet/dry ratio'\n",
    "ylabel = 'Mean of the scores on the ground truth class of an audio clip'\n",
    "\n",
    "graphs.histogram(h_WetDry, a_WetDry, [[],[]], [[],[]], title, xlabel, ylabel)\n",
    "\n",
    "h_Diffusion = [diffusions_reverbed_h, zero_scores_reverbed_h]\n",
    "a_Diffusion = [diffusions_reverbed_a, one_scores_reverbed_a]\n",
    "\n",
    "title = 'How diffusion affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Diffusion value'\n",
    "ylabel = 'Mean of the scores on the ground truth class of an audio clip'\n",
    "\n",
    "graphs.histogram(h_Diffusion, a_Diffusion, [[],[]], [[],[]], title, xlabel, ylabel)\n",
    "\n",
    "h_DecayFactor = [decayfactors_reverbed_h, zero_scores_reverbed_h]\n",
    "a_DecayFactor = [decayfactors_reverbed_a, one_scores_reverbed_a]\n",
    "\n",
    "title = 'How the decay factor affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Decay factor value'\n",
    "ylabel = 'Mean of the scores on the ground truth class of an audio clip'\n",
    "\n",
    "graphs.histogram(h_DecayFactor, a_DecayFactor, [[],[]], [[],[]], title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only evaluate deamplified and noised wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Happy validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_deamplified_noised_h = ha_eval_deamplified_noised([emotionFolders[0]])\n",
    "\n",
    "one_scores_deamplified_noised_h = dictionary_deamplified_noised_h.get('one_scores')\n",
    "zero_scores_deamplified_noised_h = dictionary_deamplified_noised_h.get('zero_scores')\n",
    "deamplified_dbs_deamplified_noised_h = dictionary_deamplified_noised_h.get('deamplified_dbs')\n",
    "wetdrys_deamplified_noised_h = dictionary_deamplified_noised_h.get('wetdrys')\n",
    "diffusions_deamplified_noised_h = dictionary_deamplified_noised_h.get('diffusions')\n",
    "decayfactors_deamplified_noised_h = dictionary_deamplified_noised_h.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Angry validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_deamplified_noised_a = ha_eval_deamplified_noised([emotionFolders[1]])\n",
    "\n",
    "one_scores_deamplified_noised_a = dictionary_deamplified_noised_a.get('one_scores')\n",
    "zero_scores_deamplified_noised_a = dictionary_deamplified_noised_a.get('zero_scores')\n",
    "deamplified_dbs_deamplified_noised_a = dictionary_deamplified_noised_a.get('deamplified_dbs')\n",
    "wetdrys_deamplified_noised_a = dictionary_deamplified_noised_a.get('wetdrys')\n",
    "diffusions_deamplified_noised_a = dictionary_deamplified_noised_a.get('diffusions')\n",
    "decayfactors_deamplified_noised_a = dictionary_deamplified_noised_a.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw the plot (evaluation on only the wav files that are deamplified and mixed with noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Error Rate', 'Accuracy']\n",
    "graph_title = 'Error rate and accuracy on only the reverberated wav files'\n",
    "results = {\n",
    "    'Happy': [dictionary_deamplified_noised_h.get('error_rate'), dictionary_deamplified_noised_h.get('accuracy')],\n",
    "    'Angry': [dictionary_deamplified_noised_a.get('error_rate'), dictionary_deamplified_noised_a.get('accuracy')],\n",
    "}\n",
    "\n",
    "draw(results, category_names, graph_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [deamplified_dbs_deamplified_noised_h, zero_scores_deamplified_noised_h]\n",
    "a = [deamplified_dbs_deamplified_noised_a, one_scores_deamplified_noised_a]\n",
    "\n",
    "title = 'How deamplification affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Deamplified amount measured in decibels'\n",
    "ylabel = 'Score on the ground truth class of an audio clip'\n",
    "#graphs.draw_scatter(h, a, n, s, title, xlabel, ylabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs.draw_scatter(h, [[],[]], [[],[]], [[],[]], title, xlabel, ylabel)\n",
    "graphs.draw_scatter([[],[]], a, [[],[]], [[],[]], title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only evaluate deamplified and noised and reverberated wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Happy validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_deamplified_noised_reverbed_h = ha_eval_deamplified_noised_reverbed([emotionFolders[0]])\n",
    "\n",
    "one_scores_deamplified_noised_reverbed_h = dictionary_deamplified_noised_reverbed_h.get('one_scores')\n",
    "zero_scores_deamplified_noised_reverbed_h = dictionary_deamplified_noised_reverbed_h.get('zero_scores')\n",
    "deamplified_dbs_deamplified_noised_reverbed_h = dictionary_deamplified_noised_reverbed_h.get('deamplified_dbs')\n",
    "wetdrys_deamplified_noised_reverbed_h = dictionary_deamplified_noised_reverbed_h.get('wetdrys')\n",
    "diffusions_deamplified_noised_reverbed_h = dictionary_deamplified_noised_reverbed_h.get('diffusions')\n",
    "decayfactors_deamplified_noised_reverbed_h = dictionary_deamplified_noised_reverbed_h.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Angry validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_deamplified_noised_reverbed_a = ha_eval_deamplified_noised_reverbed([emotionFolders[1]])\n",
    "\n",
    "one_scores_deamplified_noised_reverbed_a = dictionary_deamplified_noised_reverbed_a.get('one_scores')\n",
    "zero_scores_deamplified_noised_reverbed_a = dictionary_deamplified_noised_reverbed_a.get('zero_scores')\n",
    "deamplified_dbs_deamplified_noised_reverbed_a = dictionary_deamplified_noised_reverbed_a.get('deamplified_dbs')\n",
    "wetdrys_deamplified_noised_reverbed_a = dictionary_deamplified_noised_reverbed_a.get('wetdrys')\n",
    "diffusions_deamplified_noised_reverbed_a = dictionary_deamplified_noised_reverbed_a.get('diffusions')\n",
    "decayfactors_deamplified_noised_reverbed_a = dictionary_deamplified_noised_reverbed_a.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw the plot (evaluation on only the wav files that are deamplified, mixed with noise, and reverberated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Error Rate', 'Accuracy']\n",
    "graph_title = 'Evaluation on only the wav files that are deamplified, mixed with noise, and reverberated'\n",
    "results = {\n",
    "    'Happy': [dictionary_deamplified_noised_reverbed_h.get('error_rate'), \\\n",
    "              dictionary_deamplified_noised_reverbed_h.get('accuracy')], \\\n",
    "    'Angry': [dictionary_deamplified_noised_reverbed_a.get('error_rate'), \\\n",
    "              dictionary_deamplified_noised_reverbed_a.get('accuracy')]\n",
    "}\n",
    "\n",
    "draw(results, category_names, graph_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = [deamplified_dbs_deamplified_noised_reverbed_h, zero_scores_deamplified_noised_reverbed_h]\n",
    "a = [deamplified_dbs_deamplified_noised_reverbed_a, one_scores_deamplified_noised_reverbed_a]\n",
    "\n",
    "title = 'How deamplification affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Deamplified amount measured in decibels'\n",
    "ylabel = 'Score on the ground truth class of an audio clip'\n",
    "#graphs.draw_scatter(h, a, n, s, title, xlabel, ylabel)\n",
    "graphs.draw_scatter(h, [[],[]], [[],[]], [[],[]], title, xlabel, ylabel)\n",
    "graphs.draw_scatter([[],[]], a, [[],[]], [[],[]], title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_WetDry = [wetdrys_deamplified_noised_reverbed_h, zero_scores_deamplified_noised_reverbed_h]\n",
    "a_WetDry = [wetdrys_deamplified_noised_reverbed_a, one_scores_deamplified_noised_reverbed_a]\n",
    "\n",
    "title = 'How wet/dry ratio affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Wet/dry ratio'\n",
    "ylabel = 'Mean of the scores on the ground truth class of an audio clip'\n",
    "graphs.histogram(h_WetDry, a_WetDry, [[],[]], [[],[]], title, xlabel, ylabel)\n",
    "\n",
    "h_Diffusion = [diffusions_deamplified_noised_reverbed_h, zero_scores_deamplified_noised_reverbed_h]\n",
    "a_Diffusion = [diffusions_deamplified_noised_reverbed_a, one_scores_deamplified_noised_reverbed_a]\n",
    "\n",
    "title = 'How diffusion affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Diffusion value'\n",
    "ylabel = 'Mean of the scores on the ground truth class of an audio clip'\n",
    "\n",
    "graphs.histogram(h_Diffusion, a_Diffusion, [[],[]], [[],[]], title, xlabel, ylabel)\n",
    "\n",
    "h_DecayFactor = [decayfactors_deamplified_noised_reverbed_h, zero_scores_deamplified_noised_reverbed_h]\n",
    "a_DecayFactor = [decayfactors_deamplified_noised_reverbed_a, one_scores_deamplified_noised_reverbed_a]\n",
    "\n",
    "title = 'How the decay factor affects the performance of the classifier in the presence of background noise'\n",
    "xlabel = 'Decay factor value'\n",
    "ylabel = 'Mean of the scores on the ground truth class of an audio clip'\n",
    "\n",
    "graphs.histogram(h_DecayFactor, a_DecayFactor, [[],[]], [[],[]], title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate all wav files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Happy validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all_h = ha_eval_all([emotionFolders[0]])\n",
    "\n",
    "one_scores_all_h = dictionary_all_h.get('one_scores')\n",
    "zero_scores_all_h = dictionary_all_h.get('zero_scores')\n",
    "deamplified_dbs_all_h = dictionary_all_h.get('deamplified_dbs')\n",
    "wetdrys_all_h = dictionary_all_h.get('wetdrys')\n",
    "diffusions_all_h = dictionary_all_h.get('diffusions')\n",
    "decayfactors_all_h = dictionary_all_h.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the set of Angry validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_all_a = ha_eval_all([emotionFolders[1]])\n",
    "\n",
    "one_scores_all_a = dictionary_all_a.get('one_scores')\n",
    "zero_scores_all_a = dictionary_all_a.get('zero_scores')\n",
    "deamplified_dbs_all_a = dictionary_all_a.get('deamplified_dbs')\n",
    "wetdrys_all_a = dictionary_all_a.get('wetdrys')\n",
    "diffusions_all_a = dictionary_all_a.get('diffusions')\n",
    "decayfactors_all_a = dictionary_all_a.get('decayfactors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draw the plot (evaluation on all the wav files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = ['Error Rate', 'Accuracy']\n",
    "graph_title = 'Evaluation on all the wav files'\n",
    "results = {\n",
    "    'Happy': [dictionary_all_h.get('error_rate'), dictionary_all_h.get('accuracy')],\n",
    "    'Angry': [dictionary_all_a.get('error_rate'), dictionary_all_a.get('accuracy')]\n",
    "}\n",
    "\n",
    "draw(results, category_names, graph_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
