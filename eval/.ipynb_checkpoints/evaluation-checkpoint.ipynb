{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "# print(len(backend.tensorflow_backend._get_available_gpus()) > 0)\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlappiong=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 272 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "sys.path.insert(1, '..//components//')\n",
    "import load_feat_directories\n",
    "\n",
    "# input new indices file here\n",
    "# indices_filename = 'D://indices_filename.npy'\n",
    "# indices=np.load(indices_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avail_modules(directory, prefix):\n",
    "    module_names = []\n",
    "    for item in os.listdir(directory):\n",
    "        if prefix in item:\n",
    "            module_names.append(directory + item)\n",
    "            i = module_names.index(directory + item)\n",
    "            print(str(i) + 'th module')\n",
    "            print(directory + item)\n",
    "    return module_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprise_vector(path, dist, reverb, noise):\n",
    "    vec_to_return = []\n",
    "    i = 0\n",
    "    for fname in os.listdir(path):\n",
    "        components = fname.split('_')\n",
    "        '''\n",
    "        if dist == 0 and 'deamp' in components: continue\n",
    "        if reverb == 0 and 'WetDry' in components: continue\n",
    "        if noise == 0 and 'noise' in components: continue\n",
    "        '''\n",
    "        current_vec = np.load(path + fname)\n",
    "        vec_to_return.append(current_vec)\n",
    "        print(components)\n",
    "        i += 1\n",
    "        if i > 5: break\n",
    "        \n",
    "    vec_to_return = np.array(vec_to_return)\n",
    "    return vec_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprise_label(feature_vector, label):\n",
    "    label_vec_to_ret = []\n",
    "    length = len(list(feature_vector))\n",
    "    for index in range(0, length):\n",
    "        current_label = [label]\n",
    "        label_vec_to_ret.append(current_label)\n",
    "    label_vec_to_ret = np.array(label_vec_to_ret)\n",
    "\n",
    "    return label_vec_to_ret\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]\n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "\n",
    "    return input_np\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allnoised_npy[0, 1, 2, 3, 4] ==> H, A, N, S, O\n",
    "# homenoised_npy[0, 1, 2, 3, 4] ==> H, A, N, S, O\n",
    "all_noised_npy = load_feat_directories.allnoised_npy\n",
    "all_noised_npy_test = load_feat_directories.allnoised_npy_test\n",
    "home_noised_npy = load_feat_directories.homenoised_npy\n",
    "home_noised_npy_test = load_feat_directories.homenoised_npy_test\n",
    "\n",
    "for index in range(0, 5):\n",
    "    if not os.path.exists(all_noised_npy[index]):\n",
    "        print(all_noised_npy[index] + ' does not exist. Breaking the loop... ')\n",
    "    if not os.path.exists(home_noised_npy[index]):\n",
    "        print(home_noised_npy[index] + 'does not exist. Breaking the loop... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Happy572.npy']\n",
      "['deamp', '8.219405347510113', 'noise', 'home', '82', 'Happy930', 'WetDry', '4', 'DecayFactor', '8', 'Diffusion', '3.npy']\n",
      "['deamp', '1.2934488993661284', 'noise', 'home', '82', 'Happy1194', 'WetDry', '8', 'DecayFactor', '8', 'Diffusion', '5.npy']\n",
      "['deamp', '6.434147943332854', 'noise', 'home', '80', 'Happy1101.npy']\n",
      "['deamp', '5.9416001922179795', 'noise', 'home', '80', 'Happy479.npy']\n",
      "['Happy1293', 'WetDry', '4', 'DecayFactor', '2', 'Diffusion', '5.npy']\n",
      "['deamp', '11.517513973209176', 'noise', 'home', '23', 'Angry681', 'WetDry', '6', 'DecayFactor', '6', 'Diffusion', '4.npy']\n",
      "['deamp', '3.904454911082019', 'noise', 'home', '23', 'Angry1166', 'WetDry', '8', 'DecayFactor', '2', 'Diffusion', '4.npy']\n",
      "['deamp', '2.8839094782798997', 'noise', 'home', '23', 'Angry1451', 'WetDry', '6', 'DecayFactor', '6', 'Diffusion', '5.npy']\n",
      "['deamp', '11.238322777532778', 'noise', 'home', '80', 'Angry310', 'WetDry', '4', 'DecayFactor', '6', 'Diffusion', '2.npy']\n",
      "['Angry680', 'WetDry', '4', 'DecayFactor', '2', 'Diffusion', '2.npy']\n",
      "['Angry804.npy']\n",
      "['deamp', '5.4832499065805385', 'noise', 'home', '81', 'Neutral493', 'WetDry', '2', 'DecayFactor', '4', 'Diffusion', '5.npy']\n",
      "['deamp', '0.31435362182237636', 'noise', 'home', '26', 'Neutral1401.npy']\n",
      "['deamp', '9.481002603718947', 'noise', 'home', '23', 'Neutral1350.npy']\n",
      "['Neutral872.npy']\n",
      "['deamp', '0.7786665639220978', 'noise', 'home', '81', 'Neutral1198', 'WetDry', '2', 'DecayFactor', '2', 'Diffusion', '6.npy']\n",
      "['deamp', '4.306535320576716', 'noise', 'home', '24', 'Neutral1397.npy']\n",
      "['Sad259', 'WetDry', '2', 'DecayFactor', '2', 'Diffusion', '5.npy']\n",
      "['Sad290', 'WetDry', '2', 'DecayFactor', '4', 'Diffusion', '3.npy']\n",
      "['deamp', '10.558837732807568', 'noise', 'home', '83', 'Sad271', 'WetDry', '6', 'DecayFactor', '8', 'Diffusion', '2.npy']\n",
      "['Sad429', 'WetDry', '2', 'DecayFactor', '6', 'Diffusion', '5.npy']\n",
      "['deamp', '10.162272890969474', 'noise', 'home', '81', 'Sad432', 'WetDry', '6', 'DecayFactor', '8', 'Diffusion', '4.npy']\n",
      "['deamp', '11.380477984207365', 'noise', 'home', '23', 'Sad1781.npy']\n"
     ]
    }
   ],
   "source": [
    "emotions = [0, 1, 2, 3]\n",
    "home_or_all = 'home'\n",
    "dist = 0\n",
    "reverb = 0\n",
    "noise = 0\n",
    "\n",
    "for index in emotions:\n",
    "    if home_or_all == 'home':\n",
    "        path = home_noised_npy_test[index]\n",
    "    else:\n",
    "        path = all_noised_npy_test[index]\n",
    "        \n",
    "    if index == 0:\n",
    "        val_h_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_h_label = comprise_label(val_h_feat, index)\n",
    "    elif index == 1:\n",
    "        val_a_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_a_label = comprise_label(val_a_feat, index)\n",
    "    elif index == 2:\n",
    "        val_n_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_n_label = comprise_label(val_n_feat, index)\n",
    "    elif index == 3:\n",
    "        val_s_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_s_label = comprise_label(val_s_feat, index)\n",
    "    else:\n",
    "        val_o_feat = comprise_vector(path, dist, reverb, noise)\n",
    "        val_o_label = comprise_label(val_o_feat, index)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation data: (1300, 48, 272)\n",
      "evaluation label: (1300, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load testing npy files\n",
    "featureSet_val = float_compatible(np.vstack((val_h_feat, val_a_feat, val_n_feat, val_s_feat)))\n",
    "Label_val = np.vstack((val_h_label, val_a_label, val_n_label, val_s_label))\n",
    "Label_val[Label_val == 0] = 0\n",
    "Label_val[Label_val == 1] = 0\n",
    "Label_val[Label_val == 2] = 1\n",
    "Label_val[Label_val == 3] = 1\n",
    "Label_val = to_categorical(Label_val)\n",
    "print('evaluation data: ' + str(featureSet_val.shape))\n",
    "print('evaluation label: ' + str(Label_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th module\n",
      "..//..//modules//Checkpoint_home_Top_neurons_home_2048_filters_512_dropout_0.2_epoch_1000_dense_2.hdf5\n",
      "1th module\n",
      "..//..//modules//Final_home_Top_neurons_home_2048_filters_512_dropout_0.2_epoch_1000_dense_2.hdf5\n"
     ]
    }
   ],
   "source": [
    "directory = '..//..//modules//'\n",
    "module_prefix = 'Top_'\n",
    "modules = avail_modules(directory, module_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot create group in read only mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5328bddd0e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot create group in read only mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create group in read only mode."
     ]
    }
   ],
   "source": [
    "title = modules[1]\n",
    "model = keras.models.load_model(top_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_eval_original(emotionFolders):\n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 0\n",
    "        if 'Neutral' in emotionFolder: val = 1\n",
    "        if 'Sad' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile\n",
    "            noise = 'noise_' in emotionfiles\n",
    "        \n",
    "            r_n = not dist and reverb and noise\n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise\n",
    "            \n",
    "            if original: # only consider the original samples\n",
    "                one_sample = np.load(emotionfile)\n",
    "                class_neg_score, class_pos_score = list(model.predict(np.array(one_sample)))\n",
    "                pos_scores.append([deamp_amount, class_pos_score])\n",
    "                neg_scores.append([deamp_amount, class_neg_score])\n",
    "                \n",
    "    mydict = {'pos_scores': pos_scores, 'neg_scores': neg_scores}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_eval_deamplify(emotionFolders):\n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 0\n",
    "        if 'Neutral' in emotionFolder: val = 1\n",
    "        if 'Sad' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile\n",
    "            noise = 'noise_' in emotionfiles\n",
    "        \n",
    "            r_n = not dist and reverb and noise\n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise\n",
    "            \n",
    "            if d: # only consider the effect of distance\n",
    "                components = fname.split('_')\n",
    "                deamp_amount = float(components[components.index('deamp') + 1])\n",
    "                one_sample = np.load(emotionfile)\n",
    "                class_neg_score, class_pos_score = list(model.predict(np.array(one_sample)))\n",
    "                pos_scores.append([deamp_amount, class_pos_score])\n",
    "                neg_scores.append([deamp_amount, class_neg_score])\n",
    "                \n",
    "    mydict = {'pos_scores': pos_scores, 'neg_scores': neg_scores}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_eval_deamplify_reverb(emotionFolders):\n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    pos_scores_diffusion = []\n",
    "    neg_scores_diffusion = []\n",
    "    pos_scores_wetdry = []\n",
    "    neg_scores_wetdry = []\n",
    "    pos_scores_decayfactor = []\n",
    "    neg_scores_decayfactor = []\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 0\n",
    "        if 'Neutral' in emotionFolder: val = 1\n",
    "        if 'Sad' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile\n",
    "            noise = 'noise_' in emotionfiles\n",
    "        \n",
    "            r_n = not dist and reverb and noise\n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise\n",
    "            \n",
    "            if d_r: # consider the effect of distance and reverberation\n",
    "                components = fname.split('_')  \n",
    "\n",
    "                deamp_amount = float(components[components.index('deamp') + 1])\n",
    "                diffusion = float((components[components.index('Diffusion') + 1].split('.')[0]))\n",
    "                wetdry = float(components[components.index('WetDry') + 1])\n",
    "                decayfactor = float(components[components.index('DecayFactor') + 1])\n",
    "                \n",
    "                one_sample = np.load(emotionfile)\n",
    "                class_neg_score, class_pos_score = list(model.predict(np.array(one_sample)))\n",
    "                \n",
    "                pos_scores.append([deamp_amount, class_pos_score])\n",
    "                neg_scores.append([deamp_amount, class_neg_score])\n",
    "                pos_scores_diffusion.append([diffusion, class_pos_score])\n",
    "                neg_scores_diffusion.append([diffusion, class_neg_score])\n",
    "                pos_scores_wetdry.append([wetdry, class_pos_score])\n",
    "                neg_scores_wetdry.append([wetdry, class_neg_score])\n",
    "                pos_scores_decayfactor.append([decayfactor, class_pos_score])\n",
    "                neg_scores_decayfactor.append([decayfactor, class_neg_score])\n",
    "                \n",
    "    mydict = {'neg_scores': neg_scores, 'pos_scores': pos_scores, \\\n",
    "              'neg_scores_diffusion': neg_scores_diffusion, 'pos_scores_diffusion': pos_scores_diffusion, \\\n",
    "              'neg_scores_wetdry': neg_scores_wetdry, 'pos_scores_wetdry': pos_scores_wetdry, \\\n",
    "              'neg_scores_decayfactor': neg_scores_decayfactor, 'pos_scores_decayfactor': pos_scores_decayfactor}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_classifier_dist_reverb_noise(emotionFolders):\n",
    "    print('Predicted with overall classifier: ' + hafilepath)\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    pos_scores = []\n",
    "    neg_scores = []\n",
    "    pos_scores_diffusion = []\n",
    "    neg_scores_diffusion = []\n",
    "    pos_scores_wetdry = []\n",
    "    neg_scores_wetdry = []\n",
    "    pos_scores_decayfactor = []\n",
    "    neg_scores_decayfactor = []\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        if 'Angry' in emotionFolder: val = 0\n",
    "        if 'Neutral' in emotionFolder: val = 1\n",
    "        if 'Sad' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            dist = 'deamp_' in emotionfile\n",
    "            reverb = 'WetDry_' in emotionfile\n",
    "            noise = 'noise_' in emotionfiles\n",
    "        \n",
    "            r_n = not dist and reverb and noise\n",
    "            r = not dist and reverb and not noise\n",
    "            n = not dist and not reverb and noise\n",
    "            original = not dist and not reverb and not noise\n",
    "            d_r_n = dist and reverb and noise\n",
    "            d_r = dist and reverb and not noise\n",
    "            d_n = dist and not reverb and noise\n",
    "            d = dist and not reverb and not noise\n",
    "\n",
    "            if d_r_n: # consider the effect of distance, reverberation, and noise\n",
    "                components = fname.split('_')\n",
    "                deamp_amount = float(components[components.index('deamp') + 1])\n",
    "                diffusion = float((components[components.index('Diffusion') + 1].split('.')[0]))\n",
    "                wetdry = float(components[components.index('WetDry') + 1])\n",
    "                decayfactor = float(components[components.index('DecayFactor') + 1])\n",
    "                one_sample = np.load(emotionfile)\n",
    "                class_neg_score, class_pos_score = list(model.predict(np.array(one_sample)))\n",
    "                \n",
    "                pos_scores.append([deamp_amount, class_pos_score])\n",
    "                neg_scores.append([deamp_amount, class_neg_score])\n",
    "                pos_scores_diffusion.append([diffusion, class_pos_score])\n",
    "                neg_scores_diffusion.append([diffusion, class_neg_score])\n",
    "                pos_scores_wetdry.append([wetdry, class_pos_score])\n",
    "                neg_scores_wetdry.append([wetdry, class_neg_score])\n",
    "                pos_scores_decayfactor.append([decayfactor, class_pos_score])\n",
    "                neg_scores_decayfactor.append([decayfactor, class_neg_score])\n",
    "    mydict = {'neg_scores': neg_scores, 'pos_scores': pos_scores, \\\n",
    "              'neg_scores_diffusion': neg_scores_diffusion, 'pos_scores_diffusion': pos_scores_diffusion, \\\n",
    "              'neg_scores_wetdry': neg_scores_wetdry, 'pos_scores_wetdry': pos_scores_wetdry, \\\n",
    "              'neg_scores_decayfactor': neg_scores_decayfactor, 'pos_scores_decayfactor': pos_scores_decayfactor}\n",
    "    return mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for item in list(Label_val):\n",
    "            if item[0] > item[1]:\n",
    "                y_true.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    for item in list(model.predict(featureSet_val)):\n",
    "            if item[0] > item[1]:\n",
    "                y_pred.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('f1 score: ' + str(f1_score(y_true, y_pred)))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print('true positive ' + str(tp))\n",
    "    print('false positive ' + str(fp))\n",
    "    print('false negative ' + str(fn))\n",
    "    print('true negative ' + str(tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
