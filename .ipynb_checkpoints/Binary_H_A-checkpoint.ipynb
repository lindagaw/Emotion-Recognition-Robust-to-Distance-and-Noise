{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (16632, 48, 272)\n",
      "training label: (16632, 2)\n",
      "evaluation data: (3684, 48, 272)\n",
      "evaluation label: (3684, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:192: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(48, 272), kernel_constraint=<keras.con..., filters=512, kernel_size=3)`\n",
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:210: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_constraint=<keras.con..., filters=1536, kernel_size=3)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 46, 512)           418304    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 46, 512)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 23, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 21, 1536)          2360832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 21, 1536)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 10, 1536)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 1536)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 30722     \n",
      "=================================================================\n",
      "Total params: 2,809,858\n",
      "Trainable params: 2,809,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:245: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12474 samples, validate on 4158 samples\n",
      "Epoch 1/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.6920 - acc: 0.5220 - val_loss: 0.6892 - val_acc: 0.5443\n",
      "Epoch 2/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6867 - acc: 0.5595 - val_loss: 0.6847 - val_acc: 0.5772\n",
      "Epoch 3/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6824 - acc: 0.5831 - val_loss: 0.6809 - val_acc: 0.5911\n",
      "Epoch 4/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6787 - acc: 0.5962 - val_loss: 0.6773 - val_acc: 0.5988\n",
      "Epoch 5/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6743 - acc: 0.6089 - val_loss: 0.6739 - val_acc: 0.6049\n",
      "Epoch 6/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6699 - acc: 0.6155 - val_loss: 0.6704 - val_acc: 0.6101\n",
      "Epoch 7/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6662 - acc: 0.6224 - val_loss: 0.6671 - val_acc: 0.6150\n",
      "Epoch 8/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.6625 - acc: 0.6304 - val_loss: 0.6640 - val_acc: 0.6154\n",
      "Epoch 9/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6590 - acc: 0.6340 - val_loss: 0.6608 - val_acc: 0.6207\n",
      "Epoch 10/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.6548 - acc: 0.6456 - val_loss: 0.6577 - val_acc: 0.6255\n",
      "Epoch 11/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6514 - acc: 0.6432 - val_loss: 0.6543 - val_acc: 0.6282\n",
      "Epoch 12/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.6476 - acc: 0.6535 - val_loss: 0.6512 - val_acc: 0.6325\n",
      "Epoch 13/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6445 - acc: 0.6546 - val_loss: 0.6482 - val_acc: 0.6352\n",
      "Epoch 14/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6407 - acc: 0.6595 - val_loss: 0.6453 - val_acc: 0.6443\n",
      "Epoch 15/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6373 - acc: 0.6647 - val_loss: 0.6427 - val_acc: 0.6441\n",
      "Epoch 16/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6333 - acc: 0.6702 - val_loss: 0.6394 - val_acc: 0.6477\n",
      "Epoch 17/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6302 - acc: 0.6713 - val_loss: 0.6370 - val_acc: 0.6484\n",
      "Epoch 18/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6266 - acc: 0.6741 - val_loss: 0.6340 - val_acc: 0.6554\n",
      "Epoch 19/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.6238 - acc: 0.6797 - val_loss: 0.6318 - val_acc: 0.6561\n",
      "Epoch 20/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6204 - acc: 0.6831 - val_loss: 0.6293 - val_acc: 0.6616\n",
      "Epoch 21/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6174 - acc: 0.6866 - val_loss: 0.6269 - val_acc: 0.6638\n",
      "Epoch 22/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6143 - acc: 0.6849 - val_loss: 0.6244 - val_acc: 0.6619\n",
      "Epoch 23/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6112 - acc: 0.6911 - val_loss: 0.6235 - val_acc: 0.6590\n",
      "Epoch 24/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6084 - acc: 0.6915 - val_loss: 0.6202 - val_acc: 0.6659\n",
      "Epoch 25/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6056 - acc: 0.6962 - val_loss: 0.6184 - val_acc: 0.6638\n",
      "Epoch 26/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.6030 - acc: 0.6968 - val_loss: 0.6163 - val_acc: 0.6681\n",
      "Epoch 27/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.6002 - acc: 0.6996 - val_loss: 0.6146 - val_acc: 0.6679\n",
      "Epoch 28/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.5980 - acc: 0.6999 - val_loss: 0.6128 - val_acc: 0.6688\n",
      "Epoch 29/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5954 - acc: 0.7064 - val_loss: 0.6112 - val_acc: 0.6712\n",
      "Epoch 30/1000\n",
      "12474/12474 [==============================] - 89s 7ms/step - loss: 0.5926 - acc: 0.7066 - val_loss: 0.6092 - val_acc: 0.6751\n",
      "Epoch 31/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.5909 - acc: 0.7066 - val_loss: 0.6076 - val_acc: 0.6753\n",
      "Epoch 32/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5876 - acc: 0.7086 - val_loss: 0.6064 - val_acc: 0.6765\n",
      "Epoch 33/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5867 - acc: 0.7092 - val_loss: 0.6045 - val_acc: 0.6763\n",
      "Epoch 34/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5837 - acc: 0.7106 - val_loss: 0.6037 - val_acc: 0.6797\n",
      "Epoch 35/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5814 - acc: 0.7136 - val_loss: 0.6017 - val_acc: 0.6797\n",
      "Epoch 36/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5799 - acc: 0.7160 - val_loss: 0.6003 - val_acc: 0.6801\n",
      "Epoch 37/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5777 - acc: 0.7175 - val_loss: 0.5995 - val_acc: 0.6789\n",
      "Epoch 38/1000\n",
      "12474/12474 [==============================] - 88s 7ms/step - loss: 0.5753 - acc: 0.7185 - val_loss: 0.5978 - val_acc: 0.6811\n",
      "Epoch 39/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5744 - acc: 0.7159 - val_loss: 0.5961 - val_acc: 0.6823\n",
      "Epoch 40/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.5709 - acc: 0.7203 - val_loss: 0.5953 - val_acc: 0.6816\n",
      "Epoch 41/1000\n",
      "12474/12474 [==============================] - 94s 8ms/step - loss: 0.5686 - acc: 0.7236 - val_loss: 0.5937 - val_acc: 0.6818\n",
      "Epoch 42/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.5668 - acc: 0.7275 - val_loss: 0.5923 - val_acc: 0.6842\n",
      "Epoch 43/1000\n",
      "12474/12474 [==============================] - 97s 8ms/step - loss: 0.5650 - acc: 0.7259 - val_loss: 0.5913 - val_acc: 0.6833\n",
      "Epoch 44/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.5625 - acc: 0.7296 - val_loss: 0.5899 - val_acc: 0.6859\n",
      "Epoch 45/1000\n",
      "12474/12474 [==============================] - 98s 8ms/step - loss: 0.5620 - acc: 0.7274 - val_loss: 0.5892 - val_acc: 0.6883\n",
      "Epoch 46/1000\n",
      "12474/12474 [==============================] - 98s 8ms/step - loss: 0.5604 - acc: 0.7282 - val_loss: 0.5875 - val_acc: 0.6893\n",
      "Epoch 47/1000\n",
      "12474/12474 [==============================] - 98s 8ms/step - loss: 0.5585 - acc: 0.7302 - val_loss: 0.5861 - val_acc: 0.6888\n",
      "Epoch 48/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.5561 - acc: 0.7297 - val_loss: 0.5851 - val_acc: 0.6922\n",
      "Epoch 49/1000\n",
      "12474/12474 [==============================] - 99s 8ms/step - loss: 0.5544 - acc: 0.7340 - val_loss: 0.5843 - val_acc: 0.6934\n",
      "Epoch 50/1000\n",
      "12474/12474 [==============================] - 100s 8ms/step - loss: 0.5526 - acc: 0.7360 - val_loss: 0.5828 - val_acc: 0.6926\n",
      "Epoch 51/1000\n",
      "12474/12474 [==============================] - 98s 8ms/step - loss: 0.5508 - acc: 0.7381 - val_loss: 0.5822 - val_acc: 0.6972\n",
      "Epoch 52/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.5492 - acc: 0.7367 - val_loss: 0.5808 - val_acc: 0.6962\n",
      "Epoch 53/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.5475 - acc: 0.7392 - val_loss: 0.5795 - val_acc: 0.6960\n",
      "Epoch 54/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.5456 - acc: 0.7426 - val_loss: 0.5785 - val_acc: 0.6991\n",
      "Epoch 55/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.5437 - acc: 0.7437 - val_loss: 0.5774 - val_acc: 0.6989\n",
      "Epoch 56/1000\n",
      "12474/12474 [==============================] - 106s 9ms/step - loss: 0.5422 - acc: 0.7428 - val_loss: 0.5772 - val_acc: 0.6977\n",
      "Epoch 57/1000\n",
      "12474/12474 [==============================] - 110s 9ms/step - loss: 0.5396 - acc: 0.7462 - val_loss: 0.5756 - val_acc: 0.7011\n",
      "Epoch 58/1000\n",
      "12474/12474 [==============================] - 110s 9ms/step - loss: 0.5385 - acc: 0.7441 - val_loss: 0.5745 - val_acc: 0.6996\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 109s 9ms/step - loss: 0.5371 - acc: 0.7447 - val_loss: 0.5748 - val_acc: 0.7035\n",
      "Epoch 60/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.5353 - acc: 0.7491 - val_loss: 0.5725 - val_acc: 0.7047\n",
      "Epoch 61/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.5334 - acc: 0.7508 - val_loss: 0.5729 - val_acc: 0.7035\n",
      "Epoch 62/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.5313 - acc: 0.7500 - val_loss: 0.5705 - val_acc: 0.7063\n",
      "Epoch 63/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5302 - acc: 0.7540 - val_loss: 0.5697 - val_acc: 0.7073\n",
      "Epoch 64/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.5288 - acc: 0.7514 - val_loss: 0.5683 - val_acc: 0.7080\n",
      "Epoch 65/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.5260 - acc: 0.7566 - val_loss: 0.5680 - val_acc: 0.7083\n",
      "Epoch 66/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5258 - acc: 0.7559 - val_loss: 0.5663 - val_acc: 0.7088\n",
      "Epoch 67/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5242 - acc: 0.7550 - val_loss: 0.5656 - val_acc: 0.7100\n",
      "Epoch 68/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.5211 - acc: 0.7609 - val_loss: 0.5656 - val_acc: 0.7112\n",
      "Epoch 69/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.5205 - acc: 0.7586 - val_loss: 0.5638 - val_acc: 0.7128\n",
      "Epoch 70/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5194 - acc: 0.7619 - val_loss: 0.5632 - val_acc: 0.7124\n",
      "Epoch 71/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5178 - acc: 0.7597 - val_loss: 0.5628 - val_acc: 0.7112\n",
      "Epoch 72/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5157 - acc: 0.7637 - val_loss: 0.5609 - val_acc: 0.7165\n",
      "Epoch 73/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5148 - acc: 0.7637 - val_loss: 0.5601 - val_acc: 0.7128\n",
      "Epoch 74/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.5129 - acc: 0.7650 - val_loss: 0.5593 - val_acc: 0.7119\n",
      "Epoch 75/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.5119 - acc: 0.7660 - val_loss: 0.5582 - val_acc: 0.7160\n",
      "Epoch 76/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5100 - acc: 0.7685 - val_loss: 0.5573 - val_acc: 0.7193\n",
      "Epoch 77/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.5084 - acc: 0.7686 - val_loss: 0.5581 - val_acc: 0.7138\n",
      "Epoch 78/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.5070 - acc: 0.7663 - val_loss: 0.5559 - val_acc: 0.7208\n",
      "Epoch 79/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.5061 - acc: 0.7695 - val_loss: 0.5546 - val_acc: 0.7191\n",
      "Epoch 80/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.5038 - acc: 0.7711 - val_loss: 0.5537 - val_acc: 0.7198\n",
      "Epoch 81/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.5028 - acc: 0.7712 - val_loss: 0.5533 - val_acc: 0.7227\n",
      "Epoch 82/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5015 - acc: 0.7727 - val_loss: 0.5524 - val_acc: 0.7184\n",
      "Epoch 83/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.5004 - acc: 0.7737 - val_loss: 0.5517 - val_acc: 0.7246\n",
      "Epoch 84/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4963 - acc: 0.7786 - val_loss: 0.5530 - val_acc: 0.7167\n",
      "Epoch 85/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4962 - acc: 0.7764 - val_loss: 0.5496 - val_acc: 0.7198\n",
      "Epoch 86/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.4957 - acc: 0.7747 - val_loss: 0.5494 - val_acc: 0.7203\n",
      "Epoch 87/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4945 - acc: 0.7767 - val_loss: 0.5484 - val_acc: 0.7198\n",
      "Epoch 88/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4923 - acc: 0.7810 - val_loss: 0.5475 - val_acc: 0.7213\n",
      "Epoch 89/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4906 - acc: 0.7809 - val_loss: 0.5462 - val_acc: 0.7249\n",
      "Epoch 90/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4896 - acc: 0.7827 - val_loss: 0.5467 - val_acc: 0.7217\n",
      "Epoch 91/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4878 - acc: 0.7798 - val_loss: 0.5464 - val_acc: 0.7275\n",
      "Epoch 92/1000\n",
      "12474/12474 [==============================] - 94s 8ms/step - loss: 0.4878 - acc: 0.7845 - val_loss: 0.5438 - val_acc: 0.7270\n",
      "Epoch 93/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4850 - acc: 0.7872 - val_loss: 0.5435 - val_acc: 0.7241\n",
      "Epoch 94/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4839 - acc: 0.7853 - val_loss: 0.5427 - val_acc: 0.7253\n",
      "Epoch 95/1000\n",
      "12474/12474 [==============================] - 94s 8ms/step - loss: 0.4821 - acc: 0.7881 - val_loss: 0.5418 - val_acc: 0.7275\n",
      "Epoch 96/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4804 - acc: 0.7875 - val_loss: 0.5422 - val_acc: 0.7302\n",
      "Epoch 97/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4789 - acc: 0.7900 - val_loss: 0.5415 - val_acc: 0.7302\n",
      "Epoch 98/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4768 - acc: 0.7900 - val_loss: 0.5394 - val_acc: 0.7280\n",
      "Epoch 99/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4763 - acc: 0.7920 - val_loss: 0.5387 - val_acc: 0.7311\n",
      "Epoch 100/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4754 - acc: 0.7877 - val_loss: 0.5378 - val_acc: 0.7321\n",
      "Epoch 101/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4738 - acc: 0.7914 - val_loss: 0.5381 - val_acc: 0.7328\n",
      "Epoch 102/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4714 - acc: 0.7948 - val_loss: 0.5372 - val_acc: 0.7282\n",
      "Epoch 103/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4708 - acc: 0.7953 - val_loss: 0.5360 - val_acc: 0.7299\n",
      "Epoch 104/1000\n",
      "12474/12474 [==============================] - 90s 7ms/step - loss: 0.4695 - acc: 0.7949 - val_loss: 0.5351 - val_acc: 0.7306\n",
      "Epoch 105/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4672 - acc: 0.7980 - val_loss: 0.5345 - val_acc: 0.7304\n",
      "Epoch 106/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4671 - acc: 0.7990 - val_loss: 0.5336 - val_acc: 0.7321\n",
      "Epoch 107/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4642 - acc: 0.8004 - val_loss: 0.5333 - val_acc: 0.7326\n",
      "Epoch 108/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4639 - acc: 0.8009 - val_loss: 0.5319 - val_acc: 0.7340\n",
      "Epoch 109/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4635 - acc: 0.8001 - val_loss: 0.5313 - val_acc: 0.7326\n",
      "Epoch 110/1000\n",
      "12474/12474 [==============================] - 94s 8ms/step - loss: 0.4633 - acc: 0.8013 - val_loss: 0.5316 - val_acc: 0.7364\n",
      "Epoch 111/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4592 - acc: 0.8046 - val_loss: 0.5294 - val_acc: 0.7403\n",
      "Epoch 112/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4586 - acc: 0.8062 - val_loss: 0.5307 - val_acc: 0.7342\n",
      "Epoch 113/1000\n",
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4562 - acc: 0.8053 - val_loss: 0.5281 - val_acc: 0.7386\n",
      "Epoch 114/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4549 - acc: 0.8074 - val_loss: 0.5278 - val_acc: 0.7354\n",
      "Epoch 115/1000\n",
      "12474/12474 [==============================] - 91s 7ms/step - loss: 0.4537 - acc: 0.8061 - val_loss: 0.5267 - val_acc: 0.7412\n",
      "Epoch 116/1000\n",
      "12474/12474 [==============================] - 92s 7ms/step - loss: 0.4538 - acc: 0.8043 - val_loss: 0.5258 - val_acc: 0.7395\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474/12474 [==============================] - 93s 7ms/step - loss: 0.4517 - acc: 0.8090 - val_loss: 0.5251 - val_acc: 0.7412\n",
      "Epoch 118/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.4497 - acc: 0.8094 - val_loss: 0.5274 - val_acc: 0.7386\n",
      "Epoch 119/1000\n",
      "12474/12474 [==============================] - 95s 8ms/step - loss: 0.4493 - acc: 0.8120 - val_loss: 0.5241 - val_acc: 0.7391\n",
      "Epoch 120/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.4477 - acc: 0.8148 - val_loss: 0.5236 - val_acc: 0.7381\n",
      "Epoch 121/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.4467 - acc: 0.8108 - val_loss: 0.5221 - val_acc: 0.7429\n",
      "Epoch 122/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.4449 - acc: 0.8147 - val_loss: 0.5219 - val_acc: 0.7407\n",
      "Epoch 123/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.4437 - acc: 0.8135 - val_loss: 0.5206 - val_acc: 0.7443\n",
      "Epoch 124/1000\n",
      "12474/12474 [==============================] - 97s 8ms/step - loss: 0.4409 - acc: 0.8183 - val_loss: 0.5201 - val_acc: 0.7458\n",
      "Epoch 125/1000\n",
      "12474/12474 [==============================] - 96s 8ms/step - loss: 0.4410 - acc: 0.8143 - val_loss: 0.5193 - val_acc: 0.7446\n",
      "Epoch 126/1000\n",
      "12474/12474 [==============================] - 97s 8ms/step - loss: 0.4396 - acc: 0.8177 - val_loss: 0.5187 - val_acc: 0.7460\n",
      "Epoch 127/1000\n",
      "12474/12474 [==============================] - 97s 8ms/step - loss: 0.4390 - acc: 0.8167 - val_loss: 0.5177 - val_acc: 0.7460\n",
      "Epoch 128/1000\n",
      "12474/12474 [==============================] - 97s 8ms/step - loss: 0.4357 - acc: 0.8183 - val_loss: 0.5170 - val_acc: 0.7470\n",
      "Epoch 129/1000\n",
      "12474/12474 [==============================] - 97s 8ms/step - loss: 0.4359 - acc: 0.8219 - val_loss: 0.5170 - val_acc: 0.7439\n",
      "Epoch 130/1000\n",
      "12474/12474 [==============================] - 98s 8ms/step - loss: 0.4328 - acc: 0.8219 - val_loss: 0.5161 - val_acc: 0.7484\n",
      "Epoch 131/1000\n",
      "12474/12474 [==============================] - 99s 8ms/step - loss: 0.4323 - acc: 0.8209 - val_loss: 0.5150 - val_acc: 0.7489\n",
      "Epoch 132/1000\n",
      "12474/12474 [==============================] - 100s 8ms/step - loss: 0.4307 - acc: 0.8227 - val_loss: 0.5144 - val_acc: 0.7494\n",
      "Epoch 133/1000\n",
      "12474/12474 [==============================] - 98s 8ms/step - loss: 0.4290 - acc: 0.8236 - val_loss: 0.5136 - val_acc: 0.7492\n",
      "Epoch 134/1000\n",
      "12474/12474 [==============================] - 99s 8ms/step - loss: 0.4284 - acc: 0.8228 - val_loss: 0.5136 - val_acc: 0.7470\n",
      "Epoch 135/1000\n",
      "12474/12474 [==============================] - 99s 8ms/step - loss: 0.4276 - acc: 0.8267 - val_loss: 0.5126 - val_acc: 0.7482\n",
      "Epoch 136/1000\n",
      "12474/12474 [==============================] - 100s 8ms/step - loss: 0.4265 - acc: 0.8274 - val_loss: 0.5118 - val_acc: 0.7492\n",
      "Epoch 137/1000\n",
      "12474/12474 [==============================] - 99s 8ms/step - loss: 0.4249 - acc: 0.8248 - val_loss: 0.5108 - val_acc: 0.7496\n",
      "Epoch 138/1000\n",
      "12474/12474 [==============================] - 100s 8ms/step - loss: 0.4231 - acc: 0.8276 - val_loss: 0.5101 - val_acc: 0.7501\n",
      "Epoch 139/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4229 - acc: 0.8280 - val_loss: 0.5141 - val_acc: 0.7504\n",
      "Epoch 140/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4209 - acc: 0.8278 - val_loss: 0.5084 - val_acc: 0.7496\n",
      "Epoch 141/1000\n",
      "12474/12474 [==============================] - 99s 8ms/step - loss: 0.4195 - acc: 0.8321 - val_loss: 0.5083 - val_acc: 0.7523\n",
      "Epoch 142/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4183 - acc: 0.8310 - val_loss: 0.5093 - val_acc: 0.7532\n",
      "Epoch 143/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4165 - acc: 0.8309 - val_loss: 0.5075 - val_acc: 0.7494\n",
      "Epoch 144/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4151 - acc: 0.8326 - val_loss: 0.5069 - val_acc: 0.7516\n",
      "Epoch 145/1000\n",
      "12474/12474 [==============================] - 102s 8ms/step - loss: 0.4150 - acc: 0.8361 - val_loss: 0.5058 - val_acc: 0.7489\n",
      "Epoch 146/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4121 - acc: 0.8368 - val_loss: 0.5065 - val_acc: 0.7552\n",
      "Epoch 147/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4111 - acc: 0.8377 - val_loss: 0.5037 - val_acc: 0.7528\n",
      "Epoch 148/1000\n",
      "12474/12474 [==============================] - 102s 8ms/step - loss: 0.4086 - acc: 0.8393 - val_loss: 0.5033 - val_acc: 0.7530\n",
      "Epoch 149/1000\n",
      "12474/12474 [==============================] - 108s 9ms/step - loss: 0.4092 - acc: 0.8385 - val_loss: 0.5026 - val_acc: 0.7540\n",
      "Epoch 150/1000\n",
      "12474/12474 [==============================] - 105s 8ms/step - loss: 0.4089 - acc: 0.8359 - val_loss: 0.5016 - val_acc: 0.7540\n",
      "Epoch 151/1000\n",
      "12474/12474 [==============================] - 103s 8ms/step - loss: 0.4054 - acc: 0.8382 - val_loss: 0.5012 - val_acc: 0.7552\n",
      "Epoch 152/1000\n",
      "12474/12474 [==============================] - 103s 8ms/step - loss: 0.4048 - acc: 0.8389 - val_loss: 0.5018 - val_acc: 0.7571\n",
      "Epoch 153/1000\n",
      "12474/12474 [==============================] - 102s 8ms/step - loss: 0.4051 - acc: 0.8397 - val_loss: 0.5001 - val_acc: 0.7578\n",
      "Epoch 154/1000\n",
      "12474/12474 [==============================] - 101s 8ms/step - loss: 0.4024 - acc: 0.8422 - val_loss: 0.4989 - val_acc: 0.7573\n",
      "Epoch 155/1000\n",
      "12474/12474 [==============================] - 102s 8ms/step - loss: 0.4018 - acc: 0.8442 - val_loss: 0.4989 - val_acc: 0.7593\n",
      "Epoch 156/1000\n",
      "12474/12474 [==============================] - 103s 8ms/step - loss: 0.4001 - acc: 0.8447 - val_loss: 0.4983 - val_acc: 0.7590\n",
      "Epoch 157/1000\n",
      "12288/12474 [============================>.] - ETA: 1s - loss: 0.3998 - acc: 0.8460"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-57d24dec7c17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[0mfinal_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_Layer(s)//Final_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;31m#model = load_model(final_filepath)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[0mpredict_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-57d24dec7c17>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_monitor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "# print(len(backend.tensorflow_backend._get_available_gpus()) > 0)\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "sample_rate = 44100\n",
    "frame_number = 48\n",
    "hop_length = 441  # frame size= 2 * hop\n",
    "segment_length = int(sample_rate * 0.2)  # 0.2\n",
    "segment_pad = int(sample_rate * 0.02)     # 0.02\n",
    "overlapping = int(sample_rate * 0.1)   # 0.1\n",
    "\n",
    "classes = 2\n",
    "NumofFeaturetoUse = 100\n",
    "n_neurons = 4096\n",
    "dense_layers = 1\n",
    "num_layers = 2\n",
    "fillength = 10\n",
    "nbindex = 512\n",
    "dropout = 0.1\n",
    "n_batch = 128\n",
    "n_epoch = 1000\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "prefix = '..//'\n",
    "h_feature_vector = np.load(prefix + 'Features//h_feature_vector_48.npy')\n",
    "h_label_vector = np.load(prefix + 'Features//h_label_vector_48.npy')\n",
    "a_feature_vector = np.load(prefix + 'Features//a_feature_vector_48.npy')\n",
    "a_label_vector = np.load(prefix + 'Features//a_label_vector_48.npy')\n",
    "n_feature_vector = np.load(prefix + 'Features//n_feature_vector_48.npy')\n",
    "n_label_vector = np.load(prefix + 'Features//n_label_vector_48.npy')\n",
    "s_feature_vector = np.load(prefix + 'Features//s_feature_vector_48.npy')\n",
    "s_label_vector = np.load(prefix + 'Features//s_label_vector_48.npy')\n",
    "\n",
    "h_feature_vector_test = np.load(prefix + 'Features//h_feature_vector_test_48.npy')\n",
    "h_label_vector_test = np.load(prefix + 'Features//h_label_vector_test_48.npy')\n",
    "a_feature_vector_test = np.load(prefix + 'Features//a_feature_vector_test_48.npy')\n",
    "a_label_vector_test = np.load(prefix + 'Features//a_label_vector_test_48.npy')\n",
    "n_feature_vector_test = np.load(prefix + 'Features//n_feature_vector_test_48.npy')\n",
    "n_label_vector_test = np.load(prefix + 'Features//n_label_vector_test_48.npy')\n",
    "s_feature_vector_test = np.load(prefix + 'Features//s_feature_vector_test_48.npy')\n",
    "s_label_vector_test = np.load(prefix + 'Features//s_label_vector_test_48.npy')\n",
    "\n",
    "h_label_vector[h_label_vector == 0] = 0\n",
    "a_label_vector[a_label_vector == 1] = 1\n",
    "h_label_vector_test[h_label_vector_test == 0] = 0\n",
    "a_label_vector_test[a_label_vector_test == 1] = 1\n",
    "\n",
    "h_label_vector = to_categorical(h_label_vector, num_classes = 2)\n",
    "a_label_vector = to_categorical(a_label_vector, num_classes = 2)\n",
    "h_label_vector_test = to_categorical(h_label_vector_test, num_classes = 2)\n",
    "a_label_vector_test = to_categorical(a_label_vector_test, num_classes = 2)\n",
    "\n",
    "# Load training npy files\n",
    "featureSet_training = np.vstack((h_feature_vector, a_feature_vector))\n",
    "label_training = np.vstack((h_label_vector, a_label_vector))\n",
    "\n",
    "# Load testing npy files\n",
    "featureSet_testing = np.vstack((h_feature_vector_test, a_feature_vector_test))\n",
    "label_testing = np.vstack((h_label_vector_test, a_label_vector_test))\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]      \n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "        \n",
    "    return input_np\n",
    "\n",
    "train_data = float_compatible((featureSet_training).astype(np.float32))\n",
    "eval_data = float_compatible((featureSet_testing).astype(np.float32))\n",
    "\n",
    "adam = optimizers.Adam(lr = 3e-6, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0, amsgrad = True)\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "rmsprop = optimizers.RMSprop(lr = 0.0001, rho = 0.9, epsilon = None, decay = 0.0)\n",
    "adagrad = optimizers.Adagrad(lr = 0.01, epsilon = None, decay = 0.0)\n",
    "adadelta = optimizers.Adadelta(lr = 1.0, rho = 0.95, epsilon = None, decay = 0.0)\n",
    "adamax = optimizers.Adamax(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0)\n",
    "nadam = optimizers.Nadam(lr = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, schedule_decay = 0.004)\n",
    "\n",
    "featureSet = train_data\n",
    "Label = label_training\n",
    "featureSet = np.split(featureSet, np.array([NumofFeaturetoUse]), axis = 2)[0]\n",
    "\n",
    "print('training data: ' + str(featureSet.shape))\n",
    "print('training label: ' + str(Label.shape))\n",
    "\n",
    "featureSet_val = eval_data\n",
    "Label_val = label_testing\n",
    "featureSet_val = np.split(featureSet_val, np.array([NumofFeaturetoUse]), axis = 2)[0]\n",
    "\n",
    "print('evaluation data: ' + str(featureSet_val.shape))\n",
    "print('evaluation label: ' + str(Label_val.shape))\n",
    "\n",
    "def record(str_message, log_file):\n",
    "    str_message = str_message + '\\n'\n",
    "    file = open(log_file, 'a')\n",
    "    file.write(str_message)\n",
    "    file.close()\n",
    "\n",
    "def create_cnn(title, num_layers, n_neurons, n_batch, nbindex, dropout, classes, dense_layers):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution1D(nb_filter=nbindex, filter_length=fillength,\n",
    "                            input_shape=(featureSet.shape[1], featureSet.shape[2]), kernel_constraint=maxnorm(3)))\n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "    '''\n",
    "    model.add(Convolution1D(nb_filter=nbindex*2, filter_length=fillength,\n",
    "                            kernel_constraint=maxnorm(3)))\n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution1D(nb_filter=nbindex*3, filter_length=fillength,\n",
    "                            kernel_constraint=maxnorm(3)))\n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "    '''\n",
    "    model.add(Convolution1D(nb_filter=nbindex*5, filter_length=fillength,\n",
    "                            kernel_constraint=maxnorm(3)))  \n",
    "    model.add(LeakyReLU(alpha=0.05))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_cnn():\n",
    "    \n",
    "    save_to_path = prefix + str(num_layers) + \"_Layer(s)//\"\n",
    "\n",
    "    checkpoint_filepath = prefix + str(num_layers) + \"_Layer(s)//Checkpoint_\" + title + \".hdf5\"\n",
    "    final_filepath = prefix + str(num_layers) + \"_Layer(s)//Final_\" + title + \".hdf5\"\n",
    "\n",
    "    if not os.path.exists(save_to_path):\n",
    "        os.mkdir(save_to_path)\n",
    "\n",
    "    X, X_test, Y, Y_test= train_test_split(featureSet, Label, test_size = 0.25, shuffle = True)\n",
    "\n",
    "    model = create_cnn(title, num_layers, n_neurons, n_batch, nbindex, dropout, classes, dense_layers)\n",
    "\n",
    "    checkpoint = ModelCheckpoint(checkpoint_filepath, monitor = 'val_loss', verbose = 0, save_best_only = True, mode = 'auto')\n",
    "\n",
    "    early_stopping_monitor = EarlyStopping(patience = 50)\n",
    "\n",
    "    callbacks_list = [checkpoint, early_stopping_monitor]\n",
    "\n",
    "    model.fit(X, Y, nb_epoch = n_epoch, batch_size = n_batch,  callbacks = callbacks_list, validation_data = (X_test, Y_test), verbose = 1)\n",
    "\n",
    "    model.save_weights(final_filepath)\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_cnn(model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for item in list(Label_val):\n",
    "            if item[0] > item[1]:\n",
    "                y_true.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    for item in list(model.predict(featureSet_val)):\n",
    "            if item[0] > item[1]:\n",
    "                y_pred.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('f1 score: ' + str(f1_score(y_true, y_pred)))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print('true positive ' + str(tp))\n",
    "    print('false positive ' + str(fp))\n",
    "    print('false negative ' + str(fn))\n",
    "    print('true negative ' + str(tn))\n",
    "\n",
    "title = 'H_A_neurons_' + str(n_neurons) + '_filters_' + str(\n",
    "    nbindex) + '_dropout_' + str(dropout) + '_epoch_' + str(n_epoch)\n",
    "\n",
    "final_filepath = prefix + str(num_layers) + \"_Layer(s)//Final_\" + title + \".hdf5\"\n",
    "#model = load_model(final_filepath)\n",
    "model = train_cnn()\n",
    "predict_cnn(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
