{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from pydub import AudioSegment\n",
    "from xml.dom import minidom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pysndfx import AudioEffectsChain\n",
    "from librosa import load\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"D://Background_noise//meta.txt\",\"r\")\n",
    "match_noise_to_type = []\n",
    "content = f.readlines()\n",
    "\n",
    "for line in content:\n",
    "    y = line.split('\t')\n",
    "    audio_filename = y[0][6:len(y[0])]\n",
    "    audio_category = y[1][0:len(y[1])-1].replace('/', '_')\n",
    "    \n",
    "    match_noise_to_type.append((audio_filename, audio_category))\n",
    "\n",
    "noise_dict = dict(match_noise_to_type)\n",
    "#print(noise_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Happy//';\n",
    "a_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Angry//';\n",
    "n_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Neutral//';\n",
    "s_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Sad//';\n",
    "o_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Other//';\n",
    "\n",
    "h_test_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Happy_test//'\n",
    "a_test_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Angry_test//'\n",
    "n_test_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Neutral_test//'\n",
    "s_test_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Sad_test//'\n",
    "o_test_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised_reverberated//Other_test//'\n",
    "\n",
    "emotion_train_all = [h_directory_all, a_directory_all, n_directory_all, s_directory_all, o_directory_all]\n",
    "emotion_test_all = [h_test_all, a_test_all, n_test_all, s_test_all, o_test_all]\n",
    "\n",
    "h_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Happy//';\n",
    "a_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Angry//';\n",
    "n_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Neutral//';\n",
    "s_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Sad//';\n",
    "o_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Other//';\n",
    "\n",
    "h_test_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Happy_test//'\n",
    "a_test_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Angry_test//'\n",
    "n_test_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Neutral_test//'\n",
    "s_test_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Sad_test//'\n",
    "o_test_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised_reverberated//Other_test//'\n",
    "\n",
    "background_noise = 'D://Background_noise//TUT2016//'\n",
    "background_noise_test = 'D://Background_noise//noise_test//'\n",
    "\n",
    "background_noise_all = 'D://Background_noise//noise_all//'\n",
    "background_noise_home = 'D://Background_noise//noise_home//'\n",
    "\n",
    "emotion_train_home = [h_directory_home, a_directory_home, n_directory_home, s_directory_home, o_directory_home]\n",
    "emotion_test_home = [h_test_home, a_test_home, n_test_home, s_test_home, o_test_home]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaFE_happy = 'D://Datasets//CaFE//Happy//'\n",
    "CaFE_angry = 'D://Datasets//CaFE//Angry//'\n",
    "CaFE_neutral = 'D://Datasets//CaFE//Neutral//'\n",
    "CaFE_sad = 'D://Datasets//CaFE//Sad//'\n",
    "\n",
    "CaFEs = [CaFE_happy, CaFE_angry, CaFE_neutral, CaFE_sad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_emotion_wavs(emotion_directory):\n",
    "    if 'Happy' in emotion_directory:\n",
    "        word = 'Happy'\n",
    "    elif 'Angry' in emotion_directory:\n",
    "        word = 'Angry'\n",
    "    elif 'Neutral' in emotion_directory:\n",
    "        word = 'Neutral'\n",
    "    elif 'Sad' in emotion_directory:\n",
    "        word = 'Sad'\n",
    "    else:\n",
    "        word = 'Other'\n",
    "    \n",
    "    index = 0\n",
    "    for file in os.listdir(emotion_directory):\n",
    "        src = emotion_directory + file\n",
    "        dst = emotion_directory + word + str(index) + '.wav'\n",
    "        try:\n",
    "            os.rename(src, dst)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        index += 1\n",
    "        print(dst)\n",
    "        \n",
    "#rename_emotion_wavs(h_directory)\n",
    "#rename_emotion_wavs(a_directory)\n",
    "#rename_emotion_wavs(n_directory)\n",
    "#rename_emotion_wavs(s_directory)\n",
    "#rename_emotion_wavs(o_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_noise_wavs(noise_directory):\n",
    "    index = 0\n",
    "    for noise in os.listdir(noise_directory):\n",
    "        noise_type = noise_dict.get(noise)\n",
    "        new_noise_name = noise_type + '_' + str(index)\n",
    "        src = noise_directory + noise\n",
    "        dst = noise_directory + new_noise_name + '.wav'\n",
    "        os.rename(src, dst) \n",
    "        index += 1\n",
    "\n",
    "        print(dst)\n",
    "\n",
    "#rename_noise_wavs(background_noise_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_directory(path):\n",
    "    shutil.rmtree(path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_directory(path, new_path, percent):\n",
    "    \n",
    "    if not os.path.exists(new_path):\n",
    "        os.mkdir(new_path)\n",
    "    else:\n",
    "        delete_directory(new_path)\n",
    "        os.makdir(new_path)\n",
    "        \n",
    "    total = len(os.listdir(path))\n",
    "    test_number = int(total * percent)\n",
    "    test_set = np.random.permutation(total)[0:test_number]\n",
    "    \n",
    "    for index in test_set:\n",
    "        try:\n",
    "            if os.listdir(path)[index].endswith('.wav'):\n",
    "                original_location = path + os.listdir(path)[index]\n",
    "                new_location = new_path + os.listdir(path)[index]\n",
    "                os.rename(original_location, new_location)\n",
    "                print(new_location)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    print('# of training data + # of testing data = ' + str(total))\n",
    "    print(str(percent) + ' of the data is in training set')\n",
    "    print('# of training data = ' + str(test_set.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_silence_per_file(emotionfile, newSoundFile):\n",
    "    \n",
    "    emotionsound = AudioSegment.from_wav(emotionfile)\n",
    "    file_duration = emotionsound.duration_seconds * 1000\n",
    "    silence = AudioSegment.silent(duration=5000)\n",
    "    threshold = 5000 - file_duration\n",
    "    if threshold > 0:\n",
    "        overlay_start = np.random.randint(0, threshold)\n",
    "    else:\n",
    "        emotionsound = emotionsound[0:5000]\n",
    "        overlay_start = 0\n",
    "    \n",
    "    newSound = silence.overlay(emotionsound, position=overlay_start)\n",
    "    \n",
    "    newSound=newSound[0:5000]\n",
    "    newSound.export(newSoundFile, format='wav')  ### save the new generated file in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_silence_per_folder(directory, extension):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(extension) and file[0] != '.':\n",
    "            newSoundFile = directory + file\n",
    "            \n",
    "            if newSoundFile.endswith('.aiff'):\n",
    "                newSoundFile = directory + file[:len(file)-4] + '.wav'\n",
    "            \n",
    "            pad_silence_per_file(newSoundFile, newSoundFile)\n",
    "            print(newSoundFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_silence_per_folder(CaFEs[0], '.aiff')\n",
    "pad_silence_per_folder(CaFEs[1], '.aiff')\n",
    "pad_silence_per_folder(CaFEs[2], '.aiff')\n",
    "pad_silence_per_folder(CaFEs[3], '.aiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_amplitude(emotionfile, d1, newSoundFile, d2):\n",
    "    \n",
    "    if d1 <= d2:\n",
    "        sound = AudioSegment.from_file(emotionfile) - np.random.randint(0, (6 * d2/d1 - 1))\n",
    "        sound.export(newSoundFile, format='wav')  ### save the new generated file in a folder\n",
    "    else:\n",
    "        print('Invalid distance parameters. d1 should be <= d2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_amplitude_range(emotionfile, newSoundFile, threshold):\n",
    "    #amount = np.random.randint(0, threshold)\n",
    "    amount = random.uniform(0, threshold)\n",
    "    #print('Deamplify ' + str(emotionfile) + ' by ' + str(amount) + ' db.')\n",
    "    sound = AudioSegment.from_file(emotionfile) - amount\n",
    "    sound.export(newSoundFile, format='wav')  ### save the new generated file in a folder\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef deamplify_per_folder(directory):\\n    for file in os.listdir(directory):\\n        if file.endswith('.wav'):\\n            soundFile = directory + file\\n            newSoundFile = directory + 'deamplified_' + file\\n            change_amplitude_range(soundFile, newSoundFile, 12)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def deamplify_per_folder(directory):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith('.wav'):\n",
    "            soundFile = directory + file\n",
    "            newSoundFile = directory + 'deamplified_' + file\n",
    "            change_amplitude_range(soundFile, newSoundFile, 12)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor directory in emotion_train_folders:\\n    deamplify_per_folder(directory)\\n    \\nfor directory in emotion_test_folders:\\n    deamplify_per_folder(directory)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for directory in emotion_train_folders:\n",
    "    deamplify_per_folder(directory)\n",
    "    \n",
    "for directory in emotion_test_folders:\n",
    "    deamplify_per_folder(directory)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_per_file(emotionfile, bgnoise, newSoundFile):\n",
    "    \n",
    "    emotionsound = AudioSegment.from_wav(emotionfile)\n",
    "    emotion_duration = emotionsound.duration_seconds * 1000\n",
    "    noise = AudioSegment.from_wav(bgnoise)\n",
    "    noise_duration = noise.duration_seconds * 1000\n",
    "    \n",
    "    threshold = noise_duration - emotion_duration\n",
    "    \n",
    "    if threshold > 0:\n",
    "        overlay_start = np.random.randint(0, threshold)\n",
    "    else:\n",
    "        overlay_start = 0\n",
    "        \n",
    "    targeted_chunk = noise[overlay_start:overlay_start + emotion_duration]\n",
    "    newSound = emotionsound.overlay(targeted_chunk, position=0)\n",
    "    newSound=newSound[0:5000]\n",
    "    newSound.export(newSoundFile, format='wav')  ### save the new generated file in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_and_deamplify_per_folder(directory, extension, noise_directory):\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(extension) and not file[1] == '_':\n",
    "            for i in range(0, 2):\n",
    "                soundFile = directory + file\n",
    "                amount = change_amplitude_range(soundFile, soundFile, 12)\n",
    "                noise = random.choice(os.listdir(noise_directory))\n",
    "                random_noise = noise_directory + noise\n",
    "                newSoundFile = directory + 'deamp_' + str(amount) + '_noise_' + noise[:len(noise)-5] + '_' + file\n",
    "                add_noise_per_file(soundFile, random_noise, newSoundFile)\n",
    "                print(newSoundFile)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in CaFEs:\n",
    "    add_noise_and_deamplify_per_folder(item, 'wav', background_noise_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised//Neutral//'\n",
    "s_directory_all = 'D://Datasets//TRAINING//padded_deamplified_allnoised//Sad//'\n",
    "\n",
    "n_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised//Neutral//'\n",
    "s_directory_home = 'D://Datasets//TRAINING//padded_deamplified_homenoised//Sad//'\n",
    "\n",
    "#add_noise_and_deamplify_per_folder(n_directory_all, 'wav', background_noise_all)\n",
    "#add_noise_and_deamplify_per_folder(s_directory_all, 'wav', background_noise_all)\n",
    "#add_noise_and_deamplify_per_folder(n_directory_home, 'wav', background_noise_home)\n",
    "#add_noise_and_deamplify_per_folder(s_directory_home, 'wav', background_noise_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "percent = 0.2\n",
    "partition_directory(h_directory, h_test, percent)\n",
    "partition_directory(a_directory, a_test, percent)\n",
    "partition_directory(n_directory, n_test, percent)\n",
    "partition_directory(s_directory, s_test, percent)\n",
    "partition_directory(o_directory, o_test, percent)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AudioEffectsChain().reverb()(infile, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
