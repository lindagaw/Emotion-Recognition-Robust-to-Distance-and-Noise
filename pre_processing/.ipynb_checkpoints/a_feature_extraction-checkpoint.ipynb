{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features are unspecified. Defaut is set to = 272.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import os, shutil, glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pickle\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "import pickle\n",
    "\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Add\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Add\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dropout, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlapping=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 272 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "try:\n",
    "    NumofFeaturetoUse = int(sys.argv[1])\n",
    "    print('Number of features to use is set to ' + str(sys.argv[1]) )\n",
    "except:\n",
    "    print('Number of features are unspecified. Defaut is set to = 272.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_FeatureExtractfromSinglewindow(y,hop_length,sr):\n",
    "\n",
    "    genFeatures=np.array([])\n",
    "    try:\n",
    "        mfcc0 = librosa.feature.mfcc(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length, n_mfcc=13)\n",
    "        mfcc=np.transpose(mfcc0)\n",
    "\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(mfcc, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        mfcc_delta=librosa.feature.delta(mfcc0)\n",
    "        mfcc_delta=np.transpose(mfcc_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(mfcc_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        zcr0=librosa.feature.zero_crossing_rate(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "        zcr=np.transpose(zcr0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(zcr, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(zcr, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        zcr_delta=librosa.feature.delta(zcr0)\n",
    "        zcr_delta=np.transpose(zcr_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(zcr_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(zcr_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        Erms0=librosa.feature.rms(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "        Erms=np.transpose(Erms0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(Erms, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(Erms, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        Erms_delta=librosa.feature.delta(Erms0)\n",
    "        Erms_delta=np.transpose(Erms_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(Erms_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(Erms_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        cent0 = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length)\n",
    "        cent=np.transpose(cent0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(cent, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(cent, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        cent_delta=librosa.feature.delta(cent0)\n",
    "        cent_delta=np.transpose(cent_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(cent_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(cent_delta, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "        #Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame.\n",
    "\n",
    "        ############### pitch at certain frame\n",
    "        pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=75, fmax=8000, n_fft=hop_length*2, hop_length=hop_length)\n",
    "        p=[pitches[magnitudes[:,i].argmax(),i] for i in range(0,pitches.shape[1])]\n",
    "        pitch0=np.array(p)   #shape (305,)\n",
    "        pitch=np.transpose(pitch0)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(pitch, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(pitch, 0)))\n",
    "        #print(genFeatures.shape)\n",
    "\n",
    "        pitch_delta=librosa.feature.delta(pitch0)\n",
    "        pitch_delta=np.transpose(pitch_delta)\n",
    "        genFeatures = np.hstack((genFeatures, np.amin(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.amax(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.median(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.mean(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.std(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, np.var(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.skew(pitch_delta, 0)))\n",
    "        genFeatures = np.hstack((genFeatures, st.kurtosis(pitch_delta, 0)))\n",
    "    except:\n",
    "        return None\n",
    "    #print(genFeatures.shape)    #272\n",
    "    return genFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract specified amount of features from an audio file\n",
    "'''\n",
    "def function_FeatureExtract1(audiofile, NumofFeatures):\n",
    "    extension = '.wav'\n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    All = np.array([])\n",
    "    NumofFeaturetoUse = NumofFeatures #needs to be reassigned, takes two parameters\n",
    "    ListOfFrame2Vec = np.empty((0, frame_number, NumofFeaturetoUse))\n",
    "    audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "    segment_start_flag = 0\n",
    "    start_seg = 0\n",
    "    while (start_seg + segment_length) < len(audio):\n",
    "        flag = 1\n",
    "        sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "\n",
    "        featureSet = function_FeatureExtractfromSinglewindow(sound1, hop_length, sample_rate)\n",
    "\n",
    "        if segment_start_flag == 0:\n",
    "            SegAllFeat = featureSet\n",
    "            segment_start_flag = 1\n",
    "        else:\n",
    "            SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "        start_seg = start_seg + overlappiong\n",
    "\n",
    "    if segment_start_flag == 1:\n",
    "        #print(SegAllFeat.shape)\n",
    "        SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "\n",
    "    #print(SegAllFeat.shape)\n",
    "    if flag_start_all == 0:\n",
    "        All = SegAllFeat\n",
    "        flag_start_all = 1\n",
    "    else:\n",
    "        All = np.vstack((All, SegAllFeat))\n",
    "\n",
    "    return All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_new_feature_vector(feature_raw, feature_vector, label, label_vector):\n",
    "    \n",
    "    # feature_raw = the path in which the raw files (images, audios) are saved.\n",
    "    # feature_vector = the npy file consisting of all the feature vectors in the class\n",
    "    # label = the label of the class, should be numerical,  a single number\n",
    "    # label_vector = just an npy array of the labels\n",
    "    \n",
    "    if os.path.exists(feature_vector):\n",
    "        print('Deleting old feature vector npy ...')\n",
    "        os.remove(feature_vector)\n",
    "        \n",
    "    if os.path.exists(label_vector):\n",
    "        print('Deleting old label vector npy ...')\n",
    "        os.remove(label_vector)\n",
    "    \n",
    "    featureSet, Label = function_FeatureExtract(feature_raw, label)  # change here\n",
    "    \n",
    "    np.save(feature_vector, featureSet)\n",
    "    np.save(label_vector, Label)\n",
    "\n",
    "\n",
    "    vec = featureSet/np.float32(255)\n",
    "    # label = Label.astype(np.int32)  # not required\n",
    "    \n",
    "    return np.array(vec), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_old_feature_vector(feature_vector, label_vector):\n",
    "    \n",
    "    # feature_raw = the path in which the raw files (images, audios) are saved.\n",
    "    # feature_vector = the npy file consisting of all the feature vectors in the class\n",
    "    # label = the label of the class, should be numerical,  a single number\n",
    "    # label_vector = just an npy array of the labels\n",
    "    vec = np.array([])\n",
    "    ret_label = np.array([])\n",
    "    \n",
    "    if not os.path.exists(feature_vector):\n",
    "        print('Unable to find old feature vector npy ...')\n",
    "        \n",
    "    elif not os.path.exists(label_vector):\n",
    "        print('Unable to find old label vector npy ... ')\n",
    "\n",
    "    else:\n",
    "        vec = np.load(feature_vector)\n",
    "        ret_label = np.load(label_vector)\n",
    "\n",
    "    return np.array(vec), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_ranking():\n",
    "    # featureSet0, Label0 = function_FeatureExtract('train/n', 0)         #### change here\n",
    "    # featureSet1, Label1 = function_FeatureExtract('train/p', 1)          #### change here\n",
    "\n",
    "    featureSet = train_data.astype(np.float32)\n",
    "    Label = train_labels.astype(np.float32)\n",
    "    \n",
    "    indices_filename = 'Features_48//indices_filename.npy'\n",
    "\n",
    "    ############################################################ feature selection\n",
    "    X, X_test, Y, Y_test= train_test_split(featureSet, Label, test_size=0.2, random_state=42)\n",
    "    seed = 7\n",
    "    num_trees = 100\n",
    "    #max_features = 200\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=num_trees)\n",
    "\n",
    "    forest.fit(X,Y)\n",
    "\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    np.save(indices_filename, indices)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "    ############## whole code is random forest based feature selection\n",
    "\n",
    "# indices = feature_ranking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_directory = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Happy//'\n",
    "h_feature_vector = 'Features//h_feature_vector_48.npy' \n",
    "h_label_vector = 'Features//h_label_vector_48.npy'\n",
    "h_label = 'H'\n",
    "\n",
    "a_directory = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Angry//'\n",
    "a_feature_vector = 'Features//a_feature_vector_48.npy' \n",
    "a_label_vector = 'Features//a_label_vector_48.npy'\n",
    "a_label = 'A'\n",
    "\n",
    "n_directory = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Neutral//'\n",
    "n_feature_vector = 'Features//n_feature_vector_48.npy' \n",
    "n_label_vector = 'Features//n_label_vector_48.npy'\n",
    "n_label = 'N'\n",
    "\n",
    "s_directory = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Sad//'\n",
    "s_feature_vector = 'Features//s_feature_vector_48.npy' \n",
    "s_label_vector = 'Features//s_label_vector_48.npy'\n",
    "s_label = 'S'\n",
    "\n",
    "h_test = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Happy_test//'\n",
    "h_feature_vector_test = 'Features//h_feature_vector_test_48.npy' \n",
    "h_label_vector_test = 'Features//h_label_vector_test_48.npy'\n",
    "h_label_test = 'H'\n",
    "\n",
    "a_test = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Angry_test//'\n",
    "a_feature_vector_test = 'Features//a_feature_vector_test_48.npy' \n",
    "a_label_vector_test = 'Features//a_label_vector_test_48.npy'\n",
    "a_label_test = 'A'\n",
    "\n",
    "n_test = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Neutral_test//'\n",
    "n_feature_vector_test = 'Features//n_feature_vector_test_48.npy' \n",
    "n_label_vector_test = 'Features//n_label_vector_test_48.npy'\n",
    "n_label_test = 'N'\n",
    "\n",
    "s_test = '..//Datasets//TRAINING_PAD_NOISE_REVERB//Sad_test//'\n",
    "s_feature_vector_test = 'Features//s_feature_vector_test_48.npy' \n",
    "s_label_vector_test = 'Features//s_label_vector_test_48.npy'\n",
    "s_label_test = 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain_new_feature_vector(h_test, h_feature_vector_test, 'H', h_label_vector_test)\n",
    "# obtain_new_feature_vector(a_test, a_feature_vector_test, 'A', a_label_vector_test)\n",
    "# obtain_new_feature_vector(n_test, n_feature_vector_test, 'N', n_label_vector_test)\n",
    "# obtain_new_feature_vector(s_test, s_feature_vector_test, 'S', s_label_vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain_new_feature_vector(h_directory, h_feature_vector, 'H', h_label_vector)\n",
    "# obtain_new_feature_vector(a_directory, a_feature_vector, 'A', a_label_vector)\n",
    "# obtain_new_feature_vector(n_directory, n_feature_vector, 'N', n_label_vector)\n",
    "# obtain_new_feature_vector(s_directory, s_feature_vector, 'S', s_label_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_int(input_np):\n",
    "    output_np = []\n",
    "    for x in np.nditer(input_np):\n",
    "        if x == 'H':\n",
    "            x = 0\n",
    "        elif x == 'A':\n",
    "            x = 1\n",
    "        elif x == 'N':\n",
    "            x = 2\n",
    "        else:\n",
    "            x = 3\n",
    "        output_np.append(x)\n",
    "    output_np = np.array(output_np)\n",
    "    output_np = np.reshape(output_np, (len(output_np), 1) )\n",
    "    \n",
    "    return output_np\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]\n",
    "        \n",
    "        input_np[x_position, y_position] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "# indices = np.load('Features_48//indices_filename.npy')\n",
    "\n",
    "def function_FeatureExtract_withword2vec(path, classLabel):\n",
    "    print('Processing ' + path)\n",
    "    \n",
    "    extension = '.wav'\n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    file_counter = 1\n",
    "    ListOfFrame2Vec = np.empty((0, frame_number, NumofFeaturetoUse))\n",
    "    LabelOfTotalFrame2Vec = np.empty((0, 1, 1))\n",
    "    \n",
    "    number_of_elements = len(os.listdir(path))\n",
    "    i = 0\n",
    "\n",
    "    for root, dirs_list, files_list in os.walk(path):\n",
    "        for file_name in files_list:\n",
    "            update_progress(i / number_of_elements)\n",
    "            i += 1\n",
    "            # if os.path.splitext(file_name)[-1] == extension:\n",
    "            audiofile = os.path.join(root, file_name)\n",
    "\n",
    "            audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "            # print(file_name)\n",
    "            segment_start_flag = 0\n",
    "            start_seg = 0\n",
    "  \n",
    "            while (start_seg + segment_length) < len(audio):\n",
    "\n",
    "                sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "\n",
    "                featureSet = function_FeatureExtractfromSinglewindow(\n",
    "                    sound1, hop_length, sample_rate)\n",
    "\n",
    "                # featureSet = np.hstack((featureSet, classValue))\n",
    "\n",
    "                if segment_start_flag == 0:\n",
    "                    SegAllFeat = featureSet\n",
    "                    segment_start_flag = 1\n",
    "                else:\n",
    "                    SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "                ################################ end of class value identify\n",
    "                start_seg = start_seg + overlapping\n",
    "\n",
    "            if segment_start_flag == 1:\n",
    "                SegAllFeat = np.nan_to_num(SegAllFeat)\n",
    "                float_compatible(SegAllFeat)\n",
    "                \n",
    "                SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "\n",
    "            # here you are doing feature selection\n",
    "            SegFeatX = SegAllFeat[:, indices[0:NumofFeaturetoUse]]\n",
    "            SegFeatX = SegFeatX[0:frame_number]\n",
    "\n",
    "            ListOfFrame2Vec = np.append(\n",
    "                ListOfFrame2Vec, array([SegFeatX]), axis=0)\n",
    "\n",
    "            #print(ListOfFrame2Vec.shape)\n",
    "\n",
    "            if classLabel == 1:\n",
    "                LabelOfTotalFrame2Vec = np.append(\n",
    "                    LabelOfTotalFrame2Vec, np.array([1]))\n",
    "            elif classLabel == 2:\n",
    "                LabelOfTotalFrame2Vec = np.append(\n",
    "                    LabelOfTotalFrame2Vec, np.array([2]))\n",
    "            elif classLabel == 3:\n",
    "                LabelOfTotalFrame2Vec = np.append(\n",
    "                    LabelOfTotalFrame2Vec, np.array([3]))\n",
    "            else:\n",
    "                LabelOfTotalFrame2Vec = np.append(\n",
    "                    LabelOfTotalFrame2Vec, np.array([0]))\n",
    "        \n",
    "    return ListOfFrame2Vec, LabelOfTotalFrame2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "try:\n",
    "    indices = np.load('Features_48//indices_filename.npy')\n",
    "except:\n",
    "    print('indices_filename.npy not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "featureSet_train1, Label_train1 = function_FeatureExtract_withword2vec(a_directory, 1)\n",
    "np.save(a_feature_vector, featureSet_train1)\n",
    "np.save(a_label_vector, Label_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################################################################################################] 99.9%\n"
     ]
    }
   ],
   "source": [
    "featureSet_validation1, Label_validation1 = function_FeatureExtract_withword2vec(a_test, 1)\n",
    "np.save(a_feature_vector_test, featureSet_validation1)\n",
    "np.save(a_label_vector_test, Label_validation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "featureSet_val=np.vstack((featureSet_validation0, featureSet_validation1))\n",
    "Label_val=np.append(Label_validation0, Label_validation1, axis=0)\n",
    "\n",
    "featureSet=np.vstack((featureSet_train0, featureSet_train1))\n",
    "Label=np.append(Label_train0, Label_train1, axis=0)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
