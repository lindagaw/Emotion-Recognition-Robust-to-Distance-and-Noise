{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ash Gao\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "#from tensorflow.python.client import device_lib\n",
    "from keras import backend\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41068, 48, 272)\n",
      "(41068, 6)\n",
      "(9995, 48, 272)\n",
      "(9995, 6)\n"
     ]
    }
   ],
   "source": [
    "# load training and testing ... \n",
    "\n",
    "condition = 'all'\n",
    "\n",
    "new_train = 'train//' + condition + '//'\n",
    "new_test = 'test//' + condition + '//'\n",
    "new_val = 'val//' + condition + '//'\n",
    "\n",
    "def load_vectors(path):\n",
    "    files = sorted(os.listdir(path))\n",
    "    X = np.expand_dims(np.zeros((48, 272)), axis=0)\n",
    "    y = []\n",
    "    for npy in files:\n",
    "        if 'Calm' in npy or 'Other' in npy:\n",
    "            continue\n",
    "        \n",
    "        current = np.load(path+npy)\n",
    "        X = np.vstack((X, current))\n",
    "        label = [files.index(npy)]*len(current)       \n",
    "        y = y + label       \n",
    "    X = X[1:]\n",
    "    y = to_categorical(y)    \n",
    "    print(X.shape)\n",
    "    print(y.shape)    \n",
    "    return X, y\n",
    "    \n",
    "X_train, y_train = load_vectors(new_train)\n",
    "try:\n",
    "    X_val, y_val = load_vectors(new_val)\n",
    "except:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "X_test, y_test = load_vectors(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mil_squared_error(y_true, y_pred):\n",
    "    return tf.keras.backend.square(tf.keras.backend.max(y_pred) - tf.keras.backend.max(y_true))\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "def create_cnn(num_layers, n_neurons, n_batch, nbindex, dropout, classes, dense_layers):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution1D(filters=nbindex, kernel_size=fillength, activation = 'relu',\n",
    "                            input_shape=(X_train.shape[1], X_train.shape[2]), kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution1D(filters=nbindex*2, kernel_size=fillength, activation = 'relu',\n",
    "                            kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution1D(filters=nbindex*2, kernel_size=fillength, activation = 'relu',\n",
    "                            kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Convolution1D(filters=nbindex, kernel_size=fillength, activation = 'relu',\n",
    "                            kernel_constraint=maxnorm(3)))  \n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for i in range(0, dense_layers):\n",
    "        model.add(Dense(n_neurons, activation = 'relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "    # Here, get the empirical class mean and covariance of training samples\n",
    "\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam,\n",
    "                  metrics=['accuracy', mil_squared_error])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "frame_number = 48\n",
    "hop_length = 441  # frame size= 2 * hop\n",
    "segment_length = int(sample_rate * 0.2)  # 0.2\n",
    "segment_pad = int(sample_rate * 0.02)     # 0.02\n",
    "overlapping = int(sample_rate * 0.1)   # 0.1\n",
    "\n",
    "classes = 5\n",
    "NumofFeaturetoUse = 272\n",
    "n_neurons = 1024 * 4\n",
    "dense_layers = 10\n",
    "num_layers = 3\n",
    "fillength = 3\n",
    "nbindex = 1024 * 3\n",
    "dropout = 0.2\n",
    "n_batch = 128\n",
    "n_epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn(num_layers=num_layers, \n",
    "                   n_neurons=n_neurons, \n",
    "                   n_batch=n_batch, \n",
    "                   nbindex=nbindex, \n",
    "                   dropout=dropout, \n",
    "                   classes=classes, \n",
    "                   dense_layers=dense_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/100\n",
      "42/42 [==============================] - 3s 66ms/step - loss: 0.0071 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.4620 - val_accuracy: 0.7310 - val_mil_squared_error: 8.3235e-14\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0114 - accuracy: 0.9957 - mil_squared_error: 0.0000e+00 - val_loss: 1.4530 - val_accuracy: 0.7277 - val_mil_squared_error: 9.9476e-14\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0100 - accuracy: 0.9957 - mil_squared_error: 0.0000e+00 - val_loss: 1.4440 - val_accuracy: 0.7366 - val_mil_squared_error: 1.5936e-13\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.0085 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.4444 - val_accuracy: 0.7383 - val_mil_squared_error: 1.2079e-13\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0059 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.4966 - val_accuracy: 0.7210 - val_mil_squared_error: 8.0190e-14\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0090 - accuracy: 0.9970 - mil_squared_error: 0.0000e+00 - val_loss: 1.4864 - val_accuracy: 0.7260 - val_mil_squared_error: 5.2783e-14\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0050 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.4589 - val_accuracy: 0.7355 - val_mil_squared_error: 9.4401e-14\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0049 - accuracy: 0.9987 - mil_squared_error: 0.0000e+00 - val_loss: 1.4693 - val_accuracy: 0.7321 - val_mil_squared_error: 4.7708e-14\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0099 - accuracy: 0.9970 - mil_squared_error: 0.0000e+00 - val_loss: 1.4711 - val_accuracy: 0.7282 - val_mil_squared_error: 6.4964e-14\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0109 - accuracy: 0.9965 - mil_squared_error: 0.0000e+00 - val_loss: 1.4502 - val_accuracy: 0.7221 - val_mil_squared_error: 6.1919e-14\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0103 - accuracy: 0.9961 - mil_squared_error: 0.0000e+00 - val_loss: 1.4366 - val_accuracy: 0.7294 - val_mil_squared_error: 2.1316e-13\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0062 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4056 - val_accuracy: 0.7310 - val_mil_squared_error: 9.3386e-14\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0074 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.4868 - val_accuracy: 0.7243 - val_mil_squared_error: 6.6994e-14\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0091 - accuracy: 0.9972 - mil_squared_error: 0.0000e+00 - val_loss: 1.4912 - val_accuracy: 0.7238 - val_mil_squared_error: 5.8874e-14\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0095 - accuracy: 0.9968 - mil_squared_error: 0.0000e+00 - val_loss: 1.4508 - val_accuracy: 0.7299 - val_mil_squared_error: 2.7305e-13\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0082 - accuracy: 0.9974 - mil_squared_error: 3.3835e-16 - val_loss: 1.4602 - val_accuracy: 0.7238 - val_mil_squared_error: 5.5828e-14\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.0073 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4897 - val_accuracy: 0.7210 - val_mil_squared_error: 6.5979e-14\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.0083 - accuracy: 0.9970 - mil_squared_error: 3.3835e-16 - val_loss: 1.4626 - val_accuracy: 0.7210 - val_mil_squared_error: 6.6994e-14\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0094 - accuracy: 0.9972 - mil_squared_error: 0.0000e+00 - val_loss: 1.4573 - val_accuracy: 0.7249 - val_mil_squared_error: 3.8572e-14\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.0090 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.5613 - val_accuracy: 0.7132 - val_mil_squared_error: 1.4921e-13\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0230 - accuracy: 0.9933 - mil_squared_error: 0.0000e+00 - val_loss: 1.4194 - val_accuracy: 0.7282 - val_mil_squared_error: 2.2636e-13\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0063 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5195 - val_accuracy: 0.7171 - val_mil_squared_error: 1.3673e-12\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 3s 71ms/step - loss: 0.0082 - accuracy: 0.9963 - mil_squared_error: 0.0000e+00 - val_loss: 1.4883 - val_accuracy: 0.7243 - val_mil_squared_error: 6.0193e-13\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0083 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4268 - val_accuracy: 0.7271 - val_mil_squared_error: 9.1355e-14\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0081 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.4512 - val_accuracy: 0.7305 - val_mil_squared_error: 1.5936e-13\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0108 - accuracy: 0.9970 - mil_squared_error: 0.0000e+00 - val_loss: 1.4024 - val_accuracy: 0.7372 - val_mil_squared_error: 2.4158e-13\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0069 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.4392 - val_accuracy: 0.7288 - val_mil_squared_error: 6.3949e-14\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0061 - accuracy: 0.9980 - mil_squared_error: 0.0000e+00 - val_loss: 1.4899 - val_accuracy: 0.7227 - val_mil_squared_error: 6.5979e-14\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0061 - accuracy: 0.9983 - mil_squared_error: 0.0000e+00 - val_loss: 1.4449 - val_accuracy: 0.7305 - val_mil_squared_error: 4.6693e-14\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0099 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.4306 - val_accuracy: 0.7344 - val_mil_squared_error: 1.2790e-13\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0080 - accuracy: 0.9980 - mil_squared_error: 0.0000e+00 - val_loss: 1.4616 - val_accuracy: 0.7310 - val_mil_squared_error: 8.7295e-14\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0085 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.4425 - val_accuracy: 0.7321 - val_mil_squared_error: 6.2934e-14\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0056 - accuracy: 0.9980 - mil_squared_error: 0.0000e+00 - val_loss: 1.4638 - val_accuracy: 0.7271 - val_mil_squared_error: 4.6693e-14\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0101 - accuracy: 0.9968 - mil_squared_error: 0.0000e+00 - val_loss: 1.4273 - val_accuracy: 0.7355 - val_mil_squared_error: 4.1618e-14\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0060 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.7238 - val_mil_squared_error: 3.8572e-14\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0076 - accuracy: 0.9980 - mil_squared_error: 0.0000e+00 - val_loss: 1.4615 - val_accuracy: 0.7277 - val_mil_squared_error: 1.4211e-13\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0056 - accuracy: 0.9980 - mil_squared_error: 0.0000e+00 - val_loss: 1.4583 - val_accuracy: 0.7299 - val_mil_squared_error: 1.3399e-13\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0064 - accuracy: 0.9974 - mil_squared_error: 0.0000e+00 - val_loss: 1.4640 - val_accuracy: 0.7232 - val_mil_squared_error: 2.9437e-14\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0064 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5015 - val_accuracy: 0.7294 - val_mil_squared_error: 4.8723e-14\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0060 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.4748 - val_accuracy: 0.7338 - val_mil_squared_error: 1.3805e-13\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0085 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4612 - val_accuracy: 0.7360 - val_mil_squared_error: 3.6542e-14\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0076 - accuracy: 0.9972 - mil_squared_error: 0.0000e+00 - val_loss: 1.5123 - val_accuracy: 0.7260 - val_mil_squared_error: 3.9587e-14\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0086 - accuracy: 0.9966 - mil_squared_error: 0.0000e+00 - val_loss: 1.4828 - val_accuracy: 0.7310 - val_mil_squared_error: 2.8422e-14\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0043 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.4742 - val_accuracy: 0.7316 - val_mil_squared_error: 3.1467e-14\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0045 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.5451 - val_accuracy: 0.7176 - val_mil_squared_error: 2.1316e-14\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0064 - accuracy: 0.9980 - mil_squared_error: 0.0000e+00 - val_loss: 1.5252 - val_accuracy: 0.7254 - val_mil_squared_error: 4.5678e-14\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0062 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5960 - val_accuracy: 0.7282 - val_mil_squared_error: 5.8874e-14\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0093 - accuracy: 0.9970 - mil_squared_error: 0.0000e+00 - val_loss: 1.5062 - val_accuracy: 0.7310 - val_mil_squared_error: 1.2181e-13\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0123 - accuracy: 0.9963 - mil_squared_error: 0.0000e+00 - val_loss: 1.4924 - val_accuracy: 0.7333 - val_mil_squared_error: 3.4106e-13\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0089 - accuracy: 0.9966 - mil_squared_error: 0.0000e+00 - val_loss: 1.4515 - val_accuracy: 0.7360 - val_mil_squared_error: 5.0753e-14\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0095 - accuracy: 0.9968 - mil_squared_error: 0.0000e+00 - val_loss: 1.5149 - val_accuracy: 0.7266 - val_mil_squared_error: 1.7358e-13\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0093 - accuracy: 0.9966 - mil_squared_error: 0.0000e+00 - val_loss: 1.4290 - val_accuracy: 0.7433 - val_mil_squared_error: 1.3399e-13\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0079 - accuracy: 0.9970 - mil_squared_error: 0.0000e+00 - val_loss: 1.5250 - val_accuracy: 0.7221 - val_mil_squared_error: 8.6280e-14\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0073 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5112 - val_accuracy: 0.7294 - val_mil_squared_error: 2.0707e-13\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0036 - accuracy: 0.9991 - mil_squared_error: 0.0000e+00 - val_loss: 1.4526 - val_accuracy: 0.7338 - val_mil_squared_error: 9.8461e-14\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0114 - accuracy: 0.9963 - mil_squared_error: 0.0000e+00 - val_loss: 1.4427 - val_accuracy: 0.7327 - val_mil_squared_error: 1.1572e-13\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0080 - accuracy: 0.9983 - mil_squared_error: 0.0000e+00 - val_loss: 1.4580 - val_accuracy: 0.7232 - val_mil_squared_error: 1.1572e-13\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0066 - accuracy: 0.9983 - mil_squared_error: 0.0000e+00 - val_loss: 1.4654 - val_accuracy: 0.7266 - val_mil_squared_error: 1.5023e-13\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0073 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.4486 - val_accuracy: 0.7316 - val_mil_squared_error: 3.4512e-14\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.0082 - accuracy: 0.9972 - mil_squared_error: 0.0000e+00 - val_loss: 1.4870 - val_accuracy: 0.7182 - val_mil_squared_error: 2.8422e-14\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0055 - accuracy: 0.9987 - mil_squared_error: 0.0000e+00 - val_loss: 1.4663 - val_accuracy: 0.7288 - val_mil_squared_error: 6.6994e-14\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 3s 65ms/step - loss: 0.0054 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.4998 - val_accuracy: 0.7188 - val_mil_squared_error: 4.7708e-14\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - 3s 66ms/step - loss: 0.0056 - accuracy: 0.9987 - mil_squared_error: 0.0000e+00 - val_loss: 1.5192 - val_accuracy: 0.7204 - val_mil_squared_error: 8.3235e-14\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0093 - accuracy: 0.9966 - mil_squared_error: 0.0000e+00 - val_loss: 1.4592 - val_accuracy: 0.7266 - val_mil_squared_error: 7.9175e-14\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0047 - accuracy: 0.9991 - mil_squared_error: 0.0000e+00 - val_loss: 1.5127 - val_accuracy: 0.7176 - val_mil_squared_error: 4.6693e-14\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0057 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5119 - val_accuracy: 0.7176 - val_mil_squared_error: 2.5377e-14\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0103 - accuracy: 0.9968 - mil_squared_error: 0.0000e+00 - val_loss: 1.4689 - val_accuracy: 0.7316 - val_mil_squared_error: 6.1919e-14\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0069 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4695 - val_accuracy: 0.7321 - val_mil_squared_error: 4.5678e-14\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0087 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4763 - val_accuracy: 0.7360 - val_mil_squared_error: 6.3949e-14\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0064 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.5987 - val_accuracy: 0.7087 - val_mil_squared_error: 5.0753e-14\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0039 - accuracy: 0.9991 - mil_squared_error: 0.0000e+00 - val_loss: 1.4769 - val_accuracy: 0.7327 - val_mil_squared_error: 5.2783e-14\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0050 - accuracy: 0.9983 - mil_squared_error: 0.0000e+00 - val_loss: 1.5586 - val_accuracy: 0.7249 - val_mil_squared_error: 1.8373e-13\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0074 - accuracy: 0.9968 - mil_squared_error: 0.0000e+00 - val_loss: 1.5196 - val_accuracy: 0.7193 - val_mil_squared_error: 2.1316e-14\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0053 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.5078 - val_accuracy: 0.7254 - val_mil_squared_error: 2.0301e-14\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0053 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.5060 - val_accuracy: 0.7282 - val_mil_squared_error: 1.7256e-14\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0072 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.4985 - val_accuracy: 0.7266 - val_mil_squared_error: 1.5226e-14\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0096 - accuracy: 0.9965 - mil_squared_error: 0.0000e+00 - val_loss: 1.5631 - val_accuracy: 0.7171 - val_mil_squared_error: 2.6392e-14\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0047 - accuracy: 0.9987 - mil_squared_error: 0.0000e+00 - val_loss: 1.4985 - val_accuracy: 0.7266 - val_mil_squared_error: 1.2181e-14\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0067 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.5051 - val_accuracy: 0.7238 - val_mil_squared_error: 1.7256e-14\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0048 - accuracy: 0.9987 - mil_squared_error: 0.0000e+00 - val_loss: 1.4918 - val_accuracy: 0.7282 - val_mil_squared_error: 3.6542e-14\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0078 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.5421 - val_accuracy: 0.7188 - val_mil_squared_error: 1.3196e-14\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0037 - accuracy: 0.9989 - mil_squared_error: 0.0000e+00 - val_loss: 1.5039 - val_accuracy: 0.7271 - val_mil_squared_error: 1.5226e-14\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0058 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.5233 - val_accuracy: 0.7204 - val_mil_squared_error: 1.5226e-14\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0063 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.5686 - val_accuracy: 0.7154 - val_mil_squared_error: 1.8271e-14\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0062 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.5475 - val_accuracy: 0.7215 - val_mil_squared_error: 2.8422e-14\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0063 - accuracy: 0.9978 - mil_squared_error: 0.0000e+00 - val_loss: 1.5069 - val_accuracy: 0.7294 - val_mil_squared_error: 4.8723e-14\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0059 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5030 - val_accuracy: 0.7299 - val_mil_squared_error: 1.6241e-14\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0040 - accuracy: 0.9989 - mil_squared_error: 0.0000e+00 - val_loss: 1.6203 - val_accuracy: 0.7193 - val_mil_squared_error: 4.6693e-14\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 3s 64ms/step - loss: 0.0044 - accuracy: 0.9989 - mil_squared_error: 0.0000e+00 - val_loss: 1.5046 - val_accuracy: 0.7243 - val_mil_squared_error: 1.7256e-14\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0045 - accuracy: 0.9985 - mil_squared_error: 0.0000e+00 - val_loss: 1.5359 - val_accuracy: 0.7310 - val_mil_squared_error: 1.6241e-14\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0071 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.5350 - val_accuracy: 0.7260 - val_mil_squared_error: 1.7256e-14\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0091 - accuracy: 0.9970 - mil_squared_error: 0.0000e+00 - val_loss: 1.5305 - val_accuracy: 0.7294 - val_mil_squared_error: 1.2181e-14\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0080 - accuracy: 0.9968 - mil_squared_error: 0.0000e+00 - val_loss: 1.5440 - val_accuracy: 0.7238 - val_mil_squared_error: 4.6693e-14\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0120 - accuracy: 0.9950 - mil_squared_error: 0.0000e+00 - val_loss: 1.5031 - val_accuracy: 0.7294 - val_mil_squared_error: 4.1618e-14\n",
      "Epoch 95/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0091 - accuracy: 0.9959 - mil_squared_error: 0.0000e+00 - val_loss: 1.4583 - val_accuracy: 0.7310 - val_mil_squared_error: 5.2783e-14\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0072 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4926 - val_accuracy: 0.7277 - val_mil_squared_error: 3.8572e-14\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0054 - accuracy: 0.9981 - mil_squared_error: 0.0000e+00 - val_loss: 1.5369 - val_accuracy: 0.7243 - val_mil_squared_error: 5.2783e-14\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0068 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.5694 - val_accuracy: 0.7154 - val_mil_squared_error: 1.3196e-14\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0074 - accuracy: 0.9976 - mil_squared_error: 0.0000e+00 - val_loss: 1.4946 - val_accuracy: 0.7277 - val_mil_squared_error: 1.7256e-14\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 3s 63ms/step - loss: 0.0051 - accuracy: 0.9983 - mil_squared_error: 0.0000e+00 - val_loss: 1.4842 - val_accuracy: 0.7366 - val_mil_squared_error: 2.3346e-14\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "\n",
    "n_epoch = 100\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=n_batch,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=(X_val, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7410824108241082\n",
      "0.7384204897566805\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import f1_score\n",
    "\n",
    "y_preds = [np.argmax(val) for val in model.predict(X_test)]\n",
    "y_trues = [np.argmax(val) for val in y_test]\n",
    "acc = accuracy_score(y_trues, y_preds)\n",
    "f1 = f1_score(y_trues, y_preds, average='weighted')\n",
    "\n",
    "print(acc)\n",
    "print(f1)\n",
    "\n",
    "#model.save('clean_models_acc_' + str(acc)[:6] + '_f1_' + str(f1)[:6] + '_cnn.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda520b236a9c6d486bbc01b80a136b32a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
