{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "import h5py\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import librosa\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from pydub import AudioSegment\n",
    "\n",
    "#imported for testing\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "# for outputing file\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "import scipy.stats.stats as st\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Convolution1D, Dense, MaxPooling1D, Flatten, Add, Dropout, Input, Activation\n",
    "from keras.layers import TimeDistributed, Bidirectional, LSTM, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras import optimizers, regularizers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "# assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "# print(len(backend.tensorflow_backend._get_available_gpus()) > 0)\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "sample_rate=44100\n",
    "hop_length = 441  # frame size= 2*hop\n",
    "segment_length=int(sample_rate*0.2)  #0.2\n",
    "segment_pad=int(sample_rate*0.02)     #0.02\n",
    "overlappiong=int(sample_rate*0.1)   #0.1\n",
    "\n",
    "NumofFeaturetoUse = 100 # this will re-assigned for different classifiers\n",
    "frame_number = 48\n",
    "\n",
    "# input new indices file here\n",
    "indices_filename = 'D://indices_filename.npy'\n",
    "indices=np.load(indices_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adagrad = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adamax = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avail_modules(directory, prefix):\n",
    "    module_names = []\n",
    "    for item in os.listdir(directory):\n",
    "        if prefix in item:\n",
    "            module_names.append(directory + item)\n",
    "            i = module_names.index(directory + item)\n",
    "            print(str(i) + 'th module')\n",
    "            print(directory + item)\n",
    "            \n",
    "    return module_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_FeatureExtractfromSinglewindow(y,hop_length,sr):\n",
    "\n",
    "    genFeatures=np.array([])\n",
    "\n",
    "    mfcc0 = librosa.feature.mfcc(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length, n_mfcc=13)\n",
    "    mfcc=np.transpose(mfcc0)\n",
    "\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(mfcc, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    mfcc_delta=librosa.feature.delta(mfcc0)\n",
    "    mfcc_delta=np.transpose(mfcc_delta)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(mfcc_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(mfcc_delta, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    zcr0=librosa.feature.zero_crossing_rate(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "    zcr=np.transpose(zcr0)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(zcr, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(zcr, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    zcr_delta=librosa.feature.delta(zcr0)\n",
    "    zcr_delta=np.transpose(zcr_delta)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(zcr_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(zcr_delta, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    Erms0=librosa.feature.rms(y=y, frame_length=hop_length*2, hop_length=hop_length)\n",
    "    Erms=np.transpose(Erms0)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(Erms, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(Erms, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    Erms_delta=librosa.feature.delta(Erms0)\n",
    "    Erms_delta=np.transpose(Erms_delta)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(Erms_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(Erms_delta, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    cent0 = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=hop_length*2, hop_length=hop_length)\n",
    "    cent=np.transpose(cent0)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(cent, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(cent, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    cent_delta=librosa.feature.delta(cent0)\n",
    "    cent_delta=np.transpose(cent_delta)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(cent_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(cent_delta, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "    #Each frame of a magnitude spectrogram is normalized and treated as a distribution over frequency bins, from which the mean (centroid) is extracted per frame.\n",
    "\n",
    "    ############### pitch at certain frame\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=75, fmax=8000, n_fft=hop_length*2, hop_length=hop_length)\n",
    "    p=[pitches[magnitudes[:,i].argmax(),i] for i in range(0,pitches.shape[1])]\n",
    "    pitch0=np.array(p)   #shape (305,)\n",
    "    pitch=np.transpose(pitch0)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(pitch, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(pitch, 0)))\n",
    "    #print(genFeatures.shape)\n",
    "\n",
    "    pitch_delta=librosa.feature.delta(pitch0)\n",
    "    pitch_delta=np.transpose(pitch_delta)\n",
    "    genFeatures = np.hstack((genFeatures, np.amin(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.amax(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.median(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.mean(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.std(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, np.var(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.skew(pitch_delta, 0)))\n",
    "    genFeatures = np.hstack((genFeatures, st.kurtosis(pitch_delta, 0)))\n",
    "    #print(genFeatures.shape)    #272\n",
    "    return genFeatures\n",
    "\n",
    "\n",
    "'''\n",
    "Extract specified amount of features from an audio file\n",
    "'''\n",
    "def function_FeatureExtract1(audiofile, NumofFeatures):\n",
    "    extension = '.wav'\n",
    "    flag_start_all = 0\n",
    "    flag_Y_start = 0\n",
    "    All = np.array([])\n",
    "    NumofFeaturetoUse = NumofFeatures #needs to be reassigned, takes two parameters\n",
    "    ListOfFrame2Vec = np.empty((0, frame_number, NumofFeaturetoUse))\n",
    "    audio, s_rate = librosa.load(audiofile, sr=sample_rate)\n",
    "    segment_start_flag = 0\n",
    "    start_seg = 0\n",
    "    while (start_seg + segment_length) < len(audio):\n",
    "        flag = 1\n",
    "        sound1 = audio[start_seg:(start_seg + segment_length)]\n",
    "\n",
    "        featureSet = function_FeatureExtractfromSinglewindow(sound1, hop_length, sample_rate)\n",
    "\n",
    "        if segment_start_flag == 0:\n",
    "            SegAllFeat = featureSet\n",
    "            segment_start_flag = 1\n",
    "        else:\n",
    "            SegAllFeat = np.vstack((SegAllFeat, featureSet))\n",
    "\n",
    "        start_seg = start_seg + overlappiong\n",
    "\n",
    "    SegAllFeat = float_compatible(SegAllFeat)\n",
    "    if segment_start_flag == 1:\n",
    "        #print(SegAllFeat.shape)\n",
    "        SegAllFeat = normalize(SegAllFeat, norm='l2', axis=0)\n",
    "\n",
    "    #print(SegAllFeat.shape)\n",
    "    if flag_start_all == 0:\n",
    "        All = SegAllFeat\n",
    "        flag_start_all = 1\n",
    "    else:\n",
    "        All = np.vstack((All, SegAllFeat))\n",
    "\n",
    "    return All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find minimum and maximum position in list \n",
    "def maxima(a): \n",
    "  \n",
    "    # inbuilt function to find the position of minimum  \n",
    "    minpos = a.index(min(a)) \n",
    "      \n",
    "    # inbuilt function to find the position of maximum  \n",
    "    maxpos = a.index(max(a))  \n",
    "    return maxpos\n",
    "\n",
    "def minima(a): \n",
    "  \n",
    "    # inbuilt function to find the position of minimum  \n",
    "    minpos = a.index(min(a)) \n",
    "      \n",
    "    # inbuilt function to find the position of maximum  \n",
    "    maxpos = a.index(max(a))  \n",
    "    return minpos\n",
    "\n",
    "def float_compatible(input_np):\n",
    "\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]\n",
    "        \n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "        \n",
    "    return input_np\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 100\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_TESS = 'D://Datasets//TESS//intact//Happy//'\n",
    "a_TESS = 'D://Datasets//TESS//intact//Angry//'\n",
    "n_TESS = 'D://Datasets//TESS//intact//Neutral//'\n",
    "s_TESS = 'D://Datasets//TESS//intact//Sad//'\n",
    "\n",
    "h_EMO = 'D://Datasets//EMO-DB//wav//Happy//'\n",
    "a_EMO = 'D://Datasets//EMO-DB//wav//Angry//'\n",
    "n_EMO = 'D://Datasets//EMO-DB//wav//Neutral//'\n",
    "s_EMO = 'D://Datasets//EMO-DB//wav//Sad//'\n",
    "o_EMO = 'D://Datasets//EMO-DB//wav//Other//'\n",
    "\n",
    "test_Happy = 'D://Datasets//TRAINING//Happy_test//'\n",
    "test_Angry = 'D://Datasets//TRAINING//Angry_test//'\n",
    "test_Neutral = 'D://Datasets//TRAINING//Neutral_test//'\n",
    "test_Sad = 'D://Datasets//TRAINING//Sad_test//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_top_conv(num_layers):\n",
    "    \n",
    "    n_neurons = 1024\n",
    "    n_batch = 128\n",
    "    n_epoch = 1000\n",
    "    nbindex = 512\n",
    "    fillength = 4\n",
    "    classes = 2\n",
    "    \n",
    "    #ofilepath = \"C://Users//yg9ca//Documents//3_Layer(s)//CNN_final_Top_1024_128_1000.hdf5\"\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Convolution1D(nb_filter=nbindex, filter_length=fillength, activation='relu', input_shape=(frame_number, 272), kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    for layer in range(0, num_layers):\n",
    "        model.add(Convolution1D(nb_filter=nbindex, filter_length=fillength, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_neurons, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(classes, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_function_FeatureExtract3(InputFolderName):\n",
    "    X = function_FeatureExtract1(InputFolderName, 272)\n",
    "    y_pred = omodel.predict(X)\n",
    "    #print(y_pred)\n",
    "    x = maxima(list(y_pred[0]))\n",
    "    return x\n",
    "\n",
    "def top_classifier_eval(emotionFolders):\n",
    "    print('Predicted with overall classifier: ' + ofilepath)\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        elif 'Angry' in emotionFolder: val = 0\n",
    "        elif 'Neutral' in emotionFolder: val = 1\n",
    "        else: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "\n",
    "            cond1 = '0_' not in emotionfile and '1_' not in emotionfile\n",
    "            cond2 = emotionfile[len(emotionfile)-4] != '-' and emotionfile[len(emotionfile)-6] != '-' \n",
    "            cond3 = len(emotionfile) != len('03-01-05-01-01-01-06-6-8-4')\n",
    "            cond4 = emotionfile[0] != '.'\n",
    "\n",
    "            if cond2 and cond3 and cond4 and cond1:\n",
    "                try:\n",
    "                    x = top_function_FeatureExtract3(\n",
    "                        InputFolderName=emotionFolder+emotionfile)\n",
    "                    if(x == val): correct += 1\n",
    "                    else: incorrect += 1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    return correct/(correct+incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#omodel = optimal_top_conv(3)\n",
    "#ofilepath = \"3_Layer(s)//CNN_final_Top_1024_128_1000.hdf5\"\n",
    "#omodel.load_weights(ofilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_classifier_eval([test_Happy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_classifier_eval([test_Angry])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_classifier_eval([test_Neutral])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_classifier_eval([test_Sad])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Top classifier accuracy on unseen Happy data - 0.9774436090225563\n",
    "Top classifier accuracy on unseen Angry data - 0.984313725490196\n",
    "Top classifier accuracy on unseen Neutral data - 0.9518518518518518\n",
    "Top classifier accuracy on unseen Sad data - 0.8954248366013072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Happy vs Angry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th module\n",
      "C://Users//yg9ca//Documents//modules//Checkpoint_H_A_neurons_4096_filters_256_dropout_0.2_epoch_50000.hdf5\n",
      "1th module\n",
      "C://Users//yg9ca//Documents//modules//Final_H_A_neurons_4096_filters_256_dropout_0.15_epoch_50000.hdf5\n",
      "2th module\n",
      "C://Users//yg9ca//Documents//modules//Final_H_A_neurons_4096_filters_256_dropout_0.1_epoch_1000.hdf5\n",
      "3th module\n",
      "C://Users//yg9ca//Documents//modules//Final_H_A_neurons_4096_filters_256_dropout_0.2_epoch_50000.hdf5\n"
     ]
    }
   ],
   "source": [
    "directory = 'C://Users//yg9ca//Documents//modules//'\n",
    "module_prefix = 'H_A_'\n",
    "modules = avail_modules(directory, module_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_title = modules[0]\n",
    "#n_neurons, n_batch, n_epoch, nbindex, fillength, classes, dropout, dense_layers = extract_parameters(this_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hafilepath = this_title\n",
    "hamodel = keras.models.load_model(hafilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_a_function_FeatureExtract3(InputFolderName):\n",
    "    X = function_FeatureExtract1(InputFolderName, NumofFeaturetoUse)\n",
    "    X = np.split(X, np.array([NumofFeaturetoUse]), axis = 1)[0]\n",
    "    X = list(X)\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_a_classifier_eval(emotionFolders):\n",
    "    print('Predicted with overall classifier: ' + hafilepath)\n",
    "\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    flag = 0\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for emotionFolder in emotionFolders:\n",
    "\n",
    "        if 'Happy' in emotionFolder: val = 0\n",
    "        elif 'Angry' in emotionFolder: val = 1\n",
    "\n",
    "        for emotionfile in os.listdir(emotionFolder):\n",
    "            cond1 = 'deamp_' not in emotionfile and 'WetDry_' not in emotionfile\n",
    "            cond2 = 'noise' not in emotionfile\n",
    "            cond4 = emotionfile[0] != '.'\n",
    "            \n",
    "            one_sample = h_a_function_FeatureExtract3(InputFolderName=emotionFolder+emotionfile)\n",
    "            result.append(one_sample)\n",
    "                    \n",
    "    y_pred = hamodel.predict(np.array(result))\n",
    "                \n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted with overall classifier: C://Users//yg9ca//Documents//modules//Checkpoint_H_A_neurons_4096_filters_256_dropout_0.2_epoch_50000.hdf5\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-cbfab49d38f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_a_classifier_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma_EMO\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-141-4edc5b11d2c9>\u001b[0m in \u001b[0;36mh_a_classifier_eval\u001b[1;34m(emotionFolders)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mcond4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memotionfile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mone_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh_a_function_FeatureExtract3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputFolderName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0memotionFolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0memotionfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-1bf21da610ba>\u001b[0m in \u001b[0;36mh_a_function_FeatureExtract3\u001b[1;34m(InputFolderName)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mh_a_function_FeatureExtract3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputFolderName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction_FeatureExtract1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputFolderName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumofFeaturetoUse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNumofFeaturetoUse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-87-d3e769059a3d>\u001b[0m in \u001b[0;36mfunction_FeatureExtract1\u001b[1;34m(audiofile, NumofFeatures)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mNumofFeaturetoUse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNumofFeatures\u001b[0m \u001b[1;31m#needs to be reassigned, takes two parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mListOfFrame2Vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNumofFeaturetoUse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[0msegment_start_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mstart_seg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# All backends failed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = h_a_classifier_eval([a_EMO])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cnn(model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for item in list(Label_val):\n",
    "            if item[0] > item[1]:\n",
    "                y_true.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_true.append(1)\n",
    "            else:\n",
    "                y_true.append(0)\n",
    "\n",
    "    for item in list(model.predict(featureSet_val)):\n",
    "            if item[0] > item[1]:\n",
    "                y_pred.append(0)\n",
    "            elif item[0] < item[1]:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "\n",
    "    print('Accuracy: ' + str(accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(recall_score(y_true, y_pred)))\n",
    "    print('f1 score: ' + str(f1_score(y_true, y_pred)))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    print('true positive ' + str(tp))\n",
    "    print('false positive ' + str(fp))\n",
    "    print('false negative ' + str(fn))\n",
    "    print('true negative ' + str(tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
