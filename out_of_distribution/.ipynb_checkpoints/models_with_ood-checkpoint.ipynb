{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os, sys, gc\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Checkpoint_home_All_neurons_home_2048_filters_2048_dropout_0.2_epoch_1000_dense_8.hdf5',\n",
       " 'Checkpoint_home_All_neurons_home_2048_filters_1024_dropout_0.2_epoch_1000_dense_4.hdf5',\n",
       " 'Checkpoint_home_All_neurons_home_4096_filters_3072_dropout_0.2_epoch_1000_dense_10.hdf5',\n",
       " 'Checkpoint_home_All_neurons_home_1024_filters_2048_dropout_0.2_epoch_1000_dense_6.hdf5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder = '..//..//modules//'\n",
    "usable_models = [model for model in os.listdir(model_folder) if '.hdf5' in model]\n",
    "usable_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 1024 * 4\n",
    "dense_layers = 10\n",
    "nbindex = 1024 * 3\n",
    "n_epoch = 1000\n",
    "num_layers = 4\n",
    "dense_layers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-trained keras model\n",
    "model = load_model(model_folder + usable_models[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_9 (Conv1D)            (None, 46, 3072)          2509824   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 23, 3072)          0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 23, 3072)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 21, 6144)          56629248  \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 10, 6144)          0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 10, 6144)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 8, 6144)           113252352 \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 4, 6144)           0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 4, 6144)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 2, 3072)           56626176  \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1, 3072)           0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 1, 3072)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4096)              12587008  \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 392,636,416\n",
      "Trainable params: 392,636,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_softmax = Sequential()\n",
    "\n",
    "for index in range(1, len(model.layers)+1):\n",
    "    if index == len(model.layers):\n",
    "        break\n",
    "    else:\n",
    "        model_no_softmax.add(model.layers[index-1])\n",
    "\n",
    "model_no_softmax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Happy_npy//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Angry_npy//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Neutral_npy//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Sad_npy//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Other_npy//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Happy_npy_test//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Angry_npy_test//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Neutral_npy_test//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Sad_npy_test//\n",
      "..//..//Datasets//padded_deamplified_homenoised_reverberated//npy//Other_npy_test//\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(1, '..//components//')\n",
    "import load_feat_directories\n",
    "\n",
    "all_noised_npy = load_feat_directories.allnoised_npy\n",
    "all_noised_npy_test = load_feat_directories.allnoised_npy_test\n",
    "home_noised_npy = load_feat_directories.homenoised_npy\n",
    "home_noised_npy_test = load_feat_directories.homenoised_npy_test\n",
    "\n",
    "for index in range(0, 5):\n",
    "    if not os.path.exists(all_noised_npy[index]):\n",
    "        print(all_noised_npy[index] + ' does not exist. Breaking the loop... ')\n",
    "        break\n",
    "\n",
    "    if not os.path.exists(home_noised_npy[index]):\n",
    "        print(home_noised_npy[index] + 'does not exist. Breaking the loop... ')\n",
    "        break\n",
    "\n",
    "def comprise_vector(path):\n",
    "    vec_to_return = []\n",
    "    for fname in os.listdir(path):\n",
    "        current_vec = np.load(path + fname)\n",
    "        vec_to_return.append(current_vec)\n",
    "\n",
    "    vec_to_return = np.array(vec_to_return)\n",
    "    return vec_to_return\n",
    "\n",
    "def comprise_label(feature_vector, label):\n",
    "    label_vec_to_ret = []\n",
    "    length = len(list(feature_vector))\n",
    "    for index in range(0, length):\n",
    "        current_label = [label]\n",
    "        label_vec_to_ret.append(current_label)\n",
    "    label_vec_to_ret = np.array(label_vec_to_ret)\n",
    "\n",
    "    return label_vec_to_ret\n",
    "\n",
    "def float_compatible(input_np):\n",
    "    x = np.where(input_np >= np.finfo(np.float32).max)\n",
    "    for index in range(0, len(x[0])):\n",
    "        x_position = x[0][index]\n",
    "        y_position = x[1][index]\n",
    "        input_np[x_position, y_position] = 0.0\n",
    "    input_np = np.nan_to_num(input_np)\n",
    "\n",
    "    return input_np\n",
    "        \n",
    "for index in [0, 1, 2, 3, 4]:\n",
    "    if not os.path.exists(home_noised_npy[index]):\n",
    "        print(home_noised_npy[index] + 'does not exist.')\n",
    "    else:\n",
    "        path = home_noised_npy[index]\n",
    "        print(path)\n",
    "        if index == 0:\n",
    "            h_feature_vector_home = comprise_vector(path)\n",
    "            h_label_vector_home = comprise_label(h_feature_vector_home, index)\n",
    "        elif index == 1:\n",
    "            a_feature_vector_home = comprise_vector(path)\n",
    "            a_label_vector_home = comprise_label(a_feature_vector_home, index)\n",
    "        elif index == 2:\n",
    "            n_feature_vector_home = comprise_vector(path)\n",
    "            n_label_vector_home = comprise_label(n_feature_vector_home, index)\n",
    "        elif index == 3:\n",
    "            s_feature_vector_home = comprise_vector(path)\n",
    "            s_label_vector_home = comprise_label(s_feature_vector_home, index)\n",
    "        else:\n",
    "            o_feature_vector_home = comprise_vector(path)\n",
    "            o_label_vector_home = comprise_label(o_feature_vector_home, index)\n",
    "\n",
    "for index in [0, 1, 2, 3, 4]:\n",
    "    \n",
    "    if not os.path.exists(home_noised_npy_test[index]):\n",
    "        print(home_noised_npy_test[index] + 'does not exist.')\n",
    "    else:\n",
    "        path = home_noised_npy_test[index]\n",
    "        print(path)\n",
    "        if index == 0:\n",
    "            h_feature_vector_home_test = comprise_vector(path)\n",
    "            h_label_vector_home_test = comprise_label(h_feature_vector_home_test, index)\n",
    "        elif index == 1:\n",
    "            a_feature_vector_home_test = comprise_vector(path)\n",
    "            a_label_vector_home_test = comprise_label(a_feature_vector_home_test, index)\n",
    "        elif index == 2:\n",
    "            n_feature_vector_home_test = comprise_vector(path)\n",
    "            n_label_vector_home_test = comprise_label(n_feature_vector_home_test, index)\n",
    "        elif index == 3:\n",
    "            s_feature_vector_home_test = comprise_vector(path)\n",
    "            s_label_vector_home_test = comprise_label(s_feature_vector_home_test, index)\n",
    "        else:\n",
    "            o_feature_vector_home_test = comprise_vector(path)\n",
    "            o_label_vector_home_test = comprise_label(o_feature_vector_home_test, index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: (39916, 48, 272)\n",
      "training label: (39916, 5)\n",
      "evaluation data: (8843, 48, 272)\n",
      "evaluation label: (8843, 5)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils, to_categorical\n",
    "\n",
    "# Load training npy files\n",
    "featureSet = float_compatible(np.vstack((h_feature_vector_home, a_feature_vector_home, n_feature_vector_home, s_feature_vector_home, o_feature_vector_home)))\n",
    "Label = (np.vstack((h_label_vector_home, a_label_vector_home, n_label_vector_home, s_label_vector_home, o_label_vector_home)))\n",
    "\n",
    "Label[Label == 0] = 0\n",
    "Label[Label == 1] = 1\n",
    "Label[Label == 2] = 2\n",
    "Label[Label == 3] = 3\n",
    "Label[Label == 4] = 4\n",
    "\n",
    "Label = to_categorical(Label)\n",
    "#featureSet = np.split(featureSet, np.array([NumofFeaturetoUse]), axis = 2)[0]\n",
    "print('training data: ' + str(featureSet.shape))\n",
    "print('training label: ' + str(Label.shape))\n",
    "\n",
    "# Load testing npy files\n",
    "featureSet_val = float_compatible(np.vstack((h_feature_vector_home_test, a_feature_vector_home_test, n_feature_vector_home_test, s_feature_vector_home_test, o_feature_vector_home_test)))\n",
    "Label_val = (np.vstack((h_label_vector_home_test, a_label_vector_home_test, n_label_vector_home_test, s_label_vector_home_test, o_label_vector_home_test)))\n",
    "\n",
    "Label_val[Label_val == 0] = 0\n",
    "Label_val[Label_val == 1] = 1\n",
    "Label_val[Label_val == 2] = 2\n",
    "Label_val[Label_val == 3] = 3\n",
    "Label_val[Label_val == 4] = 4\n",
    "\n",
    "Label_val = to_categorical(Label_val)\n",
    "#featureSet_val = np.split(featureSet_val, np.array([NumofFeaturetoUse]), axis = 2)[0]\n",
    "print('evaluation data: ' + str(featureSet_val.shape))\n",
    "print('evaluation label: ' + str(Label_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_class_mean(X, Y, c, penultimate_neuron_num):\n",
    "    \"\"\"\n",
    "    X is of shape (batch, num_of_small_segs, feats_in_one_seg).\n",
    "    Y is of shape (batch, class).\n",
    "    c is a class, of type integer.\n",
    "    func is the output of the penultimate layer of DNNs. \n",
    "    func should be called as func(x), s.t. x is one xample in X.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('calculating the empirical class mean for the class ' + str(c) )\n",
    "    N_c = 0\n",
    "    \n",
    "    for item in Y:\n",
    "        if item[c] == 1:\n",
    "            N_c += 1\n",
    "    \n",
    "    print('there are in total ' + str(N_c) + ' samples of the class ' + str(c))\n",
    "    sum_func = np.array([0] * penultimate_neuron_num)\n",
    "    \n",
    "    for index in range(0, len(Y)):\n",
    "        if Y[index][c] == 1:\n",
    "            sum_func = np.add(model_no_softmax.predict(np.array([X[index]])), sum_func)\n",
    "    return sum_func / N_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_class_means(X, Y, C, penultimate_neuron_num):\n",
    "    \"\"\"\n",
    "    Calculate the empirical class means for all classes and output a numpy array.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for c in C:\n",
    "        miu = empirical_class_mean(X, Y, c, penultimate_neuron_num)\n",
    "        result.append(miu)\n",
    "        \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emprical_covariance(X, Y, mius, penultimate_neuron_num):\n",
    "    assert len(X) == len(Y)\n",
    "    N = len(Y)\n",
    "    miu = mius[0]\n",
    "    sum_all_classes = np.array(miu.shape)\n",
    "    \n",
    "    #print(mius)\n",
    "    for c in C:\n",
    "        sum_single_c = np.array(miu.shape)\n",
    "        for index in range(0, len(Y)):\n",
    "            if Y[index][c] == 1:\n",
    "                miu = mius[c]\n",
    "                difference = model_no_softmax.predict(np.array([X[index]])) - miu\n",
    "                transpose = np.transpose(difference)\n",
    "                result = difference * transpose\n",
    "                sum_single_c = np.add(sum_single_c, result)\n",
    "        \n",
    "        sum_all_classes = np.add(sum_all_classes, sum_single_c)\n",
    "        \n",
    "    covariance = sum_all_classes/N\n",
    "    \n",
    "    return covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the empirical class mean for the class 0\n",
      "there are in total 8786 samples of the class 0\n"
     ]
    }
   ],
   "source": [
    "res_h = empirical_class_mean(featureSet, Label, 0, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the empirical class mean for the class 1\n",
      "there are in total 8816 samples of the class 1\n"
     ]
    }
   ],
   "source": [
    "res_a = empirical_class_mean(featureSet, Label, 1, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the empirical class mean for the class 2\n",
      "there are in total 7742 samples of the class 2\n"
     ]
    }
   ],
   "source": [
    "res_n = empirical_class_mean(featureSet, Label, 2, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the empirical class mean for the class 3\n",
      "there are in total 8811 samples of the class 3\n"
     ]
    }
   ],
   "source": [
    "res_s = empirical_class_mean(featureSet, Label, 3, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating the empirical class mean for the class 4\n",
      "there are in total 5761 samples of the class 4\n"
     ]
    }
   ],
   "source": [
    "res_o = empirical_class_mean(featureSet, Label, 4, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "emprical_means = [res_h, res_a, res_n, res_s, res_o]\n",
    "np.save('..//..//modules//penultimate_emprical_means_5_classes.npy', emprical_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
